<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[系统剩余空间查看]]></title>
    <url>%2F%E7%B3%BB%E7%BB%9F%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4%E6%9F%A5%E7%9C%8B%2F</url>
    <content type="text"><![CDATA[code1234567891011121314151617181920#!/bin/bash# 系统剩余磁盘空间查看等报告echo report date = `date`echo -e "\n"echo "MEM INFO:"echo mem total = `free -g |grep 'Mem' |awk '&#123;print $2&#125;'`Gecho mem used = `free -g |grep 'Mem' |awk '&#123;print $3&#125;'`Gecho -e "\n" echo "PROCESS INFO:"echo process num = `ps -elf |wc -l`echo zombie process num =`ps -elf |awk '&#123;print $2&#125;'|grep 'Z' |wc -l`echo -e "\n"echo "DISK SPACE INFO:"echo root_space_total = `df -h |grep '/dev/sda' |awk '&#123;print $2&#125;'`echo root_space_used = `df -h |grep '/dev/sda' |awk '&#123;print $3&#125;'`echo root_space_avliable = `df -h |grep '/dev/sda' |awk '&#123;print $4&#125;'`echo root_space_used_percent = `df -h |grep '/dev/sda' |awk '&#123;print $5&#125;'` result 图1. 系统剩余空间查看示例— 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal.### Ads这是小广告! 如果有需要, 不妨支持一下吧~&gt; 这些好书您看了吗?&gt; 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库分类]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[数据库分类 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集合框架]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Java集合框架 Collection 接口 规则集 比较器接口 Comparator 线性表 线性表与集合的静态方法 队列与优先队列 图 备注 Ads Java集合框架Java 集合框架是 Java 提供的几个能有效组织和操作数据的数据结构，支持两种类型的容器：集合与图。 Java 集合框架支持三种主要类型的集合：规则集(Set)、线性表(List)和队列(Queue)。Set 的实例用于存储一组不重复的元素，List 的实例用于存储一个由元素构成的有序集合，Queue 的实例用于存储先进先出方式处理的对象。 Collection 接口Collection 接口是处理对象集合的根接口，提供了在集合中添加、删除元素与查询的基本操作。 AbstractCollection 类是提供 Collection 接口的部分实现的便利类。 规则集Set 接口扩展了 Collection 接口，并未引入新的方法或常量，只是规定 Set 的实例不包含重复的元素。以下介绍 Set 接口的三个具体类。 散列集 HashSet：以一个不可预知的顺序存储元素。 链式散列集 LinkedHashSet：以元素被插入的顺序存储元素。 树形集 TreeSet：存储已按照元素之间的比较原则排好序的元素；可使用元素的 Comparable 接口或者指定一个比较器。 比较器接口 Comparator有时希望将元素插入到一个树集合中，而这些元素可能不是 java.lang.Comparable 的实例，此时可定义一个比较器来比较这些元素。若如此做，则需创建一个实现 java.util.Comparator 接口的比较器类。Comparator 接口有两个方法：compare 与 equals 。 123456789101112import java.util.Comparator;public class UserComparator implements Comparator&lt;User&gt;,java.io.Serializable&#123; public int compare(User u1, User u2)&#123; if(u1.age &gt; u2.age) return 1; else if(u1.age == u2.age) return 0; else return -1; &#125;&#125; 要想使用比较器，必须使用构造方法 TreeSet(Comparator comparator) 来创建一个有序集，它可使用比较器中的 compare 方法进行排序。 线性表线性表不仅可以存储重复的元素，而且允许用户指定它们存储的位置。 数组线性表类 ArrayList ：实现 List 接口的可变大小的数组。 链表类 LinkedList ：实现了 List 接口的一个链表。此外还额外提供了从线性表两端操作元素的方法。 线性表与集合的静态方法由于线性表不支持有序存储，因此 Collections 类提供了对线性表排序以及其他操作的静态方法。 队列与优先队列队列是一种先进先出的数据结构，元素被追加到队尾，然后从队列头删除。而在优先队列中，元素被赋予优先级，当访问元素时，拥有最高优先级的元素首先被删除。 java.util.Queue 接口用附加的插入、提取和检验操作来扩展 java.util.Collection 接口。由于 LinkedList 类实现了 Deque 接口，Deque 又扩展了 Queue 接口，因此可用 LinkedList 来创建一个队列。 java.util.PriorityQueue 类实现一个优先队列，默认情况下按照 Comparable 以元素的自然顺序来排序，也可以通过构造方法使用 Comparator 指定一个顺序。 图图是一种按照键值存储元素的容器。图中不能有重复的键值，每个键值对应一个值。一个键值与它的对应值构成一个条目。 java.util.Map 接口提供了查询、更新和获取集合的值或键值的方法。 散列图 HashMap ：条目没有顺序。 链式散裂图 LinkedHashMap：条目可按照某种顺序来获取，既可以是插入顺序也可以是最后一次访问的顺序。 树形图 TreeMap ：条目按照 Comparable 或者指定比较器的顺序进行排序。 备注 Java 集合框架中的所有实例类都实现了 Cloneable 和 Serializable 接口，因此它们的实例都是可复制和可序列化的。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Heartbeat双机热备方案]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2F%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%2FHeartbeat%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[Heartbeat 部署方案（CentOS） 安装 配置 认证文件（/etc/ha.d/authkeys） 主配置文件（/etc/ha.d/ha.cf） 资源文件（/etc/ha.d/haresources） 参考文档 Ads Heartbeat 部署方案（CentOS） 注意：Heartbeat 方案本人还未有实践过 安装两种安装方式： 主从节点都使用yum install heartbeat*命令安装 Heartbeat（须确保已安装 epel 扩展软件包源）。 在 Linux-HA 官网下载 Heartbeat。 配置Heartbeat 主要的配置文件有 3 个，分别是 authkeys，ha.cf 和 haresources。其中 ha.cf 是主配置文件，haresource 用来配置要让 Heartbeat 托管的服务，authkey 是用来指定 Heartbeat 的认证方式。 在 Heartbeat 安装后，默认并没有这三个文件，可以直接从解压的源码目录中找到。 这里以 master/slave 两节点为例，示例的配置文件为 master 节点的。 认证文件（/etc/ha.d/authkeys）该文件为 Heartbeat 的认证文件，该文件主要是用于集群中两个节点的认证，采用的算法和密钥（如果有的话）在集群中节点上必须相同。目前提供了 3 种算法：crc/md5/sha1。其中 crc 不能够提供认证，它只能够用于校验数据包是否损坏，而 sha1/md5 需要一个密钥来进行认证。 1234auth 2#1 crc2 sha1 somewords#3 md5 somewords 以上示例中使用的是 sha1 算法，如果要换用其他算法只需要修改 auth 指令后面的数字，然后取消相应行的注释即可。 注意：该文件的属性必须为600，否则 Heartbeat 启动将失败。且两个节点的 authkeys 文件内容及权限相同。 主配置文件（/etc/ha.d/ha.cf）该文件是 Heartbeat 的主配置文件。 12345678910111213141516keepalive 2warntime 5deadtime 30initdead 120udpport 6942bcast eth0# mcast eth0 225.0.0.1 694 1 0ucast eth1 &#123;&#123; slave的IP地址 &#125;&#125;auto_failback offwatchdog /dev/watchdognode host41 host42# ping 172.16.12.1 ping_group group1 172.16.12.1respawn hacluster /usr/lib64/heartbeat/ipfailrespawn hacluster /usr/lib64/heartbeat/dopdapiauth dopd gid=haclient uid=haclusteruse_logd yes keepalive：发送心跳报文的间隔。默认单位为秒，也可以使用 500ms 来指代 500 毫秒，等同于 0.5。 warntime：认为对方可能宕掉的间隔时间。 deadtime：认为对方宕掉的间隔时间，超过这个时间，则认为对方已经宕掉。 initdead：等待对方启动的最大时间。 udpport：heartbeat 广播/单播通讯使用的 udp 端口。 bcast：心跳所使用的网络接口。 ucast：单播通讯，对方网络接口及IP地址。 mcast：组播通讯，参数如右：通讯所用的接口 绑定的组播IP（224.0.0.0-239.255.255.255）通讯端口 ttl 是否允许环回。 auto_failback：表示当主节点（即提供资源/服务的节点）正常之后是否将资源/服务切换回来。 watchdog：看门狗定时器，如果节点一分钟内没有心跳，则重启节点。 node：heartbeat 集群中的节点信息（节点的主机名: uname -n）。 ping/ping_group：用于建立伪集群成员，作用是监测物理链路，如果该节点与伪集群成员不相通，那么该节点无权接管资源/服务。 另一从节点（slave）需要将 ha.cf 文件中 ucast 的 IP 地址改为主节点（master）的 IP 地址。 资源文件（/etc/ha.d/haresources）haresources 文件用于指定双机系统的主节点、集群IP、子网掩码、广播地址以及启动的服务等集群资源。文件每一行可以包含一个或多个资源脚本名，资源之间使用空格隔开，参数之间使用两个冒号隔开。在两个节点上该文件必须完全一致，此文件的一般格式为：1node-name network &lt;resource-group&gt; node-name 表示主节点的主机名，必须和 ha.cf 文件中指定的节点名一致；network 用于设定集群的 IP 地址、子网掩码、网络设备标识等（这里指定的IP地址就是集群对外服务的IP地址），resource-group 用来指定需要 Heartbeat 托管的服务，也就是这些服务可以由 Heartbeat 来启动和关闭，如果要托管这些服务，必须将服务写成可以通过 start/stop 来启动和关闭的脚本，然后放到 /etc/init.d/ 或者 /etc/ha.d/resource.d/ 目录下，heartbeat 会根据脚本的名称自动去 /etc/init.d 或者 /etc/ha.d/resource.d/ 目录下找到相应脚本进行启动或关闭操作。 以下是一个具体实例：1node1 IPaddr::192.168.60.200/24/eth0/ Filesystem::/dev/sdb5::/webdata::ext3 httpd tomcat 其中，node1 是 HA 集群的主节点，IPaddr 为 HeartbeatH自带的一个执行脚本，Heartbeat 首先将执行/etc/ha.d/resource.d/IPaddr 192.168.60.200/24 start的操作，也就是虚拟出一个子网掩码为 255.255.255.0，IP为 192.168.60.200 的地址，此IP为 Heartbeat 对外提供服务的网络地址，同时指定此 IP 使用的网络接口为 eth0，接着，Heartbeat 将执行共享磁盘分区的挂载操作，Filesystem::/dev/sdb5::/webdata::ext3相当于在命令行下执行 mount 操作，即“mount –t ext3 /dev/sdb5 /webdata”，最后依次启动 httpd 和 tomcat 服务。 注意：主节点和从节点中资源文件 haresources 一般要完全一致。 参考文档Linux-HA开源软件Heartbeat（配置篇）heartbeat配置相关 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>集群高可用方案</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy+Keepalived高可用方案]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2F%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%2FHAProxy%2BKeepalived%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[技术简介 HAProxy Keepalived HAProxy + Keepalived 部署方案 前端配置 前端配置 keepalived 前端配置 HAProxy 参考文档 Ads 技术简介HAProxyHAProxy（High Available Proxy）是一款提供高可用性、负载均衡以及基于 TCP（第四层）和 HTTP（第七层）应用的代理软件。 HAProxy 配置简单、支持多达上万并发连接。其运行模型可使得它非常容易和无风险地集成到现有的架构中，并且同时可以保护 web 服务器不被暴露到网络上。 KeepalivedKeepalived 是一款高可用软件，它的功能是基于 VRRP 协议，通过 IP 漂移实现服务的高可用：服务器集群共享一个虚拟 IP，同一时间只有一个服务器占有虚拟 IP 并对外提供服务。若该服务器不可用，则虚拟 IP 漂移至另一台服务器并对外提供服务。 Keepalived 可以单独使用，即通过 IP 漂移实现服务的高可用，也可以结合 LVS 使用（即一方面通过 IP 漂移实现 LVS 负载均衡层的高可用，另一方面实现 LVS 应用服务层的状态监控）。 HAProxy + Keepalived 部署方案准备四台虚机，分别记作 HA-master、HA-slave、web-node1、web-node2。前两者作为 HA 负载均衡调度器（即前端），后两者是提供应用服务的 web 服务器（即后端）。 前端配置前端配置 keepalivedHA-master 与 HA-slave 都需安装 keepalived 服务：yum -y install keepalived，keepalived 的配置文件路径为/etc/keepalived/keepalived.conf。 配置 HA-master 的 keepalived：1234567891011121314151617181920212223global_defs &#123; router_id HA_DEVEL&#125;vrrp_instance VI_1 &#123; #主从实例1 state MASTER #HA-master（172.18.216.115）为主， #HA-slave（172.18.216.79）为备 #在HA-slave上，该处设置为BACKUP interface ens192 #与实际网卡的名称必须保持一致 virtual_router_id 88 #实例1的VRID为88 garp_master_delay 1 #在切换到master状态后，延迟进行gratuitous ARP请求 priority 100 #HA-master的优先级为100，HA-slave的优先级为99 #在HA-slave上，该选项设置为99 advert_int 1 authentication &#123; auth_type PASS auth_pass 123456 &#125; virtual_ipaddress &#123; 172.18.216.194 #实例1的虚拟IP &#125;&#125; 接下来再配置 HA-slave 的 keepalived 配置文件。HA-slave 与 HA-master 的配置文件除了state项与priority项不同以外，其他项完全相同。 配置完成后，在两台虚机上都用service keepalived start命令启动 keepalive 服务。之后在 HA-master 上使用ip addr show命令可以看到当前节点已经绑定了虚拟 IP。且可以通过关闭 HA-master 上的 keepalive 服务来查看虚拟 IP 是否浮动到了 HA-slave。 但目前 haproxy 服务停止时，keepalived 服务并不会停止，所以还需要写一个脚本，使得当 haproxy 服务停止时，keepalived 服务也会停止 前端配置 HAProxy在 HA-master 与 HA-slave 上安装 HAProxy：yum install haproxy，然后配置 HAProxy（路径/etc/haproxy/haproxy.cfg）。 HAProxy 的配置文件分为五个部分： global：全局配置的进程级参数，用来控制 Haproxy 启动前的一些进程及系统设置 defaults：配置默认参数，可以被 frontend，backend，listen 段继承使用 frontend：定义接收请求的前端虚拟节点，可根据用户所请求的不同域名、URL 等做不同的请求处理 backend：定义处理业务的后端服务器集群，以及设置后端的权重、队列、连接数等选项 listen：frontend 和 backend 的组合体 对配置参数的更详细说明请查阅文末的参考文档。 以下是 HA-master 与 HA-slave 上的配置示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950global log 127.0.0.1 local2 # 定义日志输出设置 chroot /var/lib/haproxy # chroot运行路径 pidfile /var/run/haproxy.pid # haproxy进程PID文件 maxconn 20000 # 默认最大连接数 daemon # 以后台形式运行harpoxy#---------------------------------------------------------------------# common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will# use if not designated in their block#---------------------------------------------------------------------defaults mode http # 所处理的类别(7层代理http，4层代理tcp) log global # 引入global定义的日志格式 option httplog # 日志类别为http日志格式 option dontlognull option http-server-close # 当客户端超时时，允许服务器关闭连接 option forwardfor except 127.0.0.0/8 # 在响应头部加入forwardfor option redispatch # 在使用了基于cookie的会话保持的时候，通常需要 # 加这么一项，一旦后端某一server宕机时，能够将 # 其会话重新派发到其它的servers retries 3 # 3次连接失败就认为服务器不可用 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s # 默认持久连接超时时间 timeout check 10s # 心跳检查超时时间 maxconn 5000 # 最大并发连接数#---------------------------------------------------------------------# main frontend which proxys to the backends#---------------------------------------------------------------------frontend proxy *:80 #前端代理 default_backend dynamic#---------------------------------------------------------------------# round robin balancing between the various backends#---------------------------------------------------------------------backend dynamic #后端动态服务器 balance roundrobin cookie SESSION_ID insert indirect nocache #设置cookie保持 server web1 172.18.218.149:80 inter 3000 rise 2 fall 3 check maxconn 5000 cookie A server web2 172.18.216.107:80 inter 3000 rise 2 fall 3 check maxconn 5000 cookie Blisten statistics #设置HAProxy 的自带管理系统 mode http bind *:8080 #把stats页面绑定到8080端口 stats enable #开启stats功能 stats auth admin:admin #认证的用户名和密码 stats uri /admin?stats #指定uri访问路径 stats hide-version #为了安全（版本bug），隐藏版本信息 stats refresh 5s #页面5秒刷新一次 参考文档keepalived+haproxy双主高可用负载均衡HAProxy用法详解 全网最详细中文文档haproxy配置详解HAproxy指南之haproxy配置详解 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>集群高可用方案</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链简介]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9B%B8%E5%85%B3%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[区块链简介 应用领域 基于区块链的征信系统（与数据中心比较） Ads 区块链简介区块链技术是金融科技（FinTech）领域的一项重要技术创新。作为去中心化记账（Decentralized Ledger Technology，DLT）平台的核心技术，区块链被认为在金融、征信、物联网、经济贸易结算、资产管理等众多领域都拥有广泛的应用前景。 把区块链想象成一个公共账本，这个账本： 存放在区块链系统的各个节点上，每个节点都有一份完整的备份。 每个节点的账本都记录着自区块链系统建立以来的所有交易。 账本被分为若干个区块进行存储，每个区块包含一部分交易记录。每一个区块都会记录着前一区块的 id，形成一个链状结构，因而称为区块链。 当发起一笔交易时，只需把交易信息广播到系统的 p2p 网络中，其他节点把该笔交易信息记录成一个新的区块连到区块链上，交易即可完成。 区块链的重要特性（DACT）： Distributed（分布式的）：区块链系统中有多个独立节点，所有节点都共享同一份数据。 Autonomous（自治的）：所有操作都由系统自动完成而不需要一个中心机构进行管理。 Contractual（按照合约执行的）：数据是公开的不代表所有人可以随意访问区块链系统上的数据，系统有着最严格的权限设置。在系统约定一个共同合约后，只有确定权限的用户才可以访问加密的数据。 Trackable（可追溯的）：区块链系统中所有交易都是可追溯的，添加交易信息需要得到系统的共识，因而数据不可篡改。 区块链的意义在于：构建了更加可靠、值得信任的互联网，从根本上解决了价值转移和交换过程中出现的存在的欺诈与寻租现象。 应用领域基于区块链的征信系统（与数据中心比较）征信：为防止在非即付经济交往中的交易双方收到损失而进行的一种信用评估。征信所提供的服务，就是向交易双方提供对方的背景和信用信息，解决交易信任的问题。 在一个征信体系中，对金融机构有价值的客户可划分为优质客户（白名单）、中间客户、风险客户（黑名单）。白名单是主要服务对象，因为其意味着收益；而对黑名单则需要进行风险控制。但目前传统意义上的金融征信系统普遍存在局限性： 目前大部分信用数据是一个个独立的信息孤岛（比如央行征信系统的数据），彼此并不联通。而完全开放征信系统数据又可能会造成虚假数据上传、金融机构核心业务信息被泄露等问题。 即使是对于传统意义上的征信共享，多个机构共享的结果是把每个机构的数据汇总到一个庞大的数据中心系统，参与机构都在该系统上查询。但也会有问题： 系统是中心化的，一旦中心遭到攻击、篡改、上传虚假数据就会影响到所有数据的可靠性；同时也会出现人工误操作的情况。 数据汇总与更新速度不可控，难以及时进行征信数据同步 数据访问权限以及数据交换、共享问题：难以实现权限控制以及两个机构之间的私密数据有偿交换 由于数据中心共享的透明性，有些机构会故意保留己方的核心业务数据以防泄露 若要保证查询速度，则需要构建复杂的冗余系统；否则的话只有一个中心处理所有的请求，则系统速度可能会慢到不可用的程度 而区块链技术是最适合用于解决征信问题的解决方案： 把中心化的存储转化为去中心化的分布式存储，变统一中心节点查询为 p2p 查询，提高安全性与性能 每个节点的数据完全同步 数据无法被篡改，即使有虚假数据也可以迅速追溯到源头 利用智能合约设置数据汇总与更新规则 通过智能合约进行权限控制，拥有对应的访问权限才可访问对应的数据 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeadm部署多节点集群]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2FKubernetes%E9%83%A8%E7%BD%B2%2Fkubeadm%E9%83%A8%E7%BD%B2%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[kubeadm 部署多节点 k8s 集群教程（1.9.1） 一. 前提条件 二. 安装依赖环境 安装 Docker k8s.conf是k8s的配置文件 ——————- Dashboard Service ——————- $ kubectl delete -f kubernetes-dashboard.yaml kubeadm 部署多节点 k8s 集群教程（1.9.1）kubeadm 是一个用于快速创建与扩展 k8s 集群的工具包。本教程主要讲述如何使用 kubeadm 构建一个双节点的 k8s 集群（版本为 1.9.1），构建集群中的 pod 通信网络，最后安装可视化的管理控制台。 本教程的集群节点均是由同一台 PC 所虚拟出来的两台虚机。 一. 前提条件配置要求如下： 两台安装有 CentOS 7 操作系统的机器（命名为 kube-1 与 kube-2） 每台机器拥有 2G 以上内存以及 2核 以上处理器 每台机器关闭防火墙与 SELinux 每台机器彼此之间都可以通过网络联通 拥有一个可以“科学上网”的 ShadowSocksS 服务器 禁用 swap，以保证 kubelet 正确运行：每台机器执行swapoff -a。（注意：机器重启后可能需要再次禁用 swap） 确认每台机器的 MAC 地址与 product_uuid 都是独有的。查询 MAC 地址：ifconfig -a，查询 product_uuid：cat /sys/class/dmi/id/product_uuid。 拥有一个可以科学上网的 VPS 服务器：VPS 配置 Shadowsocks 教程。 每台机器都可以科学上网：Linux 配置 Shadowsocks 客户端，以及 为 Docker 配置网络代理。如果不能科学上网的话，就会导致很多镜像无法正常下载。 二. 安装依赖环境安装 Docker为所有节点（逻辑上的机器）安装 Docker，官方推荐安装 v1.12 版本（过高版本将不兼容 k8s）。可参考 Docker CE 安装。1234567$ yum-config-manager \ --add-repo \ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo$ yum makecache fast$ yum install -y docker-ce$ systemctl enable docker &amp;&amp; systemctl start docker``` ocker stmeablekertesocker ucgr r /tc/docker/eoso ec atuiersystemdocker et r ocker 安装 kubeadm, kubelet 与 kubectl需要在所有节点上安装： kubeadm：引导集群的命令工具 kubelet：运行在集群中所有节点上的组件，负责处理 Pods 与容器。 kubectl：与集群交互的命令工具 若可以“科学上网”（否则需要手动下载 rpm 包），则安装命令如下：123456789101112$ cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF$ yum install -y kubelet-1.9.1 kubeadm-1.9.1 kubectl-1.9.1$ systemctl enable kubelet &amp;&amp; systemctl start kubelet 选择 1.9.1 版本进行下载，但请注意必须确保 kubeadm， kubelet 的版本都一致，且与 kubectl 不低于 kubeadm 的版本。 为防止“科学上网”，则可直接进行下一步。否则就需要手动 kubeadm 初始化 k8s 时 RHEL/CentOS 7 的用户可能会报错配置失败：You should ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl config。需要执行如下命令：123456# k8s.conf是k8s的配置文件$ cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF$ sysctl --system 若 Docker 也配置了代理“科学上网”，则可直接进行下一步，否则就需要手动下载如下镜像到本地：1234567891011REPOSITORY TAG IMAGE ID CREATED SIZEgcr.io/google_containers/kube-apiserver-amd64 v1.9.1 e313a3e9d78d 7 weeks ago 210.4 MBgcr.io/google_containers/kube-scheduler-amd64 v1.9.1 677911f7ae8f 7 weeks ago 62.7 MBgcr.io/google_containers/kube-proxy-amd64 v1.9.1 e470f20528f9 7 weeks ago 109.1 MBgcr.io/google_containers/kube-controller-manager-amd64 v1.9.1 4978f9a64966 7 weeks ago 137.8 MBquay.io/coreos/flannel v0.9.1-amd64 2b736d06ca4c 3 months ago 51.31 MBgcr.io/google_containers/k8s-dns-sidecar-amd64 1.14.7 db76ee297b85 4 months ago 42.03 MBgcr.io/google_containers/k8s-dns-kube-dns-amd64 1.14.7 5d049a8c4eec 4 months ago 50.27 MBgcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.7 5feec37454f4 4 months ago 40.95 MBgcr.io/google_containers/etcd-amd64 3.1.10 1406502a6459 5 months ago 192.7 MBgcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 22 months ago 746.9 kB 可通过 官网 来查看所需手动下载的依赖镜像的版本。 三. 使用 kubeadm 初始化集群在一个节点（该节点将会成为集群的 master ）上使用kubeadm init --kubernetes-version 1.9.1 --pod-network-cidr=10.244.0.0/16来初始化一个集群（--pod-network-cidr 在下一节介绍）。 注意：若主机开启了“科学上网”的网络访问代理的话，需要先关掉主机的代理，否则初始化集群时访问内部 IP 也会经过代理，从而导致报错。 若运行成功，则输出将如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.[init] Using Kubernetes version: v1.8.0[init] Using Authorization modes: [Node RBAC][preflight] Running pre-flight checks[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)[certificates] Generated ca certificate and key.[certificates] Generated apiserver certificate and key.[certificates] apiserver serving cert is signed for DNS names [kubeadm-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.138.0.4][certificates] Generated apiserver-kubelet-client certificate and key.[certificates] Generated sa key and public key.[certificates] Generated front-proxy-ca certificate and key.[certificates] Generated front-proxy-client certificate and key.[certificates] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;admin.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;kubelet.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;controller-manager.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;scheduler.conf&quot;[controlplane] Wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] Wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;[init] This often takes around a minute; or longer if the control plane images have to be pulled.[apiclient] All control plane components are healthy after 39.511972 seconds[uploadconfig] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[markmaster] Will mark node master as master by adding a label and a taint[markmaster] Master master tainted and labelled with key/value: node-role.kubernetes.io/master=&quot;&quot;[bootstraptoken] Using token: &lt;token&gt;[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: kube-dns[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run (as a regular user): mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: http://kubernetes.io/docs/admin/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; 初始化完毕后，运行以下命令给予用户权限来使用集群：123$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config 执行 kubectl get nodes，发现得到了一个状态为NotReady的 Node。 查看一下集群状态kubectl get cs，确认各个组件都处于 healthy 状态。：1234NAME STATUS MESSAGE ERRORscheduler Healthy okcontroller-manager Healthy oketcd-0 Healthy &#123;&quot;health&quot;: &quot;true&quot;&#125; 查看集群组件 pod 运行情况：kubectl get pods --all-namespaces，正常情况下的输出如下：1234567NAMESPACE NAME READY STATUS RESTARTS AGEkube-system etcd-kube-1 1/1 Running 0 1hkube-system kube-apiserver-kube-1 1/1 Running 0 1hkube-system kube-controller-manager-kube-1 1/1 Running 0 1hkube-system kube-dns-6f4fd4bdf-jthnq 0/3 Pending 0 1hkube-system kube-proxy-2r2m4 1/1 Running 0 1hkube-system kube-scheduler-kube-1 1/1 Running 0 1h 上面输出的 kube-dns 的状态是正常的，因为集群还没有配置网络。 此外，集群初始化如果遇到问题，可以使用下面的命令进行清理：123456$ kubeadm reset$ ifconfig cni0 down$ ip link delete cni0$ ifconfig flannel.1 down$ ip link delete flannel.1$ rm -rf /var/lib/cni/ 四. 配置集群网络（Flannel）集群必须安装一个 pod 网络插件以便于 pods 能够互相通信，本教程中使用 Flannel 作为集群配置网络。 为使 flannel 运行成功，kubeadm init 运行时必须加上参数--pod-network-cidr=10.244.0.0/16。 运行：1kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml 正常输出如下：12345clusterrole &quot;flannel&quot; createdclusterrolebinding &quot;flannel&quot; createdserviceaccount &quot;flannel&quot; createdconfigmap &quot;kube-flannel-cfg&quot; createddaemonset &quot;kube-flannel-ds&quot; created 等待一段时间后，查看组件 pod 的运行情况：kubectl get pods --all-namespaces，若所有pods 都处于运行成功的状态，则说明网络部署成功。然后执行 kubectl get nodes 也可以发现 Node 已经处于 Ready 状态了。 注意：若主机有多个网卡，则可能会遭遇错误如右：flannel issues 3970。解决该问题（尚未测试）：目前需要在 kube-flannel.yml 中使用--iface参数指定集群主机内网网卡的名称，否则可能会导致 dns 无法解析。因此需要将 kube-flannel.yml 下载到本地，flanneld 启动参数加上 --iface=&lt;iface-name&gt;。 配置 master 节点是否调度 pod（可选）出于安全性考虑，在默认情况下 pod 不会被调度到 master 节点上，也就是说它不参与工作负载。但如果需要 master 也能调度 pod，以便于构造一个单节点集群用于开发用，则可以执行以下命令：1$ kubectl taint nodes --all node-role.kubernetes.io/master- 输出如下：123node &quot;test-01&quot; untaintedtaint key=&quot;dedicated&quot; and effect=&quot;&quot; not found.taint key=&quot;dedicated&quot; and effect=&quot;&quot; not found. 五. 向集群中添加节点Node 是集群中负责运行容器与 Pod 的节点，当需要添加一个主机到集群中成为一个新 Node 时，ssh 连接到该主机，切换到 root 用户权限，运行 master 节点 kubeadm init 时的输出中的参考命令，如下：1$ kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; 若运行成功则输出如下：1234567891011121314[preflight] Running pre-flight checks. [WARNING FileExisting-crictl]: crictl not found in system path[discovery] Trying to connect to API Server &quot;192.168.80.128:6443&quot;[discovery] Created cluster-info discovery client, requesting info from &quot;https://192.168.80.128:6443&quot;[discovery] Requesting info from &quot;https://192.168.80.128:6443&quot; again to validate TLS against the pinned public key[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;192.168.80.128:6443&quot;[discovery] Successfully established connection with API Server &quot;192.168.80.128:6443&quot;This node has joined the cluster:* Certificate signing request was sent to master and a response was received.* The Kubelet was informed of the new secure connection details.Run &apos;kubectl get nodes&apos; on the master to see this node join the cluster. 过一段时间后查询 kubectl get nodes 即可得到处于 Ready 状态的新 Node。 尝试运行一个应用（可选&amp;重要）123$ kubectl run curl --image=radial/busyboxplus:curl -i --ttyIf you don&apos;t see a command prompt, try pressing enter.[ root@curl-2716574283-xr8zd:/ ]$ 进入后执行 nslookup kubernetes.default 确认是否解析正常:123456$ nslookup kubernetes.defaultServer: 10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localName: kubernetes.defaultAddress 1: 10.96.0.1 kubernetes.default.svc.cluster.local 从 master 以外的节点来控制集群（可选&amp;重要）为了让其他节点（或者集群外部的节点）上的 kubectl 可以与集群通信，你需要从 master 节点复制管理员集群配置文件 admin.conf 到目标节点，命令如下：12$ scp root@&lt;master ip&gt;:/etc/kubernetes/admin.conf .$ kubectl --kubeconfig ./admin.conf get nodes admin.conf 给予用户控制集群的超级权限，必须谨慎使用。对于普通用户而言，建议生成一个独一凭证，使得放置该用户于白名单中：$ kubeadm alpha phase kubeconfig user --client-name &lt;CN&gt;，该命令将会输出一个 KubeConfig 文件，你可以保存该文件并发给该普通用户。然后使用$ kubectl create (cluster)rolebinding 启动白名单。 配置 API Server 的代理到本地 localhost（可选&amp;重要）若需要从集群外部连接到集群的 API Server，则可以使用kubectl proxy：12$ scp root@&lt;master ip&gt;:/etc/kubernetes/admin.conf .$ kubectl --kubeconfig ./admin.conf proxy 这样就可以在本地通过 http://localhost:8001/api/v1 来访问集群的 API Server 了。 六. 从集群中删除节点当需要从一个集群中删除节点时，首先需要停止该节点以确保该节点在关闭前是空的。 在 master 上运行以下命令：12$ kubectl drain &lt;node name&gt; --delete-local-data --force --ignore-daemonsets$ kubectl delete node &lt;node name&gt; 然后在被删除的节点上重置 kubeadm 的状态即可：1$ kubeadm reset 七. 安装 DashboardKubernetes Dashboard 是一个基于 web 的 k8s 集群控制台，它允许用户管理和调试已经运行在集群上的应用，甚至可以管理集群本身。 下载 Dashboard 的 yaml 配置文件：1$ wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 由于Dashboard 的 service 配置模式是 ClusterIP 而不能被集群外访问，因此我们需要配置成 NodePort 模式。编辑 kubernetes-dashboard.yaml 文件，在 Dashboard Service 中添加type: NodePort，暴露 Dashboard 服务：12345678910111213141516# ------------------- Dashboard Service ------------------- #kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: type: NodePort ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard 根据配置文件安装 Dashboard（若不能“科学上网”则可能下载镜像失败）：1$ kubectl create -f kubernetes-dashboard.yaml 执行 kubectl proxy 启动代理后，可以在代理机本地通过以下 URL 访问 Dashboard 网站：1http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ 也可以在外部通过https://[NodeIP]:[NodePort]来访问。 查看网站页面的登录 token：123$ kubectl -n kube-system get secret | grep kubernetes-dashboardkubernetes-dashboard-token-jxq7l kubernetes.io/service-account-token 3 22h$ kubectl describe -n kube-system secret/kubernetes-dashboard-token-jxq7l 当需要卸载 Dashboard ：1$ kubectl delete -f kubernetes-dashboard.yaml 如何使用管理员权限？如果我们直接使用上面获取的 token 登录 Dashboard 的网站后，发现几乎大部分的权限都不可以使用。 这是因为默认的 kubernetes-dashboard.yaml 文件中的 ServiceAccount kubernetes-dashboard 只有相对较小的权限。 因此我们需要创建一个 kubernetes-dashboard-admin 的 ServiceAccount 并授予其集群 admin 的权限。创建 kubernetes-dashboard-admin.rbac.yaml：123456789101112131415161718192021222324---apiVersion: v1kind: ServiceAccountmetadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-admin namespace: kube-system ---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-admin labels: k8s-app: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard-admin namespace: kube-system 执行该文件：1$ kubectl create -f kubernetes-dashboard-admin.rbac.yaml 再按照同样的方法查询到 kubernetes-dashboard-admin 的 token ，登录 Dashborad 网站后便可以使用所有功能了。 八. Heapster 插件部署安装 Heapster 可以为集群添加使用统计和监控功能，为 Dashboard 添加仪表盘。使用 InfluxDB 做为 Heapster 的后端存储，开始部署： 12345678mkdir -p ~/k8s/heapstercd ~/k8s/heapsterwget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yamlwget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yamlwget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yamlwget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yamlkubectl create -f ./ 最后确认所有的 pod 都处于 running 状态，打开 Dashboard，集群的使用统计会以仪表盘的形式显示出来。 注意事项1. 为何配置了科学上网也无法 pull gcr.io 的镜像？主机网络代理与 docker 的网络代理设置是不同的，你还需要设置 docker 的网络代理：为 Docker 配置网络代理 2. kubelet 服务不正常运行启动启动报错 单独使用 kubelet 服务后命令时 ，发现没有正常运行，日志报错如下：12345678910111213error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: &quot;cgroupfs&quot; is different from docker cgroup driver: &quot;systemd&quot;``` kubelet 的配置文件是`/etc/systemd/system/kubelet.service.d/10-kubeadm.conf`，请确保里面`KUBELET_CGROUP_ARGS=--cgroup-driver=systemd`的 `--cgroup-driver`驱动与 `docker info` 里的 `--cgroup-driver` 驱动相同。但即使确保了相同，独自执行`kubelet`命令时也会继续报同样的错。后来发现，该配置文件是在集群初始化时才会成功读取，而单独执行`kubelet`时不会读取配置文件。因此无视此问题即可，不影响集群初始化。在集群初始化成功后，可以发现`kubelet`服务是正常运行的。后来发现不影响集群初始化，且成功初始化可参考：[1.6.0 kubelet fails with error &quot;misconfiguration: kubelet cgroup driver: &quot;cgroupfs&quot; is different from docker cgroup driver: &quot;systemd&quot;](https://github.com/kubernetes/kubernetes/issues/43805)### 3. 运行 kubeadm init 时弹出警告警告如下： [preflight] Running pre-flight checks. [WARNING FileExisting-crictl]: crictl not found in system path12345经过 github 上的开发者确认，这个 warning 可以无视。### 4. 运行 kubeadm init 时报错报错如下所示： [kubelet-check] It seems like the kubelet isn’t running or healthy.[kubelet-check] The HTTP call equal to ‘curl -sSL http://localhost:10255/healthz‘ failed with error: Get http://localhost:10255/healthz: dial tcp [::1]:10255: getsockopt: connection refused.12345678经查资料发现是因为没有禁用 swap（每次机器重启会重置 swap），但是经过重置虚拟机网络以及恢复快照后得到的系统仍然会出现此错误。后来经过重新安装 kubeadm 与 kubelet 成功解决。### 5. 忘记了集群初始化成功时输出的参考命令如果不小心忘记了集群初始化成功时输出的参考命令，可使用以下命令来查询。查看 master 的 token： $ kubeadm token list | grep authentication,signing | awk ‘{print $1}’1查看 master 的 discovery-token-ca-cert-hash： $ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed ‘s/^.* //‘` 6. 为何设置了 NodePort 模式也无法从外部访问 Dashboard 网站？这是因为 Dashboard 配置文件默认采取了 HTTPS 协议，因此需要以 https://[NodeIP]:[NodePort] 的方式来访问。同时又因为 Chrome 浏览器不能支持访问未认证的 https 网站，所以建议使用其他浏览器（如 Firefox）。 部署总结从零开始学习使用 kubeadm 部署一个 k8s 集群总计花了我五天多时间，一开始大部分时间花在了如何下载合适版本的 kubeadm 和 kubelet，以及通过各种手段下载国内获取不到的镜像，但效果仍然不好。之后通过搭建 ShadowSocks 客户端使得可以成功下载合适版本的 kubeadm 和 kubelet，但发现还是 pull 不了镜像，最后发现是因为 Docker 的代理配置与主机的代理配置是不共用的。配置了 Docker 代理后便可以在初始化集群的过程中自动 pull 需要的镜像。通过使用翻墙代理，确实可以少花很多不必要的时间。 部署期间也遇到一些问题，有的是因为过于钻牛角尖，陷入到单独启动 kubelet 失败的问题中了，误以为该问题必须在集群初始化之前解决；有的是因为理论知识不扎实，对 Docker 的不了解；还有的是就是虚拟机网络配置突然变化导致的玄学和 Chrome 不支持不安全证书的 HTTPS 网站而导致的误判。 总而言之，以官方文档作为主线，配以他人博客上的成功部署经验，再加上使用翻墙代理，才能够又快又好地部署成功。此外，学会使用虚拟机的快照功能也是很重要的，方便进行重要操作前的备份。 参考资料Installing kubeadm （官网） Using kubeadm to Create a Cluster（官网） Dashboard: Creating sample user （Dashboard 的 github） 使用kubeadm安装kubernetes1.7/1.8/1.9 使用kubeadm安装Kubernetes 1.9（Dashboard） 使用kubeadm安装Kubernetes 1.8版本 使用 kubeadm 创建 kubernetes 1.9 集群 使用kubeadm在CentOS 7上安装Kubernetes 1.8（Dashboard） 参考资料 Installing kubeadm （来自官网） 使用kubeadm安装kubernetes1.7/1.8/1.9 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>kubernetes部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Notesby-CS-Notes.md]]></title>
    <url>%2FDocker-Notes-by-CS-Notes%2F</url>
    <content type="text"><![CDATA[一、解决的问题 二、与虚拟机的比较 三、优势 四、使用场景 五、镜像与容器 参考资料 一、解决的问题由于不同的机器有不同的操作系统，以及不同的库和组件，在将一个应用部署到多台机器上需要进行大量的环境配置操作。 Docker 主要解决环境配置问题，它是一种虚拟化技术，对进程进行隔离，被隔离的进程独立于宿主操作系统和其它隔离的进程。使用 Docker 可以不修改应用程序代码，不需要开发人员学习特定环境下的技术，就能够将现有的应用程序部署在其他机器中。 # 二、与虚拟机的比较虚拟机也是一种虚拟化技术，它与 Docker 最大的区别在于它是通过模拟硬件，并在硬件上安装操作系统来实现。 ## 启动速度启动虚拟机需要启动虚拟机的操作系统，再启动应用，这个过程非常慢；而启动 Docker 相当于启动宿主操作系统上的一个进程。## 占用资源虚拟机是一个完整的操作系统，需要占用大量的磁盘、内存和 CPU，一台机器只能开启几十个的虚拟机。而 Docker 只是一个进程，只需要将应用以及相关的组件打包，在运行时占用很少的资源，一台机器可以开启成千上万个 Docker。# 三、优势除了启动速度快以及占用资源少之外，Docker 具有以下优势：## 更容易迁移提供一致性的运行环境，可以在不同的机器上进行迁移，而不用担心环境变化导致无法运行。## 更容易维护使用分层技术和镜像，使得应用可以更容易复用重复部分。复用程度越高，维护工作也越容易。## 更容易扩展可以使用基础镜像进一步扩展得到新的镜像，并且官方和开源社区提供了大量的镜像，通过扩展这些镜像可以非常容易得到我们想要的镜像。# 四、使用场景## 持续集成持续集成指的是频繁地将代码集成到主干上，这样能够更快地发现错误。Docker 具有轻量级以及隔离性的特点，在将代码集成到一个 Docker 中不会对其它 Docker 产生影响。## 提供可伸缩的云服务根据应用的负载情况，可以很容易地增加或者减少 Docker。## 搭建微服务架构Docker 轻量级的特点使得它很适合用于部署、维护、组合微服务。# 五、镜像与容器镜像是一种静态的结构，可以看成面向对象里面的类，而容器是镜像的一个实例。镜像包含着容器运行时所需要的代码以及其它组件，它是一种分层结构，每一层都是只读的（read-only layers）。构建镜像时，会一层一层构建，前一层是后一层的基础。镜像的这种分层存储结构很适合镜像的复用以及定制。构建容器时，通过在镜像的基础上添加一个可写层（writable layer），用来保存着容器运行过程中的修改。 # 参考资料- DOCKER 101: INTRODUCTION TO DOCKER WEBINAR RECAP- Docker 入门教程- Docker container vs Virtual machine- How to Create Docker Container using Dockerfile- 理解 Docker（2）：Docker 镜像- 为什么要使用 Docker？- What is Docker- 持续集成是什么？[转自]: https://github.com/CyC2018/— 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal.### Ads这是小广告! 如果有需要, 不妨支持一下吧~&gt; 这些好书您看了吗?&gt; 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>CS-Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s基础教程]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2FKubernetes%E9%83%A8%E7%BD%B2%2Fk8s%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[K8S 集群的介绍、安装与配置（实践版）- [术语简介](#术语简介) 1. 事前准备 2. 配置 kubectl 与 Minikube 3. 安装 VirtualBox 4. 使用 Minikube 运行集群 5. 在集群上部署应用 6. 查看 Pod 与 Node 7. 部署 Service 8. 调整应用规模 9. 执行滚动更新 注意事项 参考资料 Ads K8S 集群的介绍、安装与配置（实践版）k8s 集群由一个 master 节点与多个 node 节点组成，所有节点均是在逻辑上独立的一个机器 。master 节点是管理整个集群的节点，而 node 节点是具体执行业务的节点，每个 node 都有一个 kubelet 作为其代理用于与 master 通信。 而在本教程中，我们介绍 k8s 集群的基本操作：将会在本地机器上部署一个单 Node 的 k8s 集群，并尝试在该集群上部署一个应用、配置暴露应用的服务、以及对应用进行规模调整与版本更新。 术语简介kubectl 是 k8s 的命令行管理工具，管理 k8s 集群需要通过该系列命令进行。 Minikube 是一个用于在本地上运行 kubernates 的工具插件。Minikube 可在本地机器上创建一个虚拟机（需要安装对应的虚拟机驱动，如 VirtualBox、KVM 等），从而运行一个单节点的 k8s 集群。原理图如下： VirtualBox 是一款支持 x86 和 AMD64/Intel64 的开源虚拟机软件，支持 Window、Linux 等系统。在本教程中，我们把它作为 Minikube 的虚拟机驱动。 1. 事前准备 准备好一台操作系统为 Linux CentOS 7 系统、内存为 4G 以上的虚机（或物理机），完成换源与关闭防火墙和 SELinux 需要在虚机上安装 VirtualBox 或 KVM 作为虚拟化软件（本教程介绍 VirtualBox 的安装） 设置 CPU 支持虚拟化 VT-X（若是物理机则在BIOS上设置，若是虚机则在VMware里设置 ） 2. 配置 kubectl 与 Minikube下载 kubectl 并配置到系统路径：123$ curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.9.1/bin/linux/amd64/kubectl$ chmod +x ./kubectl$ sudo mv ./kubectl /usr/local/bin/ 注意 kubectl 的版本必须新于 k8s 服务器的版本，否则会出现校验错误。可通过 curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt 命令查询当前的最新稳定版本。 下载 Minikube 并配置到系统路径：123$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 $ chmod +x ./minikube$ sudo mv ./minikube /usr/local/bin/ 注意：由于本节所述的下载网址有时会无法通过 curl 命令访问，因此建议直接下载 kubectl 或 minikube 到本地再上传到虚机中。也可以通过其他途径如 minikube 的 github 下载地址 进行下载。 3. 安装 VirtualBox本教程中 minikube 的虚拟机采用 VirtualBox ，安装步骤如下： 在官网下载对应系统的 VirtualBox rpm 包 安装 VirtualBox 的依赖包：yum install qt qt-x11 gcc gcc-c++ kernel-devel perl SDL 安装 VirtualBox：rpm -i VirtualBox-5.2-5.2.6_120293_el7-1.x86_64.rpm 添加当前用户到 VirtualBox 创建的用户组 “vboxusers”：usermod -a -G vboxusers 在 Linux 下，Minikube 也支持 –vm-driver=none 选项来在本机运行 Kubernetes 组件（此种方式尚未实验）。 4. 使用 Minikube 运行集群执行 minikube start 启动本地 k8s 集群。当正常启动成功时，出现以下输出：12345678910111213Starting local Kubernetes v1.8.0 cluster...Starting VM...Downloading Minikube ISO 140.01 MB / 140.01 MB [============================================] 100.00% 0sGetting VM IP address...Moving files into cluster...Downloading localkube binary 148.25 MB / 148.25 MB [============================================] 100.00% 0sConnecting to cluster...Setting up kubeconfig...Starting cluster components...Kubectl is now configured to use the cluster.Loading cached images from config file. 执行 minikube status 可查看当前集群状态，输出类似如下所示：123minikube: Runningcluster: Runningkubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100 使用 kubectl version 可查看当前的 k8s 集群的客户端与服务端的版本；使用 kubectl cluster-info 可查看集群的详细部署情况；使用 kubectl get nodes 查看集群节点情况。 5. 在集群上部署应用部署文件（Deployment）是用于指导 k8s 集群如何创建与维护应用实例的。 kubectl run 命令用于创建一个新的 Deployment，此命令需要提供 Deployment 的命名以及 app 镜像的地址。1234# 若需要在特定端口运行app，则用 --port 指明运行端口$ kubectl run kubernetes-bootcamp --image=docker.io/jocatalin/kubernetes-bootcamp:v1 --port=8080# 创建完成后可以查询 Deployment$ kubectl get deployments Pod 是 k8s 集群管理的基本单位。当一个 Deployment 创建后，集群将会创建一个 Pod 来管理应用实例。一个 Pod 是一个 k8s 抽象，代表了一组（一个或多个）应用容器，且这些容器之间共享存储、网络等资源。 默认情况下，集群中的 Pods 对外部网络是不可见的，但 kubectl 可以创建一个能够转发请求到集群端私有网络的代理：kubectl proxy，执行后的输出类似如下（注意当前终端会阻塞）：12$ kubectl proxyStarting to serve on 127.0.0.1:8001 通过使用 kubectl proxy 所展示的地址，我们就可以直接访问 k8s API，例如 curl http://127.0.0.1:8001/version 就可获取当前 API Server 的版本。 API Server 会自动根据 pod 的名字来为每个 pod 创建一个访问点（endpoint），该访问点也可以通过 proxy 来直接访问：123$ export POD_NAME=$(kubectl get pods -o go-template --template &apos;&#123;&#123;range .items&#125;&#125;&#123;&#123;.metadata.name&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&apos;)$ echo Name of the Pod: $POD_NAME$ curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/$POD_NAME/ 6. 查看 Pod 与 Node一个 Pod 运行于一个 Node 上，Node 则是 k8s 集群中的执行业务的逻辑主机（虚拟机或者物理机），由 master 进行管理。一个 Node 可以拥有多个 Pod，且 master 可以在集群中的多个 node 之间自动调度 Pod。示意图如下： 常用的查询应用的命令包括： kubectl get ： 列出资源 kubectl describe : 展示资源详情 kubectl logs : 打印某个 Pod 中的一个容器的日志 kubectl exec : 在一个 Pod 中的一个容器中执行命令 7. 部署 Service一个 Service 是集群中的一个抽象，它定义了一组逻辑相关的 Pods 以及如何访问它们的策略。Services 允许独立的 Pods 间的松耦合。 Service 使用标签（Label）和选择器（Selector）来匹配一组 Pods。 尽管每个 Pod 都有自己独立的 IP，但是这些 IP 要是没有 Service 就无法被外部网络访问。Service 有以下配置模式： ClusterIP（默认）： 赋予 Service 一个集群内部 IP 。这种模式使得服务只能在集群内可被访问。 NodePort：通过 NAT 允许 Service 使用集群内一个 Node 的 IP。从而就可以使用 \&lt;NodeIP>:\&lt;NodePort> 的方式让该 Service 可被集群外部访问。 LoadBalancer：创建一个外部负载均衡器，并赋予 Service 一个固定的外部 IP。 ExternalName：不使用代理，赋予 Service 一个任意的名字（由配置文件中的 externalName 参数决定） 以下命令可创建一个名为 “kubernetes-bootcamp” 的 NodePort 模式的 Service（其对外部网络可见）。再使用 describe service 命令可查看某个 Service 的详情：12$ kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080$ kubectl describe services/kubernetes-bootcamp 可设置环境变量 NODE_PORT，通过 \&lt;NodeIP>:\&lt;NodePort> 从外网访问该 Service：123$ export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=&apos;&#123;&#123;(index .spec.ports 0).nodePort&#125;&#125;&apos;)$ echo NODE_PORT=$NODE_PORT$ curl host01:$NODE_PORT 接下来介绍 Label（标签）的使用。Deployment 会自动为 Pod 创建一个 Label，使用kubectl describe可以查看 Label 名字。使用带参的 kubectl get 命令可以查询特定 Label 的 Pod 或 Service。12$ kubectl get pods -l run=kubernetes-bootcamp$ kubectl get services -l run=kubernetes-bootcamp 使用 kubectl label 命令为 Pod 增加一个新 Label 后，可用kubectl describe查询该 Pod 是否已有新 Label：1234$ export POD_NAME=$(kubectl get pods -o go-template --template &apos;&#123;&#123;range .items&#125;&#125;&#123;&#123;.metadata.name&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&apos;)$ echo Name of the Pod: $POD_NAME$ kubectl label pod $POD_NAME app=v1$ kubectl describe pods $POD_NAME 删除一个指定标签的 Service，之后便可测试到外部无法再通过 NodeIP 的方式访问到 app 了，但 app 仍在 Pod 中运行：123$ kubectl delete service -l run=kubernetes-bootcamp$ curl host01:$NODE_PORT$ kubectl exec -ti $POD_NAME curl localhost:8080 8. 调整应用规模在之前的章节中，Deployment 只创建了一个 Pod 来运行应用，但当通信量增加时，就需要扩展应用数量来满足需求。实现的主要方式则是改变 Deployment 配置中的副本数量。应用规模变化的示意图如下： 若当前集群已有一个 Deployment（假设名为”kubernetes-bootcamp”），则可使用kubectl scale命令来扩展副本数量到 4 个，之后便可以检查到 pods 数量发生了变化。同时该变化也被 Deployment 记录到日志，可在详情中查看。1234$ kubectl scale deployments/kubernetes-bootcamp --replicas=4$ kubectl get deployments$ kubectl get pods -o wide$ kubectl describe deployments/kubernetes-bootcamp 9. 执行滚动更新通常用户希望应用可一直被访问，而开发者希望应用可短时间内更新多次。而滚动更新能满足该要求，允许应用以零停机时间进行部署更新（通过新增的 Pods 来更新 Pods 实例）。默认情况下，更新过程中不可用 Pods 的最大数量与新创建 Pods 的最大数量相等。k8s 集群也可以回滚该更新。 使用set image命令可进行镜像更新，rollout status命令可进行更新确认提交，rollout undo可进行更新回滚。123$ kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2$ kubectl rollout status deployments/kubernetes-bootcamp$ kubectl rollout undo deployments/kubernetes-bootcamp 注意事项 机器的内存必须在4G以上，否则启动 VirtualBox 时会失败 使用 curl 下载时，偶尔会因为网速问题无法下载成功。此时应当通过其他方式下载文件然后手动上传到系统中 启动 minikube 时可能会存在 localkube 找不到对应文件的情况，这是因为 localkube 的镜像下载不成功。 参考资料Running Kubernetes Locally via Minikube（来自官网） Minikube：使用 Kubernetes 进行本地开发 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>kubernetes部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS+Keepalived双机热备方案]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2F%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%2FLVS%2BKeepalived%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[LVS + keepalived 双机高可用部署方案（CentOS） 前期准备 web 节点配置 LVS 节点配置 测试 参考文档 Ads LVS + keepalived 双机高可用部署方案（CentOS）前期准备准备四台虚机，分别记作 LVS-master、LVS-slave、web-node1、web-node2。前两者作为 LVS 负载均衡调度器，后两者是提供应用服务的 web 服务器。 安装epel-realease源，关闭所有虚机的防火墙与 SELinux，编辑所有节点的/etc/hosts文件设置主机名互相解析。使用yum install ntpdate安装 ntpdate，并通过ntpdate 202.120.2.101命令进行时间同步。 202.120.2.101 是上海交通大学网络中心 NTP 服务器的地址 web 节点配置在两台 web 机上开启 httpd 服务，并编辑 Real Server （真实服务器，简称 RS）用于绑定 VIP （虚拟 IP）脚本realserver.sh如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash # # Script to start LVS DR real server. # description: LVS DR real server # . /etc/rc.d/init.d/functionsVIP=192.168.18.200 # 在此处设置VIP host=`/bin/hostname`case &quot;$1&quot; in start) # Start LVS-DR real server on this machine. /sbin/ifconfig lo down /sbin/ifconfig lo up echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce /sbin/ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up /sbin/route add -host $VIP dev lo:0;; stop) # Stop LVS-DR real server loopback device(s). /sbin/ifconfig lo:0 down echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce;; status) # Status of LVS-DR real server. islothere=`/sbin/ifconfig lo:0 | grep $VIP` isrothere=`netstat -rn | grep &quot;lo:0&quot; | grep $VIP` if [ ! &quot;$islothere&quot; -o ! &quot;isrothere&quot; ];then # Either the route or the lo:0 device # not found. echo &quot;LVS-DR real server Stopped.&quot; else echo &quot;LVS-DR real server Running.&quot; fi ;; *) # Invalid entry. echo &quot;$0: Usage: $0 &#123;start|status|stop&#125;&quot; exit 1 ;; esac 使用 chmod +x realserver.sh命令给脚本文件添加执行权限，并通过/.realserver.sh start命令启动该脚本的服务。该服务的作用是使 RS 的网卡与 VIP 进行绑定，从而可允许 RS 处理来自负载调度器转发的请求（DR 模式）。启动该服务后可用ifconfig命令查看是否已绑定 VIP。 LVS 节点配置LVS 节点使用yum install keepalived ipvsadm命令安装 keepalived 服务与 LVS 服务。 配置文件的路径是/etc/keepalived/keepalived.conf。keepalived 配置文件以 block 形式组织，每个块内容都包含在{}中。keepalived 配置分为三类： 全局配置：对整个 keepalived 都生效的配置 VRRPD 配置：核心配置，主要实现高可用功能 LVS 配置：LVS 相关功能的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091####################### 全局配置（大部分选项为邮件通知服务的参数。可设置为空）######################global_defs &#123; # global_defs 全局配置标识 -------------------------------------- notification_email &#123; # notification_email用于设置报警邮件地址 acassen@firewall.loc # 可以设置多个，每行一个 failover@firewall.loc # 设置邮件报警，需开启本机Sendmail 服务 sysadmin@firewall.loc # yum -y install mailx sendmail &#125; -------------------------------------- notification_email_from 233@qq.com # 设置邮件发送地址 smtp_server 192.168.200.1 # 设置邮件的smtp server地址 smtp_connect_timeout 30 # 设置连接smtp sever超时时间 router_id LVS_DEVEL # 表示运行keepalived服务器标识 # 发邮件时会显示在邮件主题中&#125;####################### VRRPD配置######################vrrp_instance VI_1 &#123; # VRRPD 配置标识 VI_1是实例名称 state MASTER # 指定Keepalvied角色。 # MASTER表示此主机为主服务器，BACKUP则是表示为备用服务器 interface eth0 # 指定HA监测网络的接口。检查是否与ifconfig命令查看的网卡名称一致。 virtual_router_id 51 # 虚拟路由标识，标识为数字，同一个VRRP实例使用唯一的标识 # 即可表示在同一个vrrp_instance下 MASTER_ID = BACKUP_ID priority 100 # 定义节点优先级，数字越大表示节点的优先级越高 # 同一个VRRP_instance下 # 必须 MASTE_PRIORITY &gt; BACKUP_PRIORITY advert_int 1 # 设定MASTER与BACKUP主机质检同步检查的时间间隔，单位为秒 authentication &#123; # 设定节点间通信验证类型和密码，验证类型主要有PASS和AH两种 auth_type PASS # 同一个vrrp_instance，MASTER验证密码和BACKUP保持一致 auth_pass 1111 &#125; virtual_ipaddress &#123; # 设置虚拟IP地址 (VIP)，也可仅设置一个 192.168.200.16 192.168.200.17 192.168.200.18 &#125;&#125;####################### LVS配置######################virtual_server 192.168.18.200 80 &#123; # virtual_server LVS配置标识 # 格式：virtual_server [VIP] [port] delay_loop 6 # 设置健康检查时间间隔，单位为秒 lb_algo rr # 设置负载调度算法，可用的调度算法有：rr、wlc、lc、lblc、sh、dh等 lb_kind DR # 设置LVS实现负载均衡的机制，有NAT、TUN和DR三种模式可选 nat_mask 255.255.255.0 # NAT子网掩码 persistence_timeout 50 # 会话保持时间 protocol TCP # 指定转发协议类型 #---------------------------------------------------------------------------------# persistence_timeout 会话保持时间对动态网页非常有用，为集群系统中的seesion共享提供了一个很好的解决方案# 用户的请求会一直分发到某个服务节点，直至超过这个会话的保持时间（指最大无响应超时时间）# =[用户操作动态页面如果在50s没有执行任何操作则被分发到另外的节点]#--------------------------------------------------------------------------------- real_server 192.168.18.201 80 &#123; # 设置real server段开始的标识 [IP为真实IP地址] weight 1 # 用于配置real server节点的权值，数字越大，权值越高 # 设置权值大小可以为不同性能的服务器分配不同的负载 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 1 &#125; &#125; real_server 192.168.18.202 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 1 &#125; &#125; &#125; keepalived 的配置文件路径在/etc/keepalived/keepalived.conf。LVS-master 与 LVS-slave 的配置文件除了 VRRPD 配置中的状态与优先级这两个参数不同外，其他参数应当相同。 配置完成后，启动 LVS-master 与 LVS-slave的 keepalived 服务：service keepalived start，并可使用ipvsadm -L -n命令查看 LVS 状态。 Tips：可使用service keepalived status命令查看 keepalived 服务的 log。 测试通过关闭与开启 LVS-master 的 keepalived 服务，观察 VIP 在 LVS 节点上的浮动情况。通过关闭与开启某一个 web 节点的 web 服务，观察集群的高可用是否生效。 参考文档实验步骤参考：Linux 高可用集群之keepalived详解详细配置参数参考：Keepalived 工作原理及简要安装 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>集群高可用方案</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask-Web工程手册-README]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2FREADME%2F</url>
    <content type="text"><![CDATA[Flask-Web工程手册-README Ads Flask-Web工程手册-README ch1-创建Python虚拟环境 ch2-Flask项目基本部署 ch3-Flask常用扩展插件 ch4-Linux服务器部署 ch5-使用lsyncd进行文件实时备份 ch6-配置集群共享文件NFS服务器 ch7-Nginx安装与重写URL-CentOS7 ch8-高可用与负载均衡集群部署-Ubuntu … 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch1-创建Python虚拟环境]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch1-%E5%88%9B%E5%BB%BAPython%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[使用 virtualenv 虚拟环境 需求文件的创建及使用 Ads 使用 virtualenv 虚拟环境virtualenv 是 Python 的虚拟环境，可以在同一台 PC 上隔离不同的开发环境。主要用于为不同的项目构建独立与隔离的三方库依赖。 在系统中安装 virtualenv：pip install virtualenv 在项目目录中建立 virtualenv 虚拟环境：virtualenv [环境名] 启动虚拟环境： env_dir\Scripts\activate(Windows) # source env_dir/bin/activate(Linux) 退出虚拟环境： deactivate Note：python3 中有内置的虚拟环境，使用python -m venv [环境名]命令即可创建 需求文件的创建及使用Python项目中往往必须包含一个 requirements.txt 文件，用于记录所有依赖包及其精确的版本号，以便在新环境中部署。 在虚拟环境中使用 pip 生成需求文件： (venv) $ pip freeze &gt; requirements.txt 安装或升级包后，最好更新该文件。 按照需求文件上的所列项，安装依赖包： (venv) $ pip install -r requirements.txt 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch2-Flask项目基本部署]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch2-Flask%E9%A1%B9%E7%9B%AE%E5%9F%BA%E6%9C%AC%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Flask 项目基本部署 环境安装 目录结构 配置文件详解 config.py app/init.py manage.py Ads Flask 项目基本部署Flask 项目没有固定的目录配置，因此在此介绍一个对 Flask 进行基本部署的教程。 环境安装首先使用 virtualenv 构建好虚拟的 python 依赖环境，并安装必要的 Flask 依赖包，比如： flask：Flask 框架的基础库 mysql-python：处理与数据库的底层交互 SQLAlchemy：一个 ORM 框架，用于处理数据库与对象之间的映射 Flask-SQLAlchemy：简化在 Flask 中 SQLAlchemy 的 使用 Flask-Script：为 Flask 程序提供了命令行模式 Flask-Migrate：数据库迁移工具 Flask-Login：封装用户会话管理 其他功能性的扩展插件可选择安装，比如： flask-mail：用于管理邮件自动发送 Flask-babel：实现语言互相转换的翻译工具 Werkzeug： 计算密码散列值并进行核对 Flask-WTF： Web 表单 目录结构初始目录结构如下图所示： Flask 程序一般都保存在名为 app 的文件夹中 migrations 文件夹包含数据库迁移脚本 venv 文件夹包含 Python 虚拟环境 requirements.txt 列出了所有依赖包，便于项目迁移时重新生成相同的虚拟环境； config.py 存储配置参数，如数据库账户密码等 manage.py 用于通过命令行启动程序的脚本 配置文件详解config.pyconfig.py 是初始化 Flask app 的配置文件，主要包括多种模式下的配置类型和全局参数（如密钥、连接数据库的 URL） 等。此外需注意的是，敏感数据不能直接写入，应从操作系统的环境变量中读取。12345678910111213141516171819202122232425262728import osbasedir = os.path.abspath(os.path.dirname(__file__))class Config: def __init__(self): pass @staticmethod def init_app(app): passclass DevelopmentConfig(Config): def __init__(self): pass DEBUG = True SQLALCHEMY_DATABASE_URI = (os.environ.get(&apos;DEV_DATABASE_URL&apos;) or &apos;mysql://root:123456@localhost/lancs&apos;)class ProductionConfig(Config): def __init__(self): pass SQLALCHEMY_DATABASE_URI = (os.environ.get(&apos;DEV_DATABASE_URL&apos;) or &apos;mysql://root:123456@localhost/lancs&apos;)config = &#123; &apos;development&apos;: DevelopmentConfig, &apos;production&apos;: ProductionConfig, &apos;default&apos;: DevelopmentConfig&#125; app/init.pyapp/init.py 是程序包的构造文件，主要包括创建 flask app 的工厂函数。配置 Flask 扩展插件时往往在工厂函数中对 app 进行相关的初始化。123456789101112131415161718from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyfrom config import configdb = SQLAlchemy()def create_app(config_name): app = Flask(__name__) app.config.from_object(config[config_name]) config[config_name].init_app(app) db.init_app(app) # Register all the filter. from .main import main as main_blueprint app.register_blueprint(main_blueprint) return app manage.pymanage.py 是使用命令行启动服务进程、数据库迁移的脚本文件。12345678910111213import osfrom Lancs import create_app, dbfrom flask_script import Managerfrom flask_migrate import Migrate, MigrateCommandapp = create_app(os.getenv(&apos;LANCS_CONFIG&apos;) or &apos;default&apos;)manager = Manager(app)migrate = Migrate(app, db)manager.add_command(&apos;db&apos;, MigrateCommand)if __name__ == &apos;__main__&apos;: manager.run() 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch3-Flask常用扩展插件]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch3-Flask%E5%B8%B8%E7%94%A8%E6%89%A9%E5%B1%95%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Flask 常用扩展插件 Flask-SQLAlchemy 初始化应用 模型声明 Flask-Script 与 Flask-Migrate MySQL-python 参考文章 Flask-Login 初始化应用 相关配置 使用方法 Flask_Babel 初始化应用 配置参数 生成翻译模板 创建翻译文本 编译 修改翻译 Flask-Mail 初始化应用 参数配置 发送邮件 自定义模板过滤器 Flask 常用扩展插件仅仅靠 Flask 基础库的功能是不够的，Flask 拥有多种扩展插件来实现各种模块化的功能。以下按照常用的配置目录，来介绍 Flask 中较为常见的功能插件。 Flask-SQLAlchemy一个从模型到数据库的映射框架，在 Flask 中提供了模型以及数据库操作。 初始化应用1234567891011121314# app/init.pyfrom flask import Flaskfrom flask_sqlalchemy import SQLAlchemyfrom config import config# 由于是全局的实例，此后其他模块引入需SQLAlchemy时只需引入db即可db = SQLAlchemy() def create_app(config_name): app = Flask(__name__) app.config.from_object(config[config_name]) config[config_name].init_app(app) db.init_app(app) 模型声明123456789101112# app/models.pyfrom . import dbclass User(db.Model): __tablename__ = &apos;users&apos; # 将创建的数据库的实际表名 id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(80), unique=True) email = db.Column(db.String(120), unique=True) def __init__(self, username, email): self.username = username self.email = email 详细的模型关系说明请看 Flask sqlalchemy 数据库操作文档 。 Flask-Script 与 Flask-MigrateFlask-Script 为 Flask 提供了可通过外部脚本使用命令行运行程序的功能，如启动服务、数据库迁移、在环境上下文中启动 shell 等。而 Flask-Migrate 用于进行数据库迁移。1234567891011121314# manage.pyimport osfrom app import appfrom flask_script import Managerfrom flask_migrate import Migrate, MigrateCommandmanager = Manager(app)migrate = Migrate(app, db)manager.add_command(&apos;db&apos;, MigrateCommand)if __name__ == &apos;__main__&apos;: manager.run() 数据库迁移的命令主要包括： 初始化迁移库：# python manage.py db init 创建迁移脚本：# python manage.py db migrate 更新数据库：# python manage.py db upgrade MySQL-pythonMySQL-python 是 python 环境与 mysql 数据库的底层交互接口。作为一个必需库，在安装时经常会遇到安装失败的情况。因此一般是在 windows 开发环境下使用 exe 进行安装后再把库文件复制到已部署项目的虚拟环境中。 在 centos 系统中使用 pip 安装 MySQL-python 时遇到的一些问题的解决方法： 执行pip install mysql-python时，报错 EnvironmentError: mysql_config not found ，解决方法为：yum install mysql-devel 再次执行pip install mysql-python安装时，仍然报错error: command &#39;gcc&#39; failed with exit status 1， 解决方法：yum install gcc python-devel 参考文章centos下pip安装mysql_python Flask-LoginFlask-Login 为 Flask 提供了会话管理。它处理日常的登入、登出并长期保留用户会话。 初始化应用Flask-Login 最重要的部分就是登录管理器类 LoginManager ，实例化后对应用进行初始化。1234567891011# app/init.pyfrom flask_login import LoginManagerlogin_manager = LoginManager()login_manager.init_app(app)#设置会话保护强度：None、&quot;basic&quot; 或 &quot;strong&quot;login_manager.session_protection = &apos;strong&apos;#设置登录视图login_manager.login_view = &apos;user.signin&apos; 相关配置需要设置一个 user_loader 回调函数，这个函数用于从会话中存储的用户 ID 重新加载用户对象（注意：如果 ID 无效，它应该返回 None，而不是抛出异常），如：123@login_manager.user_loaderdef load_user(userid): return User.get(userid) 使用方法当用户通过验证后，用 login_user 函数来登入他们：123456789@app.route(&quot;/login&quot;, methods=[&quot;GET&quot;, &quot;POST&quot;])def login(): form = LoginForm() if form.validate_on_submit(): # login and validate the user... login_user(user) flash(&quot;Logged in successfully.&quot;) return redirect(request.args.get(&quot;next&quot;) or url_for(&quot;index&quot;)) return render_template(&quot;login.html&quot;, form=form) 可以通过 current_user 代理访问当前会话中已登录的用户。但当用户未登录时，current_user 被设置为一个 AnonymousUser 对象，它包含下列属性： is_active 和 is_authenticated 返回 False is_active 返回 True get_id 返回 None。 需要用户登入的视图可以用 login_required 装饰器来装饰，被 login_required 装饰器拦截的请求会跳转到登录视图。当重定向到登入视图，请求字符串中往往会额外设置一个 next 变量，值为用户之前试图访问的页面。1234@app.route(&quot;/settings&quot;)@login_requireddef settings(): pass 当用户要登出时：12345@app.route(&quot;/logout&quot;)@login_requireddef logout(): logout_user() return redirect(somewhere) Flask_BabelFlask_Babel 是 Flask 的翻译扩展工具，可配置指定文字的翻译文本。 初始化应用使用命令$ pip install Flask-Babel进行安装。 在完成 app 的基本配置初始化后，使用 Babel 对 app 进行初始化：1234567from flask import Flaskfrom config import configfrom flask_babel import Babelapp = Flask(__name__)app.config.from_object(config[config_name])babel = Babel(app) 配置参数首先在 app 的 config 中设置 Babel 的配置参数，分别代表翻译文本的默认语言以及其默认时区。12BABEL_DEFAULT_LOCALE = &apos;zh&apos;BABEL_DEFAULT_TIMEZONE = &apos;CST&apos; 在 app 目录下创建配置文件 babel.cfg，用于设置 babel 要从哪些位置搜索需翻译的字符串：123[python: **.py][jinja2: **/templates/**.html]extensions=jinja2.ext.autoescape,jinja2.ext.with_ 生成翻译模板使用# pybabel extract -F babel.cfg -o messages.pot .命令生成翻译模板messages.pot。该模板自动查找 babel.cfg 中所配置的区域中需要翻译的字符串。 创建翻译文本使用# pybabel init -i messages.pot -d translations -l zh创建中文翻译。这句命令会在 app 主目录中生成一个 translations 目录。要确保 flask 能找到翻译内容，translations 目录要和 templates 目录在同一个目录中。接下来我们就可以进行翻译了，修改 translations/zh_Hans_CN/LC_MESSAGES/messages.po文件添加翻译文本。 编译翻译完后执行命令# pybabel compile -d translations进行编译，编译结果为 message.mo 文件。编译成功后，即可在应用的网页上看到翻译后的文本。 修改翻译有时我们需要对程序和模板做修改，翻译也要随之更新。更新后需要用前面的命令重新生成 messages.pot 文件，然后使用命令# pybabel update -i messages.pot -d translations将更新的内容 merge 到原来的翻译中，最后再到对应 locale 的文件夹下更新翻译并 compile 即可。 若只是修改翻译文本而未更改程序和模板，则只需修改 messages.po 文件里的文本后重新编译即可。 Flask-MailFlask-Mail 用于自动发送邮件。 初始化应用12345# app/init.pyfrom flask_mail import Mailmail = Mail()mail.init_app(app) 参数配置可参考 Flask-Mail 文档 进行如下内置参数配置：12345678# config.py# If use QQ email, please see http://service.mail.qq.com/cgi-bin/help?id=28 firstly.MAIL_SERVER = &apos;smtp.sina.com&apos;MAIL_PORT = 465MAIL_USE_SSL = TrueMAIL_USERNAME = os.environ.get(&apos;MAIL_USERNAME&apos;) or &apos;milanlanlanlan@sina.com&apos;MAIL_PASSWORD = os.environ.get(&apos;MAIL_PASSWORD&apos;) or &apos;1970025901a&apos; 除了设置参数以外，还应当确保邮件服务器可提供服务。 发送邮件为了能够发送邮件，首先需要创建一个 Message 实例: 123456from flask_mail import Message@app.route(&quot;/&quot;)def index(): msg = Message(&quot;Hello&quot;, # 此处构造函数的首个参数的值&quot;Hello&quot;是邮件标题 sender=&quot;from@example.com&quot;, recipients=[&quot;to@example.com&quot;]) 可设置一个或者多个收件人:12msg.recipients = [&quot;you@example.com&quot;]msg.add_recipient(&quot;somebodyelse@example.com&quot;) 若设置了 MAIL_DEFAULT_SENDER，就不必再次填写发件人，默认情况下将会使用配置项的发件人。 邮件内容可以直接包含 body 或者包含 HTML:12msg.body = &quot;testing&quot;msg.html = &quot;&lt;b&gt;testing&lt;/b&gt;&quot; 最后，发送邮件的时候请使用 Flask 应用设置的 Mail 实例:mail.send(msg) 自定义模板过滤器为了使视图层和控制层解耦，往往使用自定义的模板过滤器，而不是在控制层中增加逻辑。 ` app/util/init.pyfrom flask import Blueprintfilter_blueprint = Blueprint(‘filters’, name) Register all the filter.往往不是把所有过滤器写入同一个文件中，而是分多个文件，然后在本文件中用 import 引用。@filter_blueprint.app_template_filter(‘reversel’)def reverse_filter(s): return s[::-1] 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch4-Linux服务器部署]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch4-Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Linux服务器部署 初始化服务器 安装MySQL 导出数据库（sql脚本） 导入数据库（sql脚本） 参考文章 在 CentOS 上安装 mysql-python 设置远程访问 MySQL 安装 virtualenv 参考文章 开放端口 使用 supervisor 维护服务进程 使用 gunicorn 作为 Web 服务器 gevent Ads Linux服务器部署初始化服务器首先需安装 Linux 操作系统并对其进行初始化配置。具体步骤请参见该文章：配置虚拟云主机(CentOS 7) 此外，最好不要用 root 账户直接进行操作，应当设置一个拥有 sudo 权限的新用户，使用该用户进行服务器的操作。 教程：添加一个新用户并授权 安装MySQL在 CentOS 7和 CentOS 7.1系统中，默认安装的 mysql 是它的分支 mariadb ，因此需要从 mysql 的官网中下载。 下载 Yum Repo：从 mysql官方下载地址 获取 Yum Repo，并使用yum install命令进行安装该 Repo：# yum -y install mysql57-community-release-el7-7.noarch.rpm。完成后可以用# yum list | grep mysql来查看可安装的 mysql 包。 安装 MySQL 数据库的服务器版本：# yum install mysql-community-server 启动服务：# service mysqld start，并可用# service mysqld status查看服务状态。 获取初始密码：使用YUM安装并启动MySQL服务后，MySQL进程会自动在进程日志中打印 root 用户的初始密码。使用grep &quot;password&quot; /var/log/mysqld.log可查看日志中的MySQL root 密码。 修改root用户密码：使用# mysql -uroot -p并输入密码后进入 mysql 终端，再使用mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;new password&#39;;命令修改 mysql 的密码。 注意：如果装的 mysql 版本是5.7，则可能出现修改密码时报错ERROR 1819 (HY000): Your password does not satisfy the current policy requirements，这是因为新密码安全性较低。可使用mysql&gt; set global validate_password_policy=0;降低密码安全等级后解决。 mariadb 是 mysql 的一个分支版本，与 mysql 不能同时安装，但是接口与 mysql 完全兼容。当数据库需要迁移到 mariadb 时，可能会出现ImportError: libmysqlclient.so.18的错误，解决方法为’pip install mysql-client’（这里很奇怪，如果是 mysql 数据库的话不用安装 mysql-client 也可以）。 导出数据库（sql脚本）mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名 例如：mysqldump -u root -p db_name &gt; test_db.sql 导入数据库（sql脚本）使用mysql -u root -p命令进入 MySQL 后：12mysql&gt; use test;mysql&gt; source c:/test.sql 参考文章CentOS 7.2使用yum安装MYSQL 5.7.10 阿里云CentOS 7.1使用yum安装MySql 5.6.24 修改MySQL 5.7.9版本的root密码方法以及一些新变化整理 在 CentOS 上安装 mysql-python在 CentOS 下用pip install mysql-python命令直接安装时会出现找不到mysql_config、gcc等错误，解决方案是安装mysql(或mariadb)的devel包(如mysql-devel或mariadb-devel)，以及安装python的devel包。 设置远程访问 MySQLlinux 上的 mysql 数据库都是默认仅允许本地访问。设置 mysql 为远程访问，可以供开发者在本地使用数据库可视化工具远程连接而不用通过 ssh。 在shell中，$mysql -r -u root -p 输入密码后进入 mysql 数据库。 1234mysql&gt;use mysql;mysql&gt;update user set host = &apos;%&apos; where user = &apos;root&apos;; //这个命令执行错误时可略过mysql&gt;flush privileges;mysql&gt;select host, user from user; //检查‘%’ 是否插入到数据库中 找到文件/etc/mysql/my.cnf 修改 bind-address = 0.0.0.0 之后，重启 mysql 进程：$service mysqld restart。 安装 virtualenv首先需安装 python-pip ，若提示没有包可安装，则使用命令# yum -y install epel-release安装扩展仓库后再使用 yum 进行安装。使用 pip 安装 virtualenv：# pip install virtualenv。 使用virtualenv命令创建python虚拟环境：# virtualenv [虚拟环境名称]，之后在本地会生成一个与虚拟环境同名的文件夹。默认情况下虚拟环境不会依赖系统环境的global site-packages，如果想依赖系统环境的第三方软件包，也可以使用参数–system-site-packages。 进入虚拟环境目录，启动虚拟环境，如下：1234[root@localhost ~]# cd env1/[root@localhost env1]# source bin/activate(env1)[root@localhost env1]# python -VPython 2.7.8 部署服务时，可直接把开发者 windows 本地的虚拟环境下的 /Lib/site-packages 复制到 Linux 系统里的虚拟环境中，有些出于 python 版本不同导致的兼容问题可通过重新下载库来解决。 参考文章使用 virtualenv 搭建独立的 Python 环境 开放端口如果系统的防火墙开启，则需要设置防火墙开放端口。若没有启动防火墙服务，则默认开放所有端口。 当使用脚本启动 flask 服务时可以指定 Host 和 端口：# python manage.py runserver -h 0.0.0.0 -p 80（使用80端口时需要 root 权限） 使用 supervisor 维护服务进程supervisor 是用 Python 开发的一套通用的 Linux 进程管理程序，能将一个普通的命令行进程变为后台 daemon，并监控进程状态，使其异常退出时能自动重启。 首先使用# yum install supervisor命令安装 supervisor 。查看配置文件/etc/supervisord.conf，检查项 [include] 里的应用配置文件应放置在哪个目录，然后在指定目录下新建应用配置文件：1234[program:app] # app 为具体用户名command=python manage.py runserver -h 0.0.0.0 -p 5000 # 启动命令，与手动启动命令一样directory=/home/netlab301/lancs # 程序的启动目录user=root # 启动命令所使用的用户身份 启动 supervisor 即可：supervisord -c /etc/supervisord.conf 常用命令：1234567ps -aux | grep python # 查看进程ps -aux | grep 5000 # 查看占用某端口的进程supervisorctl status # 监控状态supervisorctl stop app # 停止 appsupervisorctl start app # 启动 app （往往需要先启动 virtualenv 虚拟环境）supervisorctl restart app # 重启 app 由于 supervisor 往往需要与虚拟环境同时使用，因此 supervisor 脚本中的 python 命令可以用虚拟环境中的 python 命令替代（如：/home/ehpcadmin/venv/bin/python manage.py runserver） 使用 gunicorn 作为 Web 服务器由于 Flask 自带的服务器（通过runserver命令启动）性能差且无法支持并发请求，因此需要使用 gunicorn 作为服务器（或其他 web 服务器）来提供更好的性能。 1Gunicorn &apos;Green Unicorn&apos; is a Python WSGI HTTP Server for UNIX. It&apos;s a pre-fork worker model. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy. 安装 gunicorn：pip install gunicorn 启动 gunicorn 服务器：gunicron -w4 -b0.0.0.0:8000 myapp:app，其中 -w 表示开启多少个 worker，-b 表示 gunicorn 开放的访问地址。想要结束 gunicorn 只需执行pkill gunicorn。 Gunicorn 官方文档 geventgevent 是第三方库，可通过 greenlet 实现协程，其基本思想是：当一个 greenlet 遇到 IO 操作时，比如访问网络，就自动切换到其他的 greenlet，等到 IO 操作完成，再在适当的时候切换回来继续执行。由于 IO 操作非常耗时，经常使程序处于等待状态，有了 gevent 为我们自动切换协程，就保证总有 greenlet 在运行，而不是等待 IO。 因此结合 gunicorn 启动服务的命令可设置为：gunicorn manage:app -b 0.0.0.0:8080 -w 4 --worker-class gevent（此命令可写入 supervisor 的应用配置文件中） 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch5-使用lsyncd进行文件实时备份]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch5-%E4%BD%BF%E7%94%A8lsyncd%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E5%AE%9E%E6%97%B6%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[安装 Ubuntu 环境 CentOS 环境 配置 配置选项说明 启动 lsyncd SSH 密钥配置 备份服务器操作 主服务器操作 配置文件模式示例 参考文档 Ads Lysncd 实际上是 lua 语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过 rsync 去差异同步，达到实时的效果。它完美解决了 inotify + rsync 海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。 另外，它的配置方式很简单，lua 本身就是一种配置语言，可读性非常强。lsyncd 也有多种工作模式可以选择（本地目录 cp，本地目录 rsync，远程目录 rsyncssh）。 安装Ubuntu 环境已经收录在 ubuntu 的官方镜像源里，直接通过apt-get install lsyncd命令安装。 CentOS 环境安装了 epel-release 扩展源后，通过yum install lsyncd命令安装。 配置lsyncd 安装完后默认并没有提供配置文件，因此需要我们自行创建。配置文件 lsyncd.conf 的一个示例如下： 12345678910111213141516# cd /usr/local/lsyncd-2.1.5# mkdir etc var# vi etc/lsyncd.confsettings &#123; logfile = &quot;/home/ubuntu/Desktop/lsyncd.log&quot;, statusFile = &quot;/home/ubuntu/Desktop/lsyncd.status&quot;&#125;sync &#123; default.rsyncssh, source = &quot;/home/ubuntu/Desktop/src&quot;, host = &quot;192.168.10.133&quot;, targetdir = &quot;/home/ubuntu/Desktop/dst&quot;, delay = 15&#125; 配置选项说明settings里是全局设置，--开头表示注释，下面是几个常用选项说明： logfile ：设置日志文件 stausFile ：设置状态文件 statusInterval ：将 lsyncd 的状态写入上面的statusFile的间隔，默认10秒 inotifyMode ：指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify maxProcesses ：同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程 maxDelays ：累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到 sync里是定义同步参数。 一般第一个参数指定 lsyncd serv以什么模式运行：rsync、rsyncssh、direct 三种模式： default.rsync ：本地目录间同步。使用 rsync 也可以达到使用 ssh 形式的远程 rsync 效果default.direct ：本地目录间同步，使用 cp、rm 等命令完成差异文件备份default.rsyncssh ：同步到远程主机目录，rsync 的 ssh 模式，需要使用 key 来认证 source ：同步的源目录，使用绝对路径。 target ：同步的目的目录，在不同模式下有不同的写法。 init ：当init=false时表示跳过初始同步，启动时即使原目录有差异时也不会同步。默认值为true。 delay ：等待同步的延时，默认15s，即每15s同步一次。 excludeFrom： 排除选项，后面指定排除的列表文件. 更多参数设置可以在参考文档中查看。 启动 lsyncd使用命令加载配置文件启动： 1lsyncd -log Exec [CONFIG-FILE] [CONFIG-FILE]为配置文件所在路径。 更加详细的说明可以通过lsyncd -help查看。 SSH 密钥配置为了让lysncd能够以 rsyncssh 模式进行工作，我们还需要对备份服务器进行一些配置。 主服务器是指需要被备份的服务器，备份服务器是指用来实现主服务器备份的服务器。 备份服务器操作在备份服务器中创建一个密钥对，直接回车即可，然后设置为authorized_keys。 123ssh-keygen -t rsacd ~/.sshcat id_rsa.pub &gt;&gt; authorized_keys 然后检查备份服务器有没有安装openssh-server，没有的话需要安装。 主服务器操作将备份服务器中生成的私钥id_rsa拷贝到主服务器的~/.ssh/里面。然后设置好权限，并且测试是否能够正常登陆。 12chmod 600 ~/.ssh/id_rsassh [USER]@[REMOTE_IP] [USER]和[REMOTE_IP]为登陆的用户和备份服务器的IP。如果能成功登陆的话则表示配置成功。 也可以在主服务器中生成一对密钥，把公钥拷贝到备份服务器的~/.ssh/authorized_keys中。 配置文件模式示例下面的内容几乎涵盖了所有同步的模式。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091settings &#123; logfile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;, statusFile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;, inotifyMode = &quot;CloseWrite&quot;, maxProcesses = 8, &#125;-- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大sync &#123; default.direct, source = &quot;/tmp/src&quot;, target = &quot;/tmp/dest&quot;, delay = 1 maxProcesses = 1 &#125;-- II. 本地目录同步，rsync模式：rsyncsync &#123; default.rsync, source = &quot;/tmp/src&quot;, target = &quot;/tmp/dest1&quot;, excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, bwlimit = 2000 &#125; &#125;-- III. 远程目录同步，rsync模式 + rsyncd daemonsync &#123; default.rsync, source = &quot;/tmp/src&quot;, target = &quot;syncuser@172.29.88.223::module1&quot;, delete=&quot;running&quot;, exclude = &#123; &quot;.*&quot;, &quot;.tmp&quot; &#125;, delay = 30, init = false, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, password_file = &quot;/etc/rsyncd.d/rsync.pwd&quot;, _extra = &#123;&quot;--bwlimit=200&quot;&#125; &#125; &#125;-- IV. 远程目录同步，rsync模式 + ssh shellsync &#123; default.rsync, source = &quot;/tmp/src&quot;, target = &quot;172.29.88.223:/tmp/dest&quot;, -- target = &quot;root@172.29.88.223:/remote/dest&quot;, -- 上面target，注意如果是普通用户，必须拥有写权限 maxDelays = 5, delay = 30, -- init = true, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, bwlimit = 2000 -- rsh = &quot;/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no&quot; -- 如果要指定其它端口，请用上面的rsh &#125; &#125;-- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同sync &#123; default.rsyncssh, source = &quot;/tmp/src2&quot;, host = &quot;172.29.88.223&quot;, targetdir = &quot;/remote/dir&quot;, excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, -- maxDelays = 5, delay = 0, -- init = false, rsync = &#123; binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, _extra = &#123;&quot;--bwlimit=2000&quot;&#125;, &#125;, ssh = &#123; port = 1234 &#125; &#125; 参考文档Config Layer 4: Default Config Lsyncd | 使用lsyncd同步文件目录 lsyncd实时同步搭建指南——取代rsync+inotify 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch6-配置集群共享文件NFS服务器]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch6-%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6NFS%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[配置集群共享文件 NFS 服务器 简介 安装与配置 启动与挂载 NFS 的常用命令 参考文档 Ads 配置集群共享文件 NFS 服务器简介在 Web 服务中往往需要涉及到一些不储存在数据库中的文件资源（比如用户上传的图片、文件等），而在 Web 服务器集群中，若每个服务器节点都有独立的文件资源存储的话，会造成节点间存储不一致的后果。因此比较成熟的解决方案是构建一个 NFS（Network File System）服务器专门提供服务器节点间的共享文件存储。当其他所有 Web 服务器挂载共享目录后，每次读写共享文件资源时实际上读写的是 NFS 服务器上的共享文件系统，这样服务器节点间的存储就可以保持一致性。 安装与配置首先在服务器节点上安装 NFS 服务：yum install nfs-utils rpcbind，然后在客户端节点上安装 NFS 服务：yum install nfs-utils。 配置 NFS 服务器（配置文件路径/etc/exports），配置文件中的每一行表示设置一个共享目录以及其有访问权限的主机地址。以下是一个说明示例：12345# 共享目录路径为“/home/share”，对所有主机可读，对地址为192.168.1.19的主机可读可写/home/share *(sync,ro,no_root_squash) 192.168.1.19(sync,rw,no_root_squash)# 共享目录路径为“/home/pub”，对192.168.152.0子网内的所有主机可读/home/pub 192.168.152.0/24(sync,ro,no_root_squash) sync：设置NFS服务器同步写磁盘，这样不会轻易丢失数据，建议所有的NFS共享目录都使用该选项 ro：设置输出的共享目录只读，与 rw 不能共同使用 rw：设置输出的共享目录可读写，与 ro 不能共同使用 root_squash：远程登录 NFS 主机后，使用该共享目录时相当于该目录的拥有者。但是如果是以 root 身份使用这个共享目录的时候，那么这个使用者（root）的权限将被压缩成为匿名使用者，即通常他的 UID 与 GID 都会变成nobody那个身份（较为安全） no_root_squash：远程登录 NFS 主机后，使用该共享目录时相当于该目录的拥有者，如果是 root 的话，那么对于这个共享的目录来说，他就具有 root 的权限（不安全） all_squash：不论登入 NFS 的使用者身份为何，他的身份都会被压缩成为匿名使用者，通常也就是 nobody 启动与挂载NFS 服务器启动 nfs 服务：service nfs start后， NFS 客户端即可进行挂载操作：mount : ，如mount 192.168.216.128:/home /mnt。客户端卸载 NFS 共享时：umount 。 挂载完成，但是这只是临时挂载，客户端重启后 NFS 挂载就失效了，要设置永久挂载可以编辑文件：12vim /etc/fstab &#123;&#123;NFS服务器地址&#125;&#125;:&#123;&#123;远程共享目录&#125;&#125; &#123;&#123;本地挂载目录&#125;&#125; nfs defaults 0 0 保存配置，执行mount -a 命令 PS：客户端不需启动 nfs 服务，但需要安装 nfs 来支持挂载共享目录。客户端卸载共享目录时需保证当前工作目录不是所卸载的目录。 NFS 的常用命令showmount 命令： showmount -e：显示 NFS 服务器的输出目录列表 showmount -d：显示当前主机 NFS 服务器中已经被 NFS 客户机挂载使用的共享目录 showmount -a：显示当前主机中 NFS 服务器的客户机信息 showmount -a [主机]：显示指定主机中 NFS 服务器的客户机信息 exportfs 命令： exportfs -rv：使 NFS 服务器重新读取 exports 文件中的设置 exportfs -auv：停止当前主机中 NFS 服务器的所有目录输出 参考文档Linux 系统中文件共享之 NFS NFS 文件共享配置参数 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch7-Nginx安装与重写URL-CentOS7]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch7-Nginx%E5%AE%89%E8%A3%85%E4%B8%8E%E9%87%8D%E5%86%99URL-CentOS7%2F</url>
    <content type="text"><![CDATA[Nginx安装与重写URL（CentOS7） Nginx安装 重写URL Ads Nginx安装与重写URL（CentOS7）Nginx安装新建 /etc/yum.repos.d/nginx.repo：12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/7/$basearch/gpgcheck=0enabled=1 使用命令# yum install nginx安装nginx。安装完成后使用命令# nginx启动 nginx 。使用# nginx -v查看 nginx 版本。并可通过在浏览器里直接访问机器的IP地址可查看 nginx 是否启动成功（需确保关闭 CentOS 的 SELinux 和防火墙服务）。 重写URL使用# nginx -t命令查看当前 nginx 配置文件状态以及路径。在配置文件中的项 http{} 里可重写URL：1234567server&#123; listen 80; #设置监听端口 server_name 172.18.216.123; #决定配置哪几台服务器，值可为域名也可为IP地址 location / &#123; #对匹配目录&quot;/&quot;进行操作。也可设置为其它的目录 rewrite / http://www.baidu.com break; #执行URL重写，支持正则表达式 &#125;&#125; 也可在配置文件的 server 块中写，此时是针对该服务器的全局配置。如：123server &#123; rewrite 规则 定向路径 重写类型;&#125; 规则：可以是字符串或者正则来表示想匹配的目标url 定向路径：表示匹配到规则后要定向的路径，如果规则里有正则，则可以使用 $index 来表示正则里的捕获分组 重写类型： last ：匹配重写后的URL，再一次对URL重写规则进行匹配。浏览器地址栏URL地址不变 break；匹配重写URL后终止匹配，直接使用。浏览器地址栏URL地址不变 redirect：返回302临时重定向，浏览器地址会显示跳转后的URL地址 permanent：返回301永久重定向，浏览器地址栏会显示跳转后的URL地址 更多具体语法可参见官方文档 Rewrite模块 或中文技术博客 Nginx配置URL重写。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch8-高可用与负载均衡集群部署-Ubuntu]]></title>
    <url>%2Fse-notes%2FFlask-Web%E5%B7%A5%E7%A8%8B%E6%89%8B%E5%86%8C%2Fch8-%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2-Ubuntu%2F</url>
    <content type="text"><![CDATA[EHPC负载均衡及高可用集群部署说明 一.物理架构及技术简介 HAProxy Keepalived NFS 二.部署准备 三.数据库节点配置 NFS 服务配置 MySQL 服务配置 四.Web服务节点配置 五.HAProxy代理节点配置 如何进行项目文件更新 架构中将来可能遇到的问题 部署问题汇总 ubuntu系统设置DNS失败 启动 80 端口的 web 节点的服务时提示端口被占用 virtualenv 虚拟环境迁移后无法正常引用库 复制 .bashrc 文件后虚拟环境导向出错 设置语言的环境变量时警告 warning: setlocale: LC_ALL： cannot change locale (zh_CN.UTF-8) 安装 gevent 失败 supervisor启动后 web 服务启动失败 Ads EHPC负载均衡及高可用集群部署说明一.物理架构及技术简介使用 Haproxy + Keepalived + nfs 作为集群部署方式。其中一台或多台 Hapoxy 代理服务器作为集群负载均衡的调度前端，多个 web 服务节点、单个数据库节点（同时提供 nfs 文件共享存储）作为对外隐藏的集群后端。 HAProxyHAProxy（High Available Proxy）是一款提供高可用性、负载均衡以及基于 TCP（第四层）和 HTTP（第七层）应用的代理软件。 HAProxy 配置简单、支持多达上万并发连接。其运行模型可使得它非常容易和无风险地集成到现有的架构中，并且同时可以保护 web 服务器不被暴露到网络上。 KeepalivedKeepalived 是一款高可用软件，它的功能是基于 VRRP 协议、通过 IP 漂移实现服务的高可用：服务器集群共享一个虚拟 IP，同一时间只有一个服务器占有虚拟 IP 并对外提供服务。若该服务器不可用，则虚拟 IP 漂移至另一台服务器并对外提供服务。 NFS在 Web 服务中往往需要涉及到一些不储存在数据库中的文件资源（比如用户上传的图片、文件等），而在集群中，若每个节点都有独立的文件存储的话，会造成存储不一致的后果。因此解决方案是构建一个 NFS（Network File System）服务器专门提供服务器节点间的共享文件存储，这样服务器节点间的存储就可以保持一致性。 二.部署准备准备四台虚机（Linux Ubuntu），分别作为前端代理（ ha1[10.182.15.46]）、服务节点（web1[10.182.15.51]、web2[10.182.15.52]）、数据库节点（nfs1[10.182.15.50]）。所有节点均可访问外网，其中只有 ha1 拥有公网 IP。 此外还拥有一台备份节点，用于对数据库节点 nfs1 的数据库以及文件目录进行实时主从备份。 所有节点须设置好 hosts 互相解析：12345#vi /etc/hosts10.182.15.46 ha110.182.15.50 nfs110.182.15.51 web110.182.15.52 web2 以及更新好 apt-get 库：apt-get update 三.数据库节点配置数据库节点为 nfs1，主要提供 NFS 与 MySQL 服务。 NFS 服务配置安装 NFS 服务sudo apt-get install nfs-kernel-server，并编辑配置文件（路径为/etc/exports），配置文件中的每一行表示设置一个共享目录以及有其访问权限的主机地址。 12# 共享目录路径为“/home/share”，对 web1 与 web2 两台主机开放读写权限/home/share web1(rw,sync,no_root_squash) web2(rw,sync,no_root_squash) 启动 NFS 服务：service nfs-kernel-server start后， NFS 客户端才可对共享目录进行挂载。 共享目录中放置 ehpc 的服务端项目文件，所有 web 服务节点将一起使用共享目录中的项目文件。 更多配置参数请参考 NFS服务器配置文档。 MySQL 服务配置ubuntu 系统一般会自带 MySQL 5.5，因此无需再安装一遍。首先使用默认的 mysql root 账户进入 mysql 命令行，修改 root 默认密码，并创建一个拥有访问权限的普通用户。 按照以下步骤设置开放 MySQL 的远程访问权限： 保证远程访问的 mysql 用户的 host 为’%’而不是’localhost’ sudo vi /etc/mysql/my.cnf，注释掉bind-address = 127.0.0.1 重启 mysql 服务 之后导入原数据库的 sql 脚本即可。 至此便完成了节点 nfs1 的配置。 四.Web服务节点配置本集群拥有两个 web 服务节点 web1、web2，两个节点的部署操作完全一致。 先使用 pip 安装 virtualenv、gunicorn、gevent、supervisor 等软件并使用apt-get install nfs-common​安装 NFS 客户端。再把 nfs1 节点开放的共享目录/home/share挂载到本地目录/home/haproxy/share，并设置为永久挂载（挂载操作参考 NFS服务器配置文档）。 迁移原 python 虚拟环境（迁移方法参考本文文末）后，还需要配置环境变量：把原脚本.bashrc copy 到用户根目录中，并对其中数据库配置等环境参数进行修改以满足当前实际要求，之后source ~/.bashrc刷新环境变量即可。 之后配置 supervisor（路径/etc/supervisor/conf.d/ehpc.conf）：12345[program:ehpc]command=/home/haproxy/env/bin/gunicorn manage:app -b 0.0.0.0:80 -w 4 --worker-class geventautostart = trueautorestart = trueuser=root 注意 manage.py 路径，需当前工作目录为项目主目录才可启动成功。最好在启动 supervisor 前手工启动跑一下以便及早发现可能的问题。 五.HAProxy代理节点配置前端节点为 ha1，作为集群中唯一直接对外通信的代理服务器。 安装 HAProxy：yum install haproxy，然后配置 HAProxy（路径/etc/haproxy/haproxy.cfg）。 HAProxy 的配置文件分为五个部分： global：全局配置的进程级参数，用来控制 Haproxy 启动前的一些进程及系统设置 defaults：配置默认参数，可以被 frontend，backend，listen 段继承使用 frontend：定义接收请求的前端虚拟节点，可根据用户所请求的不同域名、URL 等做不同的请求处理 backend：定义处理业务的后端服务器集群，以及设置后端的权重、队列、连接数等选项 listen：frontend 和 backend 的组合体 配置参数详细说明请查阅 HAProxy用法详解。 以下是 ha1 的配置实例：12345678910111213141516171819202122232425262728293031323334353637global log /dev/log local0 log /dev/log local1 notice chroot /var/lib/haproxy maxconn 20000 daemondefaults log global mode http option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 # 3次连接失败就认为服务器不可用 timeout http-keep-alive 10s # 默认持久连接超时时间 timeout check 10s # 心跳检查超时时间 contimeout 5000 clitimeout 50000 srvtimeout 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.httpfrontend proxy *:80 #前端代理 default_backend dynamicbackend dynamic #后端Web服务器 balance roundrobin cookie SESSION_ID insert indirect nocache #设置cookie保持 server web1 10.182.15.51:80 inter 3000 rise 2 fall 3 check maxconn 10000 cookie A server web2 10.182.15.52:80 inter 3000 rise 2 fall 3 check maxconn 10000 cookie B 启动 HAProxy 服务：service haproxy start即可。 如何进行项目文件更新更新之前先停掉 web1 与 web2 的服务：supervisorctl stop ehpc 更新数据库：登录 nfs1，进入 mysql 命令行进行新的数据库 sql 文件导入即可 更新项目文件：登录 nfs1，新的项目文件代替/home/share中对应的文件即可。 提示：由于通过跳板机登录 nfs1 不能使用 sftp 功能，因此目前也把跳板机下的目录挂载了 nfs1 上的共享目录，这样直接通过在跳板机上上传文件就可以修改项目文件了。 最后记得要重启 web1 与 web2 的服务：supervisorctl start ehpc 架构中将来可能遇到的问题由于 nfs1 既作为集群中唯一的数据库服务节点以及唯一的文件共享目录挂载节点，同时还负责对外实时备份，因此很有可能成为集群中效率的瓶颈。今后的架构重构中，应当考虑把数据库服务从文件共享目录挂载节点分离开，减小 nfs1 的压力。 部署问题汇总ubuntu系统设置DNS失败在/etc/resolvconf/resolv.conf.d/base里添加 DNS 失败，则应当在/etc/resolvconf/resolv.conf.d/head中进行添加，之后使用resolvconf -u刷新即可。 启动 80 端口的 web 节点的服务时提示端口被占用ubuntu 系统自带 Apache2 服务占用了 80 端口且开机自动启动，用sudo lsof -i:80命令找出 80 端口的占用程序 kill 掉即可，此外还可使用sudo update-rc.d apache2 disable命令关闭 apache2 的自启动。 virtualenv 虚拟环境迁移后无法正常引用库直接 copy 虚拟环境到另一台主机上就会出现新虚拟环境下的 python 无法引用库的问题。解决方法是在新主机上重新新建一个虚拟环境，然后把要原虚拟环境中的lib/python2.7/site-packages/目录下的库都 copy 到新虚拟环境中的该目录下即可。 复制 .bashrc 文件后虚拟环境导向出错.bashrc 复制到新的主机的用户根目录下时出现，删除以下两行即可：12export WORKON_HOME=~/.Envssource /usr/local/bin/virtualenvwrapper.sh 设置语言的环境变量时警告 warning: setlocale: LC_ALL： cannot change locale (zh_CN.UTF-8)如果不处理的话会导致程序中编码问题而报错。这是因为系统里没有安装对应的语言包，使用sudo apt-get install language-pack-zh-hans安装对应的语言包后重启并source ~/.bashrc即可。 安装 gevent 失败使用pip install gevent安装 gevent 时失败时，需要安装依赖包 python-dev ：sudo apt-get install python-dev supervisor启动后 web 服务启动失败在使用 supervisor 启动服务前先使用gunicorn manage:app -b 0.0.0.0:80 -w 4 --worker-class gevent命令进行测试，观察服务能否正常启动。若测试成功，则还要保证以下三点： 工作目录是 ehpc 项目的主目录 supervisor 服务处于开启状态：sudo service supervisor status 使用supervisord -c /etc/supervisor/supervisor.conf启动 supervisor 进程 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>框架</category>
        <category>python-web应用框架</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>web开发</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM基础]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2FJVM%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JVM基础 类加载器(classloader) 双亲委托机制 执行引擎(execution engine) 运行时数据区域(JVM Runtime Area) GC 找出需要回收的对象 垃圾回收算法 标记-清除算法 标记-整理算法 复制算法 分代收集算法（结合以上三种算法） heap 的组成 *对象引用类型 Ads JVM基础 Java 虚拟机（Java virtual machine，JVM）是运行 Java 程序必不可少的机制。JVM 实现了 Java 最重要的特征：平台无关性。 原理：编译后的 Java 程序指令并不直接在硬件系统的 CPU 上执行，而是由 JVM 执行。JVM 屏蔽了与具体平台相关的信息，使 Java 语言编译程序只需要生成在 JVM 上运行的目标字节码（.class），就可以在多种平台上不加修改地运行。Java 虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行，由此实现平台无关性。 JVM = 类加载器(classloader) + 执行引擎(execution engine) + 运行时数据区(runtime data area) 类加载器(classloader)类加载器用于装载 .class 文件到 JVM 中，有两种装载 class 的方式 ： 隐式：运行过程中，碰到 new 方式生成对象时，隐式调用 classLoader 到 JVM 显式：通过 Class.forname() 动态加载 双亲委托机制类的加载过程采用双亲委托机制，这种机制能更好的保证 Java 平台的安全。 该模型要求除了顶层的 Bootstrap class loader 启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关系来复用父加载器的代码。每个类加载器都有自己的命名空间。 双亲委托机制的工作过程如下： 当前 classLoader 首先从自己已经加载的类中查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。（每个类加载器都有自己的加载缓存，当一个类被加载了以后就会放入缓存，等下次加载的时候就可以直接返回） 当前 classLoader 的缓存中没有找到被加载的类的时候，委托父类加载器去加载，父类加载器采用同样的策略，首先查看自己的缓存，然后委托父类的父类去加载，一直到 bootstrap ClassLoader 。（当所有的父类加载器都没有加载的时候，再由当前的类加载器加载，并将其放入它自己的缓存中，以便下次有加载请求的时候直接返回） 类加载器 classloader 是具有层次结构的，也就是父子关系。其中 Bootstrap 是所有类加载器的父亲。 使用双亲委托机制的目的在于： 安全性考虑：为了安全性，避免用户自己编写的类动态替换 Java 的一些核心类，比如 String。 避免重复加载：JVM 中区分不同类，不仅仅是根据类名。相同的 class 文件被不同的 ClassLoader 加载就是不同的两个类，如果相互转型的话会抛 java.lang.ClassCaseException。 执行引擎(execution engine)执行引擎用于执行字节码或者本地方法。 运行时数据区域(JVM Runtime Area)JVM 运行时数据区 (JVM Runtime Area) 是 JVM 在运行期间，其对 JVM 内存空间的划分和分配。JVM 在运行时将数据划分为了多个区域来存储。 程序员写的 Java 程序都被加载到运行时数据区域中，按不同类别存放在堆（Heap）、方法区（Method Area）、虚拟机栈（VM Stack）、程序计数器（PC）中。 程序计数器：线程私有。当前线程所执行的字节码的指令计数器，存储每个线程下一步将执行的 JVM 指令。 JVM栈：线程私有。与线程同时创建，生命周期与线程相同。每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量、操作数栈等信息。每一个方法被调用直至执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 Native 方法栈：线程私有。类似于 JVM 栈，但虚拟机栈用于为虚拟机执行 java 方法，而本地方法栈则用于为虚拟机执行 native 方法。（native 方法是原生函数，是用 C/C++ 语言实现的，并且被编译成了 DLL，由 java 去调用） Java 堆：被所有线程共享的存储区域，在虚拟机启动时创建。它是 JVM 用于存储对象实例和数组的区域，Java 中所有通过 new 创建的对象的内存都在此分配。（这些对象被 GC 自动管理，无需也无法显式被销毁） 内存分配方式：指针碰撞（用一个指针指向内存已用区和空闲区的分界点）和空闲列表（用一个列表记录哪些内存块可用）。 指针碰撞的分配方式明显要优于空闲列表的方式，但是使用哪种方式取决于堆内存是否规整，而堆内存是否规整则由使用的垃圾收集算法决定。 堆在 JVM 是所有线程共享的，因此在其上进行对象内存的分配均需要进行加锁，这也是 new 开销比较大的原因。 鉴于上面的原因，Sun Hotspot JVM 为了提升对象内存分配的效率，对于所创建的线程都会分配一块独立的空间，这块空间又称为 TLAB。 方法区：被所有线程共享的内存区域，在虚拟机启动时创建，它用于存储已被虚拟机加载的类信息、常量、静态变量等数据。JVM 用持久代（Permanet Generation）来存放方法区。 运行时常量池：方法区的一部分，存放的为类中固定的常量信息、方法和域的引用信息。 GC垃圾回收机制是由垃圾收集器 Garbage Collection（GC）来实现的，GC 是后台的守护进程。它是一个低优先级进程，但是可以根据内存的使用情况动态的调整它的优先级。因此，它在内存可用量低到一定限度时才会自动运行，从而实现对内存的回收。这就是垃圾回收的时间不确定的原因。 程序运行期间，所有对象实例存储在运行时数据区域的 heap 中，当一个对象不再被引用（使用），它就需要被收回。在 GC 过程中，这些不再被使用的对象从 heap 中收回，这样就会有内存空间被循环利用。 由于 GC 要消耗一些资源和时间，Java 在对对象的生命周期特征（eden or survivor）进行分析之后，采用了分代的方式进行对象的收集，以缩短 GC 对应用造成的暂停。 在垃圾回收器回收内存之前，还需要一些清理工作。因为 GC 只能回收通过 new 申请的内存（在堆上），但是堆上的内存并不完全是通过 new 申请分配的。还有一些本地方法（一般是调用的 C 方法）。这部分特殊内存如果不手动释放，就会导致内存泄露，而 GC 是无法回收这部分内存的。所以需要在 finalize 中用本地方法(native method)如 free 操作等，再使用 gc 方法。显式的 GC 方法是 system.gc() 。 找出需要回收的对象 引用计数法：给对象添加一个引用计数器，计数器的值代表着这个对象被引用的次数，当计数器的值为0的时候，就代表没有引用指向这个对象，所以就可以对它进行回收。但无法解决对象循环引用的问题。（即多个对象互相循环引用，但没有其他对象持有这些对象的引用，从而是一个孤立的系统） 可达性分析：从一些顶点开始，对有向图中的每个顶点进行可达性分析，就可以把不可达的对象找出来。这些起始对象被称为 GC Roots。可以作为 GC Roots 的对象有：栈区中引用的对象、 方法区中静态属性或常量引用的对象。 垃圾回收算法找到需要回收的对象后，即可进行回收。JVM 中的 GC 是”自适应”的垃圾回收器，它会根据不同的环境和需要选择不同的处理方式。 标记-清除算法通过可达性分析算法找到可以回收的对象后，对这些对象进行标记，代表它可以被回收。标记完成之后就统一回收所有被标记的对象。但是这种方式会产生大量的内存碎片，导致可用内存不规整，于是分配新的内存时就需要采用空闲列表的方法。如果没有找到足够大的空间，那么就要提前触发下一次垃圾收集。 标记-整理算法标记的过程和标记-清除算法一样，但是标记完成之后，让所有存活的对象都向堆内存的一端移动，最后直接清除掉边界以外的内存。这样对内存进行回收之后，内存是规整的，于是可以使用指针碰撞的方式分配新的内存。 复制算法标记-清除算法和标记-整理算法都使用先标记的方式，但当对象数量很多时，这种算法的效率并不高。 复制算法将可用内存分成两个部分，每次只使用其中的一部分，当其中一块用完时，就将仍然存活的对象复制到另外一块上，再把原来的那一块内存清理掉。这样回收的结果同样能得到规整的剩余空间，但是会浪费一部分内存。 可将新生代划分为三个部分，分别为Eden、Survivor from、Survivor to，大小比例为8：1：1。每次只使用 Eden 和其中的一块 Survivor，回收时将存活的对象复制到另一块 Survivor 中，这样就只有10%的内存被浪费，但是如果存活的对象总大小超过了 Survivor 的大小，那么就把多出的对象放入老年代中。 分代收集算法（结合以上三种算法）把 Java堆分成新生代和老年代，新生代使用复制算法，老年代使用标记-清理或标记-整理算法。这样可以根据各个代自己的特点，选用合适的收集算法，提高内存收集的效率。在新生代中长期存活的对象会逐渐向老年代过渡，新生代中的对象每经历一次 GC，年龄就增加一岁，当年龄超过一定值时，就会被移动到旧生代。 heap 的组成由于 GC 需要消耗一些资源和时间的，Java 在对对象的生命周期特征进行分析后，采用了分代的方式来进行对象的收集，即按照新生代、旧生代的方式来对对象进行收集，以尽可能的缩短 GC 对应用造成的暂停。 heap 的组成有三区域/世代：(可以理解随着时间，对象实例不断变换 heap 中的等级) 新生代（Young Generation） Eden Space：任何新进入运行时数据区域的实例都会存放在此 S0 Suvivor Space：存在时间较长，经过垃圾回收没有被清除的实例，就从Eden 搬到了S0 S1 Survivor Space：存在时间更长的实例，就从S0 搬到了S1 旧生代（Old Generation/tenured）：存在时间更长的对象，多次 GC 没被清除，就从 S1 搬到了 tenured 持久代：存放运行时数据区的方法区 Java 对新生代和旧生代使用不同的 GC 算法。新生代做“复制收集”，旧生代做“标记压缩收集”。 PS：搬运工作都由 GC 完成。GC 负责在 heap 中搬运实例，以及收回存储空间。 *对象引用类型JVM 中将对象的引用分为了四种类型，不同的对象引用类型会造成 GC 采用不同的方法进行回收： 强引用：默认情况下，对象采用的均为强引用。（GC 不会回收） 软引用：软引用是 Java 中提供的一种比较适合于缓存场景的应用。（只有在内存不够用的情况下才会被GC） 弱引用：在GC时一定会被GC回收 虚引用：在GC时一定会被GC回 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐 收]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Servlet]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2FJava-Servlet%2F</url>
    <content type="text"><![CDATA[简介 生命周期- [init() 方法](#init-方法) - [service() 方法](#service-方法) - [destroy() 方法](#destroy-方法) - [一个典型的 Servlet 生命周期图](#一个典型的-servlet-生命周期图) 面试题- [Servlet 和 GCI 的区别](#servlet-和-gci-的区别) - [Servlet 生命周期](#servlet-生命周期) - [Servle 和 JSP 的区别](#servle-和-jsp-的区别) - [JSP有哪些内置对象？作用是什么？](#jsp有哪些内置对象作用是什么) - [JSP有哪些基本动作？作用是什么？](#jsp有哪些基本动作作用是什么) - [JSP 中动态 INCLUDE 与静态 INCLUDE 的区别？](#jsp-中动态-include-与静态-include-的区别) - [四种会话跟踪技术作用域](#四种会话跟踪技术作用域) 参考文档- [Ads](#ads) 简介Java Servlet 是运行在 Web 服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。 Servlet 架构如下所示： Servlet 执行以下主要任务： 读取客户端（浏览器）发送的数据 处理数据并生成响应结果（该过程可能需要访问数据库等操作） 发送响应数据到客户端（浏览器） 生命周期Servlet 生命周期可被定义为从创建直到毁灭的整个过程： Servlet 通过调用 init () 方法进行初始化。 Servlet 调用 service() 方法来处理客户端的请求。 Servlet 通过调用 destroy() 方法终止。 Servlet 最后由 JVM 的垃圾回收器进行垃圾回收。 init() 方法init 方法只能调用一次。它在第一次创建 Servlet 时被调用，在后续每次用户请求时不再调用。当用户调用一个 Servlet 时，就会创建一个 Servlet 实例，每一个用户请求都会产生一个新的线程，适当的时候移交给 doGet 或 doPost 方法。 init() 方法简单地创建或加载一些数据，这些数据将被用于 Servlet 的整个生命周期。 service() 方法service() 方法是执行实际任务的主要方法。Servlet 容器（即 Web 服务器）调用 service() 方法来处理来自客户端（浏览器）的请求，并把格式化的响应写回给客户端。 每次服务器接收到一个 Servlet 请求时，服务器会产生一个新的线程并调用服务。service() 方法检查 HTTP 请求类型（GET、POST、PUT、DELETE 等），并在适当的时候调用 doGet、doPost、doPut，doDelete 等方法。 service() 方法由容器调用，service 方法在适当的时候调用 doGet、doPost、doPut、doDelete 等方法。所以，开发者一般不用对 service() 方法做任何动作，只需要根据来自客户端的请求类型来重写 doGet() 或 doPost() 即可。 destroy() 方法destroy() 方法只会被调用一次，在 Servlet 生命周期结束时被调用。destroy() 方法可以让 Servlet 关闭数据库连接、停止后台线程等清理活动。 一个典型的 Servlet 生命周期图 第一个到达服务器的 HTTP 请求被委派到 Servlet 容器。 Servlet 容器在调用 service() 方法之前加载 Servlet。 然后 Servlet 容器处理由多个线程产生的多个请求，每个线程执行一个单一的 Servlet 实例的 service() 方法。 面试题Servlet 和 GCI 的区别Servlet 是基于 Java 编写的，处于服务器进程中，它能够通过多线程方式运行 service() 方法，一个实例可以服务于多个请求，而且一般不会销毁；而 CGI 对每个请求都生产新的进程，服务完成后销毁，所以从效率上低于 Servlet。 Servlet 生命周期Servlet生命周期包括三部分： 初始化：Web 容器加载 servlet，调用 init() 方法 处理请求：当请求到达时，运行其 service() 方法。service() 自动派遣运行与请求相对应的 doXXX（doGet 或者 doPost）方法。 销毁：服务结束，Web 容器会调用 servlet 的 distroy() 方法销毁 servlet。 Servle 和 JSP 的区别服务器端有一个 JSP 容器，主要处理 JSP 页面请求，容器首先把 JSP 转成一个 Servlet，所有的 JSP 元素都会被转换为 Java 代码，然后编译这个 Servlet 类。 Servlet 和 JSP 最主要的不同点在于，Servlet 的应用逻辑是在 Java 文件中，并且完全从表示层中的 HTML 里分离开来。而 JSP 的情况是 Java 和 HTML 可以组合成一个扩展名为 .jsp 的文件。JSP 侧重于视图，Servlet 主要用于控制逻辑。 JSP有哪些内置对象？作用是什么？JSP 共有以下 9 种基本内置组件： 名称 作用 request 包含用户端请求的信息 response 包含服务器传回客户端的响应信息 page 网页本身 pageContext 管理网页属性 session 与请求有关的会话 application 伴随服务器的生命周期，为多个应用程序保存信息 out 向客户端输出数据 config servlet的架构部件 exception 针对错误页面才可使用 JSP有哪些基本动作？作用是什么？ jsp:include：在页面被请求的时候引入一个文件。 jsp:useBean：寻找或者实例化一个JavaBean。 jsp:setProperty：设置 JavaBean 的属性。 jsp:getProperty：输出某个 JavaBean 的属性。 jsp:forward：把请求转到一个新的页面。 jsp:plugin：根据浏览器类型为 Java 插件生成 OBJECT 或 EMBED 标记 JSP 中动态 INCLUDE 与静态 INCLUDE 的区别？动态 INCLUDE 用 jsp:include 动作实现，它总是会检查所含文件中的变化，适合用于包含动态页面，并且可以带参数；静态 INCLUDE 用 include 伪码实现，不会检查所含文件的变化，适用于包含静态页面。 四种会话跟踪技术作用域 page：一个页面 request：：一次请求，一个请求可能跨越多个 page session：一次会话，一个会话可能跨越多个 request application：代表与整个 Web 应用程序相关的对象和属性，跨越了整个 Web 应用程序。 参考文档Servlet 教程 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础知识]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2FJava%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Java 基础 面向对象的特征有哪些方面？ 访问修饰符public,private,protected,以及不写（默认）时的区别？ String 是最基本的数据类型吗？ float f=3.4;是否正确？ short s1 = 1; s1 = s1 + 1;有错吗? short s1 = 1; s1 += 1;有错吗？ int和Integer有什么区别？ 解释内存中的栈(stack)、堆(heap)和方法区(method area)的用法 Math.round(11.5) 等于多少？Math.round(-11.5)等于多少？ switch 是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上？ 用最有效率的方法计算2乘以8？ 构造器（constructor）是否可被重写（override）？ 两个对象值相同(x.equals(y) == true)，但却可有不同的hash code，这句话对不对？ String 和 StringBuilder、StringBuffer 的区别？ 是否可以继承String类？ 重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？ char 型变量中能不能存贮一个中文汉字？ 抽象类（abstract class）和接口（interface）有什么异同？ * 静态嵌套类(Static Nested Class)和内部类（Inner Class）的不同？ Java 中会存在内存泄漏吗，请简单描述。 * 抽象的（abstract）方法是否可同时是静态的（static）,是否可同时是本地方法（native），是否可同时被 synchronized 修饰？ * 如何实现对象克隆？ GC是什么？为什么要有GC？ String s = new String(“xyz”);创建了几个字符串对象？ 接口是否可继承（extends）接口？抽象类是否可实现（implements）接口？抽象类是否可继承具体类（concrete class）？ 一个”.java”源文件中是否可以包含多个类（不是内部类）？有什么限制？ Anonymous Inner Class(匿名内部类)是否可以继承其它类？是否可以实现接口？ * 内部类可以引用它的包含类（外部类）的成员吗？有没有什么限制？ Java 中的 final 关键字有哪些用法？ * 指出下面程序的运行结果 数据类型之间的转换 Error和Exception有什么区别？ try{}里有一个return语句，那么紧跟在这个try后的finally{}里的代码会不会被执行，什么时候被执行，在return前还是后? Java语言如何进行异常处理，关键字：throws、throw、try、catch、finally 分别如何使用？ 运行时异常与受检（必检）异常有何异同？ 阐述final、finally、finalize的区别 List、Set、Map是否继承自Collection接口？ 阐述 ArrayList、Vector、LinkedList 的存储性能和特性 Collection 和 Collections 的区别？ List、Map、Set 三个接口存取元素时，各有什么特点？ TreeMap 和 TreeSet 在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？ Thread类的sleep()方法和对象的wait()方法都可以让线程暂停执行，它们有什么区别? 线程的sleep()方法和yield()方法有什么区别？ 当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？ 请说出与线程同步以及线程调度相关的方法。 编写多线程程序有几种实现方式？ 举例说明同步和异步 什么是线程池（thread pool）？ 线程的基本状态以及状态之间的关系？ Java中如何实现序列化，有什么意义？ Interge的线程安全容器是？ 线程安全的集合对象 托管代码与非托管代码的区别 Java 基础面向对象的特征有哪些方面？ 抽象：抽象是将一类对象的共同特征总结出来构造类的过程。 继承：继承是从已有类得到继承信息创建新类的过程。 封装：把数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。 多态：允许不同子类型的对象对同一消息作出不同的响应。 访问修饰符public,private,protected,以及不写（默认）时的区别？ 注意：protected 修饰的数据域和方法可被同包访问 String 是最基本的数据类型吗？Java中的基本数据类型只有8个：byte、short、int、long、float、double、char、boolean；除了基本类型，剩下的都是引用类型。 float f=3.4;是否正确？3.4 是双精度数，3.4f 才是单精度数。Java 中默认小数为双精度数。 short s1 = 1; s1 = s1 + 1;有错吗? short s1 = 1; s1 += 1;有错吗？对于short s1 = 1; s1 = s1 + 1;，由于 1 是 int 类型，因此 s1 + 1 运算结果也是 int 型，需要强制转换类型才能赋值给 short 型。 对于short s1 = 1; s1 += 1;，可以正确编译，因为s1 += 1;相当于s1 = (short)(s1 + 1);其中有隐含的强制类型转换。 int和Integer有什么区别？Java是一个近乎纯洁的面向对象编程语言，但是为了编程的方便还是引入了基本数据类型，但是为了能够将这些基本数据类型当成对象操作，Java为每一个基本数据类型都引入了对应的包装类型（wrapper class），int 的包装类就是 Integer，从Java 5开始引入了自动装箱/拆箱机制，使得二者可以相互转换。 解释内存中的栈(stack)、堆(heap)和方法区(method area)的用法 通常定义一个基本数据类型的变量、一个对象的引用、以及函数调用的现场保存都使用 JVM 中的栈空间 而通过 new 关键字和构造器创建的对象则放在堆空间，堆是垃圾收集器管理的主要区域，由于现在的垃圾收集器都采用分代收集算法，所以堆空间还可以细分为新生代和老生代，再具体一点可以分为Eden、Survivor（又可分为From Survivor和To Survivor）、Tenured； 方法区和堆都是各个线程共享的内存区域，用于存储已经被 JVM 加载的类信息、常量、静态变量、即时编译（JIT）编译器编译后的代码等 程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在运行时常量池中，运行时常量池是方法区的一部分。 栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，栈和堆的大小都可以通过 JVM 的启动参数来进行调整，栈空间用光了会引发 StackOverflowError ，而堆和常量池空间不足则会引发 OutOfMemoryError 。 String str = new String(&quot;hello&quot;); 上面的语句中变量 str 放在栈上，用 new 创建出来的字符串对象放在堆上，而”hello”这个字面量是放在方法区的。 Math.round(11.5) 等于多少？Math.round(-11.5)等于多少？12；-11；四舍五入的原理是在参数上加0.5然后进行下取整。 switch 是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上？byte、short、char、int 和 String 类型可以。就是 long 型不可以。 用最有效率的方法计算2乘以8？ 2 &lt;&lt; 3（左移3位相当于乘以2的3次方，右移3位相当于除以2的3次方）。 构造器（constructor）是否可被重写（override）？构造器不能被继承，因此不能被重写，但可以被重载。 两个对象值相同(x.equals(y) == true)，但却可有不同的hash code，这句话对不对？不对，如果两个对象 x 和 y 满足x.equals(y) == true，它们的哈希码（hash code）应当相同。 Java 对于 eqauls 方法和 hashCode 方法是这样规定的： 如果两个对象相同（equals 方法返回 true），那么它们的hashCode值一定要相同 如果两个对象的 hashCode 相同，它们并不一定相同 当然，你未必要按照要求去做，但是如果你违背了上述原则就会发现在使用容器时，相同的对象可以出现在Set集合中，同时增加新元素的效率会大大下降（对于使用哈希存储的系统，如果哈希码频繁的冲突将会造成存取性能急剧下降） String 和 StringBuilder、StringBuffer 的区别？答：Java 平台提供了两种类型的字符串：String 和 StringBuffer/StringBuilder，它们可以储存和操作字符串。其中 String 是只读字符串，也就意味着 String 引用的字符串内容是不能被改变的。而 StringBuffer/StringBuilder 类表示的字符串对象可以直接进行修改。StringBuilder 是 Java 5 中引入的，它和 StringBuffer 的方法完全相同，区别在于它是在单线程环境下使用的，因为它的所有方面都没有被 synchronized 修饰，因此它的效率也比 StringBuffer 要高。 是否可以继承String类？String 类是 final 类，不可以被继承。 重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同）则视为重载；重载对返回类型没有特殊的要求 重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，不能比父类被重写方法声明更多的异常（里氏代换原则） char 型变量中能不能存贮一个中文汉字？char 类型可以存储一个中文汉字，因为 Java 中使用的编码是 Unicode 。而一个 char 类型占2个字节。 抽象类（abstract class）和接口（interface）有什么异同？相同点： 都不可实例化，但可以定义抽象类和接口类型的引用 不同点： 抽象类有构造器，允许有抽象方法和具体方法；接口没有构造器，且方法必须是抽象方法； 接口中成员全是 static public 类型 接口可以多继承 * 静态嵌套类(Static Nested Class)和内部类（Inner Class）的不同？Static Nested Class 是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化。 思考： 下面那些语句会有编译错误？123456789101112class Outer &#123; class Inner &#123;&#125; public static void foo() &#123; new Inner(); &#125; // error public void bar() &#123; new Inner(); &#125; public static void main(String[] args) &#123; // error new Inner(); &#125;&#125; Java 中会存在内存泄漏吗，请简单描述。理论上 Java 因为有垃圾回收机制（GC）不会存在内存泄露问题；然而在实际开发中，可能会存在无用但可达的对象，这些对象不能被 GC 回收，因此也会导致内存泄露的发生（比如当一个栈中出栈元素时，只是把栈的计数减一）。此外，Native 方法由于是用非 Java 语言写的，所以也可能导致内存泄露。 * 抽象的（abstract）方法是否可同时是静态的（static）,是否可同时是本地方法（native），是否可同时被 synchronized 修饰？都不能。 抽象方法需要子类重写，而静态的方法是无法被重写的，因此二者是矛盾的。 本地方法是由本地代码（如C代码）实现的方法，而抽象方法是没有实现的，也是矛盾的。 synchronized 和方法的实现细节有关，抽象方法不涉及实现细节，因此也是相互矛盾的。 * 如何实现对象克隆？有两种方式： 1). 实现 Cloneable 接口并重写 Object 类中的 clone() 方法 2). 实现 Serializable 接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆 注意：基于序列化和反序列化实现的克隆不仅仅是深度克隆，更重要的是通过泛型限定，可以检查出要克隆的对象是否支持序列化，这项检查是编译器完成的，不是在运行时抛出异常，这种是方案明显优于使用Object类的clone方法克隆对象。让问题在编译的时候暴露出来总是好过把问题留到运行时。 GC是什么？为什么要有GC？GC 是垃圾收集的意思，内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java 提供的 GC 功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。Java 程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一：System.gc() 或 Runtime.getRuntime().gc() ，但 JVM 可以屏蔽掉显式的垃圾回收调用。 垃圾回收可以有效的防止内存泄露，有效使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。在 Java 诞生初期，垃圾回收是 Java 最大的亮点之一，因为服务器端的编程需要有效的防止内存泄露问题，然而时过境迁，如今 Java 的垃圾回收机制已经成为被诟病的东西。移动智能终端用户通常觉得 iOS 的系统比 Android 系统有更好的用户体验，其中一个深层次的原因就在于Android系统中垃圾回收的不可预知性。 补充：垃圾回收机制有很多种，包括：分代复制垃圾回收、标记垃圾回收、增量垃圾回收等方式。标准的Java进程既有栈又有堆。栈保存了原始型局部变量，堆保存了要创建的对象。Java 平台对堆内存回收和再利用的基本算法被称为标记和清除，但是 Java 对其进行了改进，采用“分代式垃圾收集”。这种方法会跟 Java 对象的生命周期将堆内存划分为不同的区域，在垃圾收集过程中，可能会将对象移动到不同区域： 伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。 幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。 终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间。 String s = new String(“xyz”);创建了几个字符串对象？两个对象，一个是静态区的”xyz”，一个是用 new 创建在堆上的对象。 接口是否可继承（extends）接口？抽象类是否可实现（implements）接口？抽象类是否可继承具体类（concrete class）？接口可以继承接口，而且支持多重继承。抽象类可以实现(implements)接口，抽象类可继承具体类也可以继承抽象类。 一个”.java”源文件中是否可以包含多个类（不是内部类）？有什么限制？可以，但一个源文件中最多只能有一个公开类（public class）而且文件名必须和公开类的类名完全保持一致。 Anonymous Inner Class(匿名内部类)是否可以继承其它类？是否可以实现接口？可以继承其他类或实现其他接口，在 Swing 编程和 Android 开发中常用此方式来实现事件监听和回调。 * 内部类可以引用它的包含类（外部类）的成员吗？有没有什么限制？一个内部类对象可以访问创建它的外部类对象的成员，包括私有成员。 Java 中的 final 关键字有哪些用法？ 修饰类：表示该类不能被继承 修饰方法：表示方法不能被重写 修饰变量：表示变量只能一次赋值以后值不能被修改（常量） * 指出下面程序的运行结果123456789101112131415161718192021222324252627282930class A &#123; static &#123; System.out.print(&quot;1&quot;); &#125; public A() &#123; System.out.print(&quot;2&quot;); &#125;&#125;class B extends A&#123; static &#123; System.out.print(&quot;a&quot;); &#125; public B() &#123; System.out.print(&quot;b&quot;); &#125;&#125;public class Hello &#123; public static void main(String[] args) &#123; A ab = new B(); ab = new B(); &#125;&#125; 执行结果：1a2b2b。创建对象时构造器的调用顺序是：先初始化静态成员，然后调用父类构造器，再初始化非静态成员，最后调用自身构造器。 数据类型之间的转换问： 如何将字符串转换为基本数据类型？ 如何将基本数据类型转换为字符串？ 答： 调用基本数据类型对应的包装类中的方法 parseXXX(String) 或 valueOf(String) 即可返回相应基本类型； 一种方法是将基本数据类型与空字符串（””）连接（+）即可获得其所对应的字符串；另一种方法是调用String 类中的 valueOf() 方法返回相应字符串 Error和Exception有什么区别？Error 表示系统级的错误和程序不必处理的异常，是恢复很困难的情况下的一种严重问题（比如内存溢出，不可能指望程序能处理这样的情况）；Exception 表示需要捕捉或者需要程序进行处理的异常，是一种设计或实现问题。 常见的几种异常如下： NullPointerException - 空指针引用异常 ClassCastException - 类型强制转换异常 IllegalArgumentException - 传递非法参数异常 ArithmeticException - 算术运算异常 ArrayStoreException - 向数组中存放与声明类型不兼容对象异常 IndexOutOfBoundsException - 下标越界异常 NegativeArraySizeException - 创建一个大小为负数的数组错误异常 UnsupportedOperationException - 不支持的操作异常 FileNotFoundException - 文件未找到异常 IOException - 输入输出异常 NoSuchMethodException - 方法未找到异常 ClassNotFoundException - 类定义未找到异常 IllegalMonitorStateException - 当wait() 方法未在同步块中使用 java.lang.UnsupportedOperationException 是指请求的方法不被支持的异常。在从 Arrays.asList() 转化过来的 List 的不支持 add() 和 remove() 方法，这是由于从 Arrays.asList() 返回的是返回 java.util.Arrays\$ArrayList ，而不是 ArrayList 。 Arrays\$ArrayList 和 ArrayList 都是继承 AbstractList ，add() 和 remove() 等方法在 AbstractList 中默认 throw UnsupportedOperationException 而不做任何操作。 ArrayList 重写这些方法对 List 进行操作，而 Arrays\$ArrayList 却没有重写 add() 和 remove() 等方法，所以对从 Arrays.asList() 转化过来的 List 进行 add() 和 remove() 会出现 UnsupportedOperationException 异常 try{}里有一个return语句，那么紧跟在这个try后的finally{}里的代码会不会被执行，什么时候被执行，在return前还是后?会执行，在方法返回调用者前执行。 注意：在 finally 中改变返回值的做法是不好的，因为如果存在 finally 代码块，try 中的 return 语句不会立马返回调用者，而是记录下返回值待 finally 代码块执行完毕之后再向调用者返回其值。如果在finally中修改了返回值，就会返回修改后的值。显然，在finally中返回或者修改返回值会对程序造成很大的困扰，Java 中可以通过提升编译器的语法检查级别来产生警告或错误。 Java语言如何进行异常处理，关键字：throws、throw、try、catch、finally 分别如何使用？Java 通过面向对象的方法进行异常处理，每个异常都是一个对象，它是 Throwable 类或其子类的实例。当一个方法出现异常后便抛出一个异常对象（该对象中包含有异常信息），调用这个对象的方法可以捕获到这个异常并可以对其进行处理。 Java 的异常处理是通过5个关键词来实现的：try、catch、throw、throws 和 finally 。 try 用于指定一块预防所有异常的程序，如果系统会抛出（throw）一个异常对象，可以通过它的类型来捕获（catch）它，或通过总是执行代码块（finally）来处理； catch 子句紧跟在 try 块后面，用来指定你想要捕获的异常的类型； throws 用来声明一个方法可能抛出的各种异常（当然声明异常时允许无病呻吟）； finally 为确保一段代码不管发生什么异常状况都要被执行； try 语句可以嵌套，每当遇到一个 try 语句，异常的结构就会被放入异常栈中，直到所有的try语句都完成。如果下一级的 try 语句没有对某种异常进行处理，异常栈就会执行出栈操作，直到遇到有处理这种异常的 try 语句或者最终将异常抛给 JVM 。 运行时异常与受检（必检）异常有何异同？RuntimeException、Error 以及它们的子类都被称为免检异常（unchecked Exception）。所有其他异常都称为必检异常（checked Exception），意思是指编译器会强制程序员检查并处理它们。 异常表示程序运行过程中可能出现的非正常状态。运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。 阐述final、finally、finalize的区别 final： 如果一个类被声明为final，意味着它不能再派生出新的子类，即不能被继承，因此它和 abstract 是反义词。 将变量声明为 final，可以保证它们在使用中不被改变，被声明为 final 的变量必须在声明时给定初值，而在以后的引用中只能读取不可修改。 被声明为 final 的方法也同样只能使用，不能在子类中被重写。 finally：通常放在 try…catch… 的后面构造总是执行代码块，这就意味着程序无论正常执行还是发生异常，这里的代码只要 JVM 不关闭都能执行，可以将释放外部资源的代码写在 finally 块中。 finalize：Object 类中定义的方法，Java 中允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在销毁对象时调用的，通过重写 finalize() 方法可以整理系统资源或者执行其他清理工作。 List、Set、Map是否继承自Collection接口？List、Set 是，Map 不是。Map是键值对映射容器，与 List 和 Set 有明显的区别，而 Set 存储的零散的元素且不允许有重复元素（数学中的集合也是如此），List 是线性结构的容器，适用于按数值索引访问元素的情形。 阐述 ArrayList、Vector、LinkedList 的存储性能和特性ArrayList 和 Vector 都是使用数组方式存储数据，数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector 中的方法由于添加了 synchronized 修饰，因此 Vector 是线程安全的容器，但性能上较 ArrayList 差，因此已经是 Java 中的遗留容器。 LinkedList 使用双向链表实现存储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。 Vector 属于遗留容器，已经不推荐使用，但是由于 ArrayList 和 LinkedListed 都是非线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类 Collections 中的 synchronizedList 方法将其转换成线程安全的容器后再使用。 Collection 和 Collections 的区别？Collection 是一个接口，它是 Set、List 等容器的父接口；Collections 是个工具类，提供了一系列的静态方法来辅助容器操作，这些方法包括对容器的搜索、排序、线程安全化等等。 List、Map、Set 三个接口存取元素时，各有什么特点？List 以特定索引来存取元素，可以有重复元素。Set 不能存放重复元素（用对象的 equals() 方法来区分元素是否重复）。Map 保存键值对（key-value pair）映射，映射关系可以是一对一或多对一。Set 和 Map 容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。 TreeMap 和 TreeSet 在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo() 方法，当插入元素时会回调该方法比较元素的大小。TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进行排序。 Collections 工具类的 sort 方法有两种重载的形式，第一种要求传入的待排序容器中存放的对象比较实现Comparable 接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是 Comparator 接口的子类型（需要重写 compare 方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小。 Thread类的sleep()方法和对象的wait()方法都可以让线程暂停执行，它们有什么区别?sleep() 方法是线程类（Thread）的静态方法，调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复（线程回到就绪状态）。 wait() 是 Object 类的方法，调用对象的 wait() 方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的 notify() 方法（或 notifyAll() 方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。 注意：对象等待池和等锁池是两个不同的概念 总结如下： wait() 方法会释放锁，而 sleep() 方法不会释放锁。 进入 wait 状态的线程能够被 notify 和 notifyAll 唤醒，但是进入 sleeping 状态的线程只能到了规定的时间再自动苏醒。 Java 中的 wait() 方法只能在同步代码块中调用，但是 sleep() 方法不需要。 补充：进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是操作系统进行资源分配和调度的一个独立单位；线程是进程的一个实体，是 CPU 调度和分派的基本单位，是比进程更小的能独立运行的基本单位。线程的划分尺度小于进程，这使得多线程程序的并发性高；进程在执行时通常拥有独立的内存单元，而线程之间可以共享内存。使用多线程的编程通常能够带来更好的性能和用户体验，但是多线程的程序对于其他程序是不友好的，因为它可能占用了更多的 CPU 资源。当然，也不是线程越多，程序的性能就越好，因为线程之间的调度和切换也会浪费 CPU 时间。 线程的sleep()方法和yield()方法有什么区别？ sleep() 方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield() 方法只会给相同优先级或更高优先级的线程以运行的机会 线程执行 sleep() 方法后转入阻塞（blocked）状态，而执行 yield() 方法后转入就绪（ready）状态 sleep() 方法声明抛出 InterruptedException，而 yield() 方法没有声明任何异常 sleep() 方法比 yield() 方法（跟操作系统 CPU 调度相关）具有更好的可移植性 当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的 synchronized 修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池）中等待对象的锁。 请说出与线程同步以及线程调度相关的方法。 wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁 sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 InterruptedException 异常 notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关 notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态 Java 5通过 Lock 接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock 接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了 newCondition() 方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。 编写多线程程序有几种实现方式？Java 5 以前实现多线程有两种实现方法：一种是继承 Thread 类；另一种是实现 Runnable 接口。两种方式都要通过重写 run() 方法来定义线程的行为。 推荐使用后者，因为 Java 中的继承是单继承，一个类有一个父类，如果继承了 Thread 类就无法再继承其他类了，显然使用 Runnable 接口更为灵活。此外更重要的是，可以把线程逻辑从线程的执行中分离出来。 举例说明同步和异步如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），那么这些数据就必须进行同步存取（如数据库操作中的排他锁）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。 什么是线程池（thread pool）？在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在 Java 中，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是池化资源技术产生的原因。 线程池就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。Java 提供 Executor 接口来执行线程池中的任务，提供 ExecutoeService 接口来管理和控制任务。 线程的基本状态以及状态之间的关系？ Java中如何实现序列化，有什么意义？序列化是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决对象流读写操作时可能引发的问题（如果不进行序列化可能会存在数据乱序的问题）。 要实现序列化，需要让一个类实现 Serializable 接口，该接口是一个标识性接口，标注该类对象是可被序列化的。然后使用一个输出流来构造一个对象输出流并通过 writeObject(Object) 方法就可以将实现对象写出（即保存其状态）；如果需要反序列化则可以用一个输入流建立对象输入流，然后通过 readObject 方法从流中读取对象。序列化除了能够实现对象的持久化之外，还能够用于对象的深度克隆。 Interge的线程安全容器是？Java 原子操作 AtomicInteger 的用法 线程安全的集合对象 ArrayList 线程不安全，Vector 线程安全； HashMap 线程不安全，HashTable 线程安全； StringBuilder 线程不安全，StringBuffer 线程安全。 Java 集合的实现原理 托管代码与非托管代码的区别 托管代码是一种中间语言，运行在 CLR（公共语言运行库）上；非托管代码被编译为机器码，运行在机器上。 托管代码独立于平台和语言，能更好的实现不同语言平台之间的兼容；非托管代码依赖于平台和语言。 托管代码可享受 CLR 提供的服务（如安全检测、垃圾回收等），不需要自己完成这些操作；非托管代码需要自己提供安全检测、垃圾回收等操作。 托管代码与非托管代码 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础-README]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2FREADME%2F</url>
    <content type="text"><![CDATA[Java 特性（与 C++ 比较） Java 数据类型 方法调用过程 数组的复制 基本类型变量和引用类型变量 类的静态变量与方法 不可变对象和类 this引用 多态与动态绑定 异常处理 文本IO与二进制IO- [Ads](#ads) Java 特性（与 C++ 比较）核心特性： 跨平台性：Java 一次编译可到处运行 自动内存管理：Java 没有指针，内存管理依靠垃圾自动回收 完全面向对象：所有函数和变量必须是类的一部分 其他特性： 强制异常规约 内置字符串：Java 有内置类型 操作符重载：不支持操作符重载 执行速度慢 不支持多重继承 不支持默认函数参数 不支持 goto 语句 Java 数据类型JAVA 有八种基础的数据类型： 整数型：byte(8 bits)、short(16 bits)、int(32 bits)、long(64 bits) 浮点型：float(32 bits)、double(64 bits) 字符型：char(16 bits) 布尔型：boolean 方法调用过程当调用一个方法时，系统将参数和局部变量存储在一个称为堆栈的内存区域中；当一个方法调用另一个方法时，调用者的堆栈保持不动，新开辟的堆栈处理新方法的调用；当一个方法结束返回到调用者时，其相应空间被释放。 数组的复制复制数组一般有三种方法： 使用循环语句逐个复制数组的元素 使用 System 类的静态方法 arraycopy 使用 clone 方法复制数组 浅拷贝：使用一个已知实例对新创建实例的成员变量逐个赋值，这个方式被称为浅拷贝。 深拷贝：当一个类的拷贝构造方法，不仅要复制对象的所有非引用成员变量值，还要为引用类型的成员变量创建新的实例，并且初始化为形参实例的值。这个方式称为深拷贝。 基本类型变量和引用类型变量每个变量都代表一个存储值的内存位置，声明一个变量时就是在告诉编译器该变量存储何种类型的值。 对基本类型变量而言，存储值是基本类型，对引用类型变量而言，对应内存所存储值是一个对象的引用，即对象的存储地址。 当一个变量赋值给另一个变量时，对基本类型变量而言，就是将一个变量的实际值赋给了另一个变量；对引用类型变量而言，是将一个变量的引用赋给了另一个变量。 类的静态变量与方法 类的静态变量被同一个类的所有实例所共享。 可以在不使用实例的情况下调用静态方法。（一般通过类名.方法名调用，无须创建对象） 类的每一个实例都能访问该类的静态变量与静态方法。 实例变量与实例方法只能在实例方法中使用，不能在静态方法中使用。 不可变对象和类通常创建一个对象后，其内容是允许随后改变的。但是有时也需要创建一个一旦创建，其内容就不能再改变的对象。这种对象称为不可变对象，而它的类成为不可变类。 要使一个类成为不可变的，必须满足如下要求： 所有数据域都是私有的。 没有修改器方法。 没有一个访问器方法，它会返回一个指向可变数据域的引用。 this引用关键字 this 指向调用对象本身的引用名，有两种常用的使用场景： 在 set 方法中引用隐藏数据域（如this.name = name） 让构造方法调用同一个类的另外一个构造方法 多态与动态绑定多态的定义：父类型的变量可以引用子类型的对象 声明类型：引用变量在声明时的类型 实际类型：引用变量所指向的对象的实际类 当从引用变量调用实例方法时，由该引用变量的实际类型在运行时决定使用该方法的哪个实现；当引用变量访问数据域和静态方法时，由该引用变量的声明类型在编译时决定使用哪个方法。 异常处理异常处理的优势在于把“检测错误”从“处理错误”中分离出来。 免检异常：RuntimeException、Error 以及其子类都是免检异常，通常反映程序中不可恢复的逻辑错误 必检异常：除免检异常外的所有异常称为“必检异常”，编译器强制要求程序员处理的异常。 常见的几种异常如下： NullPointerException - 空指针引用异常 ClassCastException - 类型强制转换异常。 IllegalArgumentException - 传递非法参数异常。 ArithmeticException - 算术运算异常 ArrayStoreException - 向数组中存放与声明类型不兼容对象异常 IndexOutOfBoundsException - 下标越界异常 NegativeArraySizeException - 创建一个大小为负数的数组错误异常 UnsupportedOperationException - 不支持的操作异常 文本IO与二进制IOIO类分为文本IO与二进制IO，前者将数据解释成字符序列，后者将数据解释成原始的二进制数值。 文本IO建立在二进制IO的基础之上，提供字符层面的编解码的抽象。当文本IO向文件写入一个字符时，JVM会自动把统一码转为文件指定的编码，而读取字符时把文件指定的编码转换为统一码。 二进制IO不需要转换编码，当二进制IO向文件写入一个数值，就是将内存中的确切值复制到文件中。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring基础装配]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2FSpring%E5%9F%BA%E7%A1%80%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[自动化装配 使用 Java 代码装配 bean- [1. 创建配置类](#1-创建配置类) - [2. 声明简单的 bean](#2-声明简单的-bean) - [3. 借助 JavaConfig 实现注入](#3-借助-javaconfig-实现注入) 通过 XML 装配 bean 1. 创建XML装配规范 2. 声明一个简单的 bean 3. 借助构造器注入初始化 bean 使用&lt;constructor-arg&gt;声明 使用c-命名空间 4. 属性注入 p-命名空间 Ads Spring 提供了三种主要的装配机制来描述对 bean 的装配： 在 XML 中进行显式配置 在 Java 中进行显式配置 隐式的 bean 发现机制和自动装配 自动化装配Spring 从两个角度实现自动化装配： 组件扫描：Spring 会自动发现应用上下文中所创建的 bean 自动装配：Spring 自动满足 bean 之间的依赖 以下以 CD 播放器为例阐述如何进行自动化装配：首先创建 CD 类，让 Spring 将其自动创建为 bean，然后创建一个 CDPlayer 类，让 Spring 把 CD bean 注入进来。 1234567891011/* 创建CD类并声明为bean */package main;import org.springframework.stereotype.Component;@Component // 该注解把该类声明为bean,也可以用Component(&quot;name&quot;)形式进行命名public class CD &#123; private String message = &quot;this is my cd&quot;; public void play()&#123; System.out.println(message); &#125;&#125; 但组件扫描是默认不启用的，因此还需要显式配置 Spring 从而让其寻找带有 @Component 注解的类并为其创建 bean。类 CDPlayerConfig 通过 Java 代码而非配置文件来定义了装配规则（虽然为空），并使用了 @ComponentScan 注解启用了组件扫描。 12345678package main;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;@Configuration@ComponentScanpublic class CDPlayerConfig &#123;&#125; @ComponentScan 默认会以配置类所在的包作为基础包来扫描组件。若想扫描多个基础包，则可以设置注解的属性如@ComponentScan(basePackages={&quot;soundsystem&quot;,&quot;video&quot;}) 创建了这两个类后，现在我们可以对功能进行测试，观察 bean 是否注入成功。12345678910111213141516171819202122package main;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import static org.junit.Assert.*;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = CDPlayerConfig.class) // 该注解指定从哪个配置类加载配置public class CDPlayerTest &#123; // 使用 Autowird 自动装配；该注解可适用于类的任何方法上 // 若有且只有一个bean匹配依赖需求的话，则spring会加载这个bean；否则会抛出异常 @Autowired private CD cd; @Test public void myTest()&#123; assertNotNull(cd); &#125;&#125; 使用 Java 代码装配 bean虽然很多场景下通过组件扫描和自动装配实现 Spring 的自动化配置是更为推荐的方式，但有时自动化配置的方案行不通，因此需要显式地配置 Spring。显式配置有两种方案：Java 和 XML，其中 JavaConfig 由于更为强大、类型安全以及对重构友好，因此是较好的方案。 1. 创建配置类创建 JavaConfig 类的关键在于为其添加 @Configuration 注解，表明该类是一个配置类，该类应该包含在 Spring 应用上下文中如何创建 bean 的细节。 12345import org.springframework.context.annotation.Configuration;@Configurationpublic class CDPlayerConfig&#123;&#125; 2. 声明简单的 bean在 JavaConfig 中声明 bean，需要编写一个方法，该方法会创建所需类型的实例，然后为这个方法添加 @Bean 注解。@Bean 注解会告诉 Spring 这个方法会返回一个对象，该对象注册为 Spring 应用上下文中的 bean。 12345// 声明一个返回CD类型的实例的bean@Beanpublic CD sgtPeppers()&#123; return new SgtPeppers(); //此处SgtPeppers是CD的子类&#125; 默认情况下 bean 的 ID 与带有 @Bean 注解的方法名是一样的，也可以通过 @Bean(name=”name”) 的形式为其命名。 3. 借助 JavaConfig 实现注入在配置中，我们往往需要声明一个依赖于其他 bean 的 bean，因此在声明一个复杂的 bean 时往往也需要同时注入其他的 bean。 装配 bean 的最简单方式是引用创建 bean 的方法： 1234@Bean // 带有@Bean注解的方法可以采用任何必要的Java功能来产生bean实例public CDPlayer cdPlayer()&#123; return new CDPlayer(sgtPeppers());// sgtPeppers()是已经声明的、被@Bean所注解的方法&#125; 看起来 CD 是通过 sgtPeppers() 得到的，但实际上，由于 sgtPeppers() 方法上添加了 @Bean 注解，Spring 会拦截所有对它的调用，确保直接返回该方法的 bean，而不是每次都进行实际的调用。默认情况下，Spirng 中的 bean 都是单例。 但也可用以下更容易理解的方式来装配 bean： 123456@Beanpublic CDPlayer cdPlayer(CD cd)&#123; CDPlayer cdPlayer = new CDPlayer(cd); cdPlayer.setCD(cd); return cdPlayer;&#125; 此处 cdPlayer() 方法请求一个 CD 实例作为参数，当 Spring 调用 cdPlayer() 创建 CDPlayer bean 时，它会自动装配一个 CD bean 到配置方法中，而无需明确引用 CD 的 @Bean 方法。通过该方式引用其它的 bean 是最佳选择（因为它不会要求将 CD bean 声明到同一个配置类中，这样可以实现分散配置文件）。 通过 XML 装配 beanSpring 目前有了强大的自动化配置和基于 Java 的配置，XML不再是第一选择了。但是鉴于已经存在那么多基于 XML 的 Spring 配置，因此理解如何在 Spring 中使用 XML 还是很重要的。 1. 创建XML装配规范最简单的 XML 配置如下： 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context&quot;&gt; &lt;!-- configuration details go here --&gt;&lt;/beans&gt; 用于装配 bean 的最基本的 XML 元素包含在 spring-beans 模式中，它被定义为根命名空间。&lt;beans&gt; 是该模式中的一个元素，是所有 Spring 配置文件的根元素。 2. 声明一个简单的 bean使用&lt;bean&gt;元素声明一个 bean，并设置 id 进行命名：1&lt;bean id=&quot;cd1&quot; class=&quot;soundSystem.SgtPeppers&quot; /&gt; 3. 借助构造器注入初始化 bean使用构造器注入 bean 引用时，有两种基本配置方案可选择： &lt;constructor-arg&gt; 元素，特点是配置比较冗长 使用 Spring 3 所引入的 c-命名空间，特点是配置比较简练，但无法装配集合 使用&lt;constructor-arg&gt;声明1234/* 声明CDPlayer并通过id引用已有的SgtPerpers bean*/&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot;&gt; &lt;constructor-arg ref=&quot;sgtPerpers&quot; /&gt;&lt;/bean&gt; 当 Spring 遇到&lt;bean&gt;元素时，会创建一个 CDPlayer 实例，&lt;constructor-arg&gt; 元素表明要将一个 id 为 sgtPerpers 的 bean 引用传递到 CDPlayer 的构造器中。 当把字面量注入构造器而不是引用时： 123&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot;&gt; &lt;constructor-arg value=&quot;The Love&quot; /&gt;&lt;/bean&gt; 使用c-命名空间在 XML 顶部声明其模式：xmlns:c=&quot;http://www.springframework.org/schema/c&quot;，就可用其来声明构造器参数了。 一个典型的示例是 c:cd-ref=&quot;compactDisc&quot;，属性名以 c: 开头，即命名空间前缀，接下来是要装配的构造器参数名，之后是-ref，表示装配的是一个 bean 的引用，这个 bean 的 ID 为 compactDisc。 也可使用参数索引替代直接使用参数名的方案，如： 12&lt;!-- 由于xml不允许数字作为属性的首字符，因此添加一个下划线作后缀 --&gt;&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot; c:_0-ref=&quot;compactDisc&quot; /&gt; 也可以根本不标示参数（前提是只有一个构造器参数），如： 1&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot; c:_-ref=&quot;compactDisc&quot; /&gt; 当需要注入字面量而不是 bean 引用时： 方案一：引用构造器参数的名字 123&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot; c:_title=&quot;My Love&quot; c:_artist=&quot;ZZP&quot;&gt; 方案二：使用参数索引 123&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot; c:_0=&quot;My Love&quot; c:_1=&quot;ZZP&quot;&gt; 4. 属性注入假设需要属性注入的 CDPlayer 如下所示：12345678public class CDPlayer &#123; private CD cd; @Autowired pulic setCd(CD cd)&#123; this.cd = cd; &#125;&#125; 声明为一个 bean：123&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot;&gt; &lt;property name=&quot;cd&quot; ref=&quot;cd&quot;&gt;&lt;/bean&gt; &lt;property&gt;元素为属性的 Setter 方法所提供的功能与 &lt;constructor-arg&gt; 提供的功能是一样的。本例中它引用了 ID 为 CD 的 bean（通过 ref 属性），并将其注入到 cd 属性中（通过 setCD() 方法）。 p-命名空间 p-命名空间是作为&lt;property&gt;元素的替代方案，使用时需在 XML 顶部声明其模式：xmlns:p=&quot;http://www.springframework.org/schema/p&quot;。 123456&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot; p:cd-ref=&quot;cd&quot;/&gt;&lt;!-- 首先属性的名字使用了&quot;p:&quot;前缀，表面设置的是一个属性；接下来是要注入的属性名，最后属性名称以&quot;-ref&quot;结尾，表明装配的是一个引用而非字面量。--&gt; 当需要注入字面量时，区别在于是否带有”-ref”后缀： 1234&lt;bean id=“cdPlayer” class=&quot;soundSystem.CDPlayer&quot; p:title=&quot;My Love&quot; p:artist=&quot;ZZP&quot;/&gt; 注意：p-命名空间同样无法装配集合，但可以通过 util-命名空间（用于创建集合类型的bean）辅助实现装配集合的功能。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring概述]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2FSpring%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[概述 依赖注入（DI） 面向切面编程（AOP） Spring 容器 应用上下文 bean 的生命周期 Spring 其他模块- [Spring 容器](#spring-容器-1) - [AOP 模块](#aop-模块) - [数据访问和集成](#数据访问和集成) - [Web 与远程调用](#web-与远程调用) - [测试](#测试) - [Ads](#ads) 概述Spring 是一个为了解决企业级应用开发的复杂性而创建的开源框架。Spring 不仅仅局限于服务器端开发，任何 Java 应用都能在简单性、可测试性和松耦合等方面从 Spring 中获益。简化 Java 开发是 Spring 最根本的使命。 为了降低 Java 开发的复杂性，Spring 采取了以下策略： 基于 POJO 的轻量级和最小侵入性编程（侵入性：强迫应用继承框架的类或接口从而和框架绑死） 通过依赖注入和面向接口实现松耦合 基于切面和惯例进行声明式编程 通过切面和模板减少样板式代码 依赖注入（DI）任何一个有实际意义的应用都由两个以上的类组成，这些类互相协作来完成特定的业务逻辑。但如果按照传统的做法，让每个对象负责管理与自己相互协作的对象（即所依赖的对象）的引用，将会导致高度耦合和难以测试的代码。 耦合具有两面性：一方面紧密耦合的代码难以测试与复用，另一方面一定程度的耦合是必须的——完全没有耦合的代码什么也做不了。因此耦合是必须的，但应当谨慎管理。 通过依赖注入（DI），对象的依赖关系将由系统中负责协调各对象的第三方组件在创建对象的时候进行设定，对象无需自行创建或管理它们的依赖关系，从而实现松耦合。而且如果一个对象只通过接口（而非具体实现）来表明依赖关系，则这种依赖就能在对象本身无感知的情况下，用不同的具体实现进行替换。 创建应用组件之间协作的行为称为装配。Spring 有多种装配 bean 的方式，其中使用 XML 配置文件是一种常见的装配方式。 12345678910111213141516&lt;!-- knignt.xml --&gt;&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd"&gt;&lt;!-- 注入Quest bean --&gt;&lt;bean id="knight" class="com.war.knights.BravaKnight"&gt; &lt;constructor-arg ref="quest" /&gt;&lt;/bean&gt;&lt;!-- 创建SavaGirlQuest bean --&gt;&lt;bean id="quest" class="com.war.knights.SavaGirlQuest"&gt; &lt;constructor-arg value="Mary" /&gt;&lt;/bean&gt;&lt;/beans&gt; Spring 也支持使用 Java 注解 来描述配置。1234567891011121314151617181920import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.war.knights.Knight;import com.war.knights.BraveKnight;import com.war.knights.Quest;import com.war.knights.SaveGirlQuest;@Configurationpublic class KnightConfig&#123; @Bean public Knight knight()&#123; return new BraveKnignt(quest()); &#125; @Bean public Quest quest()&#123; return new SaveGirlQuest(&quot;Mary&quot;); &#125;&#125; Spring 通过应用上下文（Application Context）装载 bean 的定义并把它们组装起来。Spring 有多种应用上下文的实现，主要区别在于用何种方式加载配置。 1234567891011121314// 使用上下文加载配置文件并读取beanimport org.springframework.context.support.ClassPathXmlApplicationContext;public class KnightMain&#123; public static void main(String[] args) throws Exception&#123; // 加载上下文 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;META-INF/spring/knight.xml&quot;); // 获取 knight bean Knight knight = context.getBean(Knight.class); // 使用 knight knight.embarkOnQuest(); context.close(); &#125;&#125; main() 方法基于 knight.xml 文件创建了 Spring 应用上下文，并调用上下文获取了 ID 为 knight 的 bean。注意：该类完全不知道骑士接受何种探险任务，而且完全没有意识到是由 BraveKnight 来执行的，只有 knight.xml 知道哪个骑士执行哪种探险任务。 面向切面编程（AOP）DI 能够让相互协作的软件实体保持松耦合，而 AOP 则允许把遍布应用组件各处的系统职责从组件中分离出来。 系统由不同组件组成，每个组件负责一块特定功能。除了实现自身核心的功能外，这些组件还经常承担着额外职责（诸如日志、事务管理、安全等，这些额外的职责经常融入到自身具有核心业务逻辑的组件中去）。这些需额外承担的系统服务被称为横切关注点，因为它们会跨越系统的多个组件。 如果按照传统方式把这些关注点分散到多个组件中去，则代码会有双重的复杂性： 实现系统关注点功能的代码重复出现在多个组件中（即使把关注点抽象为了一个独立模块，其他模块只是调用其方法，但方法的调用还是会重复出现在各个模块中）。 组件会因为那些与自身核心业务逻辑无关的代码而变得混乱。 AOP 能够使这些服务模块化，并以声明的方式把它们应用到它们需要影响的组件中去。这样做的好处在于：这些组件会具有更高的内聚性与简单性（组件甚至不知道系统服务的存在）。 下列 xml 文件使用了 Spring 的 aop 配置把 minstrel bean 声明为一个切面，以及声明 minstrel bean 的 embarkOnQuest 方法作为切点，并声明了切点执行时的前置方法与后置方法。12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd&quot;&gt;&lt;!-- 声明 minstrel --&gt;&lt;bean id=&quot;minstrel&quot; class=&quot;com.war.knights.Minstrel&quot;&gt; &lt;constructor-arg ref=&quot;a common minstrel&quot; /&gt;&lt;/bean&gt;&lt;aop:config&gt; &lt;aop:aspect ref=&quot;minstrel&quot;&gt; &lt;!-- 定义切点 --&gt; &lt;aop:pointcut id=&quot;embark&quot; expression=&quot;execution(* *.embarkOnQuest(..))&quot;/&gt; &lt;!-- 声明前置通知 --&gt; &lt;aop:before pointcut-ref=&quot;embark&quot; method=&quot;singBeforeQuest&quot;/&gt; &lt;!-- 声明后置通知 --&gt; &lt;aop:after pointcut-ref=&quot;embark&quot; method=&quot;singAfterQuest&quot;/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;&lt;/beans&gt; Spring 容器在基于 Spring 的应用中，应用对象生存于 Spring 容器中。Spring 容器负责创建、装配和配置对象，并管理它们的整个生命周期。Spring 容器使用 DI 管理构成应用的组件，它会创建相互协作的组件之间的关联。 Spring 自带了两种类型的容器实现： BeanFactory（bean 工厂）：最简单的容器，提供基本的 DI 支持。 Application Context（应用上下文）：基于 BeanFactory 构建，并提供应用框架级别的服务。开发者一般使用应用上下文而非底层的 bean 工厂。 应用上下文Spring 自带了多种类型的应用上下文： AnnotationConfigApplicationContext：从一个或多个基于 Java 的配置类中加载 Spring 应用上下文 AnnotationConfigWebApplicationContext：从一个或多个基于 Java 的配置类中加载 Spring Web 应用上下文 ClassPathXmlApplicationContext：从类路径下的一个或多个 XML 配置文件中加载上下文定义 FileSystemXmlapplicationcontext：从文件系统下一个或多个 XML 配置文件加载上下文定义 XmlWebApplicationContext：从 Web 应用下的一个或多个 XML 配置文件加载上下文定义 上下文加载完毕后，就可以调用上下文的 getBean() 方法从 Spring 容器中获取 bean。 bean 的生命周期 ApplicationContext 容器中，Bean 的生命周期流程如上图所示，流程大致如下： 容器启动，对 scope 为 singleton 且非懒加载的 bean 进行实例化 按照 Bean 定义信息配置信息，注入所有的属性 如果 Bean 实现了 BeanNameAware 接口，会回调该接口的 setBeanName() 方法，传入该 Bean 的 id ，此时该 Bean 就获得了自己在配置文件中的 id 如果 Bean 实现了 BeanFactoryAware 接口,会回调该接口的 setBeanFactory() 方法，传入该 Bean 的 BeanFactory ，这样该 Bean 就获得了自己所在的 BeanFactory 如果 Bean 实现了 ApplicationContextAware 接口,会回调该接口的 setApplicationContext() 方法，传入该 Bean 的 ApplicationContext，这样该 Bean 就获得了自己所在的 ApplicationContext 如果 Bean 实现了 BeanPostProcessor 接口，则会回调该接口的 postProcessBeforeInitialzation() 方法 如果 Bean 实现了 InitializingBean 接口，则会回调该接口的 afterPropertiesSet() 方法 如果 Bean 配置了 init-method 方法，则会执行 init-method 配置的方法 如果 Bean 实现了 BeanPostProcessor 接口，则会回调该接口的 postProcessAfterInitialization() 方法 经过流程9之后，就可以正式使用该 Bean 了。对于 scope 为 singleton 的 Bean，Spring 的 IOC 容器中会缓存一份该 bean 的实例，而对于 scope 为 prototype 的 Bean，每次被调用都会 new 一个新的对象，其生命周期就交给调用方管理了，不再由 Spring 容器进行管理了 容器关闭后，如果 Bean 实现了 DisposableBean 接口，则会回调该接口的 destroy() 方法 如果 Bean 配置了 destroy-method 方法，则会执行 destroy-method 配置的方法。至此，整个Bean的生命周期结束 Spring 其他模块Spring 框架除了 DI 与 AOP 以外还有着其他大量模块，所有模块共同组成了一个构建在 Spring 核心框架之上的庞大生态圈。这些模块依据其所属功能可划分为六类。 Spring 容器容器是 Spring 框架最核心的部分，用于执行 bean 的创建、配置与管理。该模块包括了 bean 工厂，它为 Spring 提供了 DI 的功能。基于 bean 工厂，还有多种 Spring 应用上下文的实现，每一种都提供了配置 Spring 的不同方式。 AOP 模块AOP 可以把遍布系统的关注点（如事务和安全）从它们所应用的对象中解耦出来。 数据访问和集成提供了模板化的 JDBC，并在多种数据库服务的错误信息上构建了语义丰富的异常层。以及允许使用 ORM 框架。 Web 与远程调用Web 与远程调用模块提供了自带的 MVC 框架，此外还提供了多种构建与其他应用交互的远程调用方案，以及对 REST API 的良好支持。 测试提供了自带的测试模块（如一系列的 mock 对象实现） 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Java 多线程 创建任务和线程 Thread类 线程池 线程同步 同步语句 利用加锁同步 Volatile 关键字- [使用场景](#使用场景) 线程间协作 避免死锁- [Ads](#ads) Java 多线程一个程序可能包含多个并发运行的任务，线程是指一个任务从头至尾的执行流。Java 可以在一个程序中并发地启动多个线程，这些线程可以在多处理器系统上同时运行。 创建任务和线程任务就是对象。为了创建任务，必须为任务定义一个实现了 Runnable 接口的类。Runnable 接口只包含了一个 run 方法，该方法告诉系统线程如何运行。 1234567public class TaskClass implements Runnable&#123; public TaskClass()&#123;&#125; public void run()&#123; // Tell system how to run custom thread &#125;&#125; 运行线程：123TaskClass task = new TaskClass(); //根据任务类，创建任务Thread thread = new Thread(task); //创建任务的线程thread.start(); //启动线程 Thread类Thread 类包含为任务而创建的线程的构造方法，以及控制线程的方法。 方法 yield()：可为其他线程临时让出 CPU 时间。 方法 sleep(long mills)：可以将线程设置为休眠以确保其他线程的执行，休眠时间为指定的毫秒数。也可能抛出必检异常，因此需要放到 try-catch 块中。 方法 join()：使一个线程等待另一个线程的结束。 Java 为每个线程都指定了一个优先级（1~10），可用 setPriority 方法设置优先级，用 getPriority 方法获取优先级。JVM 总是选择当前优先级最高的可运行线程，较低优先级的线程只有在没有比它更高优先级的线程运行时才能运行。 注：由于 Thread 类也实现了 Runnable 接口，所以可以定义一个 Thread 的扩展类，在里面实现 run 方法来实现线程。但不推荐使用这种方式，因为把任务和运行任务的机制混在了一起。把任务从线程中分离出来是比较好的选择。 线程池对于大量的任务而言，为每一个任务开始一个新线程是不够高效的。线程池是管理并发执行任务个数的理想办法。Java 提供 Executor 接口来执行线程池里的任务，提供 ExecutorService 接口来管理和控制任务。 1234567891011121314151617181920import java.util.concurrent.*;public class ExecutorDemo&#123; public static void main(String[] args)&#123; // 创建一个固定线程数的线程池 ExecutorService executor = Executors.newFixedThreadPool(3); // 或者按需创建线程池 // ExecutorService executor = Executors.newCachedThreadPool(); // 执行任务（PrintChar实现了Runnable接口） executor.execute(new PrintChar(&apos;a&apos;,100)); executor.execute(new PrintChar(&apos;b&apos;,100)); executor.execute(new PrintChar(&apos;c&apos;,100)); // 关闭执行器，之后便不能接受新的任务 executor.shutdown(); // 判断所有任务是否已结束，返回boolean型 executor.isTerminated(); &#125;&#125; 线程同步如果一个共享资源被多个线程同时访问，可能会遭到破坏。当任务1和任务2以一种会引起冲突的方式访问一个公共资源时，该问题称为竞争状态。如果一个类的对象在多线程程序中没有导致竞争状态，则称这样的类是线程安全的。 为了避免竞争状态，应该防止多个线程同时进入程序的某一特定部分，这部分称为临界区。通过使用关键字 synchronized 来同步方法，以便一次只有一个线程可以访问该方法。如：public synchronized void deposit(double amount)。 一个同步方法在执行之前需要加锁；调用一个对象的同步实例方法要求给该对象加锁；调用一个类的同步静态方法要求对该类加锁。如果一个线程调用一个对象上的同步实例方法（静态方法），首先给该对象（类）加锁，然后执行该方法，最后解锁。在解锁之前，另一个调用该对象（类）中该方法的线程将会被阻塞。 同步语句当执行方法中某一个代码块时，同步语句不仅可用于对 this 对象加锁，而且可用于对任何对象加锁。这个代码块称为“同步块”。由于同步语句允许设置同步方法中的部分代码而不必是整个方法，从而大大增强了程序的并发能力。 123synchronized(expr)&#123; statements;&#125; 表达式 expr 必须求出对象的引用。若对象已经被另一个线程锁定，则在解锁之前，该线程将被阻塞。当获准对一个对象加锁时，该线程执行同步块中语句，然后解除给对象加的锁。 1234567891011/* 任何同步实例方法可转换为同步语句。 以下两个实例方法是等价的。 */public synchronized void xMethod()&#123; // method body&#125;public void xMethod()&#123; synchronized(this)&#123; // method body &#125;&#125; 利用加锁同步同步的实例方法在执行方法之前都隐式地加锁，而 Java 也可以显式地加锁。 一个锁是一个 Lock 接口的实例，它定义了加锁和释放锁的方法。ReentrantLock 类是为创建互斥锁的 Lock 的具体实现。 123456789101112131415161718192021222324import java.util.concurrent.locks.*public class Account&#123; private static Lock lock = new ReentrantLock(); private int balance = 0; public int getBalancs()&#123; return this.balance; &#125; public void deposit(int amount)&#123; lock.lock(); // 加锁 try&#123; int newBalance = balance + amount; Thread.sleep(5); balance = newBalance; &#125; catch(InterruptedException ex)&#123; &#125; finally&#123; lock.unlock(); // 解锁 &#125; &#125; &#125; Volatile 关键字Java 提供了一种稍弱的同步机制，即 volatile 变量，用来确保将变量的更新操作立刻对其他线程可见。当把变量声明为 volatile 类型后，编译器与 JVM 都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序，也不会使该变量被线程缓存。因此在读取 volatile 类型的变量时总会返回最新写入的值。volatile 修饰的变量不允许被线程缓存和重排序（不被缓存即直接修改内存），因此对其他线程实现了可见性。 指令重排序是编译器或运行时环境为了优化程序性能而采取的对指令进行重新排序执行的一种手段，因此多线程下指令执行的顺序可能是无法预测的。指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 在访问 volatile 变量时不会执行加锁操作，也就不会使执行线程阻塞。因此 volatile 变量是一种比 sychronized 关键字更轻量级的同步机制。 读写非 volatile 变量时，每个线程先从内存拷贝变量到 CPU 缓存中。如果计算机有多个 CPU ，每个线程可能在不同的 CPU 上被处理，这意味着每个线程可以拷贝到不同的 CPU cache 中。而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache 这一步。 注意：volatile 只能让其所修饰的变量具有可见性（即更新后的操作会立即对其他线程可见），但不能保证具有原子性，因此也会有线程安全的问题。 使用场景synchronized 关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而 volatile 关键字在某些情况下性能要优于 synchronized ，但要注意 volatile 关键字是无法替代 synchronized 关键字的，因为 volatile 关键字无法保证操作的原子性。 通常来说，使用 volatile 必须具备以下条件： 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 volatile 详解 线程间协作通过保证在临界区上多个线程的相互排斥，线程同步完全可以避免竞争状态的发生，但是有时还需要线程之间的相互协作。Java 中使用条件来便于线程间通信，一个线程可以指定在某种条件下该做什么。 条件是通过调用 Lock 对象的 newCondition() 方法而创建的对象，一旦创建了条件，就可以使用 await()、signal()、signalAll() 方法来实现线程间的互相通信： await()：让当前线程处于等待状态，直到被唤醒 signal()：唤醒一个等待的线程 signalAll()：唤醒所有等待的线程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import java.util.concurrent.*;import java.util.concurrent.locks.*;public class TestLockCondition &#123; private static Account account = new Account(); public static void main(String[] args) &#123; System.out.println(&quot;Thread 1\t\tThread 2\t\tBalance&quot;); ExecutorService executor = Executors.newFixedThreadPool(2); executor.execute(new DepositTask()); executor.execute(new SubstactTask()); executor.shutdown(); &#125; public static class DepositTask implements Runnable&#123; @Override public void run() &#123; try&#123; while(true)&#123; account.deposit((int)(Math.random() * 10) + 2); Thread.sleep(2000); &#125; &#125; catch(Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125; public static class SubstactTask implements Runnable&#123; @Override public void run() &#123; while(true)&#123; account.substract((int)(Math.random() * 10)+1); &#125; &#125; &#125; public static class Account&#123; private int balance = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public int getBalance()&#123; return balance; &#125; public void substract(int amount)&#123; lock.lock(); try&#123; while(amount &gt; balance)&#123; System.out.println(&quot;\t\t\twait for a deposit&quot;); condition.await(); &#125; balance -= amount; System.out.println(&quot;\t\t\tSubstract &quot; + amount +&quot;\t\t&quot; + getBalance()); &#125; catch(Exception e)&#123; e.printStackTrace(); &#125; finally&#123; lock.unlock(); &#125; &#125; public void deposit(int amount)&#123; lock.lock(); try&#123; balance += amount; System.out.println(&quot;Deposit &quot; + amount +&quot;\t\t\t\t\t&quot; + getBalance()); condition.signalAll(); &#125; finally&#123; lock.unlock(); &#125; &#125; &#125;&#125; 一旦线程调用条件上的 await()，线程就进入等待状态，等待恢复的信号。如果忘记调用 signal()、signalAll() ，那么线程将永久等待下去。 条件由 Lock 对象所创建，为了调用 await()、signal()、signalAll() 等方法，必须首先获取该条件对应的锁。如果没有获取锁就调用这些方法就会抛出异常。 避免死锁有时两个或多个线程需要在几个共享对象上获取锁，可能会导致死锁，即：每个线程已经锁定一个对象，而且正在等待锁定另一个对象。 使用资源排序可以轻易地避免死锁的发生。该技术是给每一个需要锁的对象指定一个顺序，确保每个线程都按照这个顺序来获得锁。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E6%B3%9B%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[泛型 泛型类和泛型方法 原始类型和向后兼容 通配泛型 消除泛型与使用泛型的限制 备注 Ads 泛型泛型是指参数化类型的能力。定义了带泛型类型的类或方法，在编译过程中编译器会用具体类型替换它。主要优点在于能够在编译时而不是在运行时检测出错误。 123456789/* 使用泛型前 */public interface Comparable&#123; public int compareTo(object o);&#125; /* 使用泛型后 */public interface Comparable&lt;T&gt;&#123; public int compareTo(T o);&#125; 泛型类和泛型方法 为了定义一个类为泛型类型，需要将泛型类型放在类名之后，如：GenericStack&lt;E&gt;。 受限泛型类型：可将泛型制定为另外一种类型的子类型。如：&lt;E extends GeometricObject&gt;。 为了定义一个方法为泛型类型，需要把泛型类型放在方法返回类型之前，如&lt;E&gt; void max(E o1,E o2)。 为了调用泛型方法，需要将实际类型放在尖括号内作为方法名的前缀，如GenericStack.&lt;String&gt;print(strings)。 原始类型和向后兼容 使用泛型类时可以无需指定具体类型，如：GenericStack stack = new GenericStack();，其大体等价于GenericStack&lt;Object&gt; stack = new GenericStack&lt;Object&gt;();。 像 GenericStack 和 ArrayList 这样不使用类型参数的泛型类称为”原始类型“。 原始类型并不安全，但使用原始类型是为了向后兼容 JDK 较早的版本。 通配泛型 尽管 Integer 是 Number 的子类型，但是 GenericStack&lt;Interger&gt;并不是GenericStack&lt;Number&gt;的子类型。为了避免该问题，可以使用通配泛型类型。 通配泛型有三种形式?、? extends T和? super T（此处的T代表某个泛型类型）： ?：称为非受限通配，等价于? extends Object。 ? extends T：称为受限通配，代表T的一个未知子类型。 ? super T：称为下限通配，表示T的一个未知父类型。 消除泛型与使用泛型的限制泛型是使用一种称为类型消除的方法来实现的：在编译时一旦编译器确认泛型类型是安全的，就会将它转换为原始类型。123456789/*编译器转换前*/ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add("Trump");String state = list.get(0);/*编译器转换后*/ArrayList list = new ArrayList();list.add("Trump");String state = (String)(list.get(0)); 由于泛型在运行时已被消除，因此对于如何使用泛型类型是有一些限制的： 不能使用new E()。 不能使用new E[]。 在静态环境下不允许类的参数是泛型类型。 异常类不能是泛型的。 备注 泛型类型必须是引用类型 尽管在编译时ArrayList&lt;String&gt;与ArrayList&lt;Integer&gt;是两种类型，但是在运行时只有一个 ArrayList 类会被加载到 JVM 中 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式——单例模式]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式 遇到的问题 饿汉式单例 懒汉式单例 两种单例实现方式比较 一种更好的单例实现方法——IoDH 单例模式总结 Ads 单例模式在实际开发中，我们经常遇到这种情况：为了节约系统资源，有时需要确保系统中某个类只有唯一一个实例，当这个唯一实例创建成功之后，我们无法再创建一个同类型的其他对象，所有的操作都只能基于这个唯一实例。为了确保对象的唯一性，我们可以通过单例模式来实现。 单例模式(Singleton Pattern)：确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，则这个类称为单例类，它提供全局访问的方法。单例模式是一种对象创建型模式。 单例模式结构图中只包含一个单例角色： Singleton（单例）：在单例类的内部实现只生成一个实例，同时它提供一个静态的 getInstance() 工厂方法，让客户可以访问它的唯一实例；为了防止在外部对其实例化，将其构造函数设计为私有；在单例类内部定义了一个 Singleton 类型的静态对象，作为外部共享的唯一实例。 遇到的问题一个负载均衡器作为单例设计如下。 123456789101112131415161718192021222324252627282930313233343536373839import java.util.*; //负载均衡器LoadBalancer：单例类，真实环境下该类将非常复杂，包括大量初始化的工作和业务方法，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码 class LoadBalancer &#123; //私有静态成员变量，存储唯一实例 private static LoadBalancer instance = null; //服务器集合 private List serverList = null; //私有构造函数 private LoadBalancer() &#123; serverList = new ArrayList(); &#125; //公有静态成员方法，返回唯一实例 public static LoadBalancer getLoadBalancer() &#123; if (instance == null) &#123; instance = new LoadBalancer(); &#125; return instance; &#125; //增加服务器 public void addServer(String server) &#123; serverList.add(server); &#125; //删除服务器 public void removeServer(String server) &#123; serverList.remove(server); &#125; //使用Random类随机获取服务器 public String getServer() &#123; Random random = new Random(); int i = random.nextInt(serverList.size()); return (String)serverList.get(i); &#125; &#125; 使用单例模式实现了如上的负载均衡器的设计，但是在实际使用中出现了一个非常严重的问题，当负载均衡器在启动过程中用户再次启动该负载均衡器时，系统无任何异常，但当客户端提交请求时出现请求分发失败，通过仔细分析发现原来系统中还是存在多个负载均衡器对象，导致分发时目标服务器不一致，从而产生冲突。 现在我们对负载均衡器的实现代码进行再次分析，当第一次调用 getLoadBalancer() 方法创建并启动负载均衡器时，instance 对象为 null 值，因此系统将执行代码 instance= new LoadBalancer()，在此过程中，由于要对 LoadBalancer 进行大量初始化工作，需要一段时间来创建 LoadBalancer 对象。而在此时，如果再一次调用 getLoadBalancer() 方法（通常发生在多线程环境中），由于 instance 尚未创建成功，仍为 null 值，判断条件 (instance== null) 为真值，因此代码 instance= new LoadBalancer() 将再次执行，导致最终创建了多个 instance 对象，这违背了单例模式的初衷，也导致系统运行发生错误。 饿汉式单例 在定义静态变量的时候实例化单例类，因此在类加载的时候就已经创建了单例对象，代码如下所示： 12345678class EagerSingleton &#123; private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() &#123; &#125; public static EagerSingleton getInstance() &#123; return instance; &#125; &#125; 当类被加载时，静态变量 instance 会被初始化，此时类的私有构造函数会被调用，单例类的唯一实例将被创建。如果使用饿汉式单例来实现负载均衡器 LoadBalancer 类的设计，则不会出现创建多个单例对象的情况，可确保单例对象的唯一性。 懒汉式单例 懒汉式单例在第一次调用 getInstance() 方法时实例化，在类加载时并不自行实例化，这种技术又称为延迟加载(Lazy Load)技术，即需要的时候再加载实例。为了避免多个线程同时调用 getInstance() 方法，我们可以使用关键字 synchronized ，代码如下所示： 123456789101112class LazySingleton &#123; private static LazySingleton instance = null; private LazySingleton() &#123; &#125; synchronized public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125; &#125; 该懒汉式单例类在 getInstance() 方法前面增加了关键字 synchronized 进行线程锁，以处理多个线程同时访问的问题。上述代码虽然解决了线程安全问题，但是每次调用 getInstance() 时都需要进行线程锁定判断，在多线程高并发访问环境中，将会导致系统性能大大降低。如何既解决线程安全问题又不影响系统性能呢？我们继续对懒汉式单例进行改进。事实上，我们无须对整个 getInstance() 方法进行锁定，只需对其中的代码 “instance = new LazySingleton();” 进行锁定即可。因此 getInstance() 方法可以进行如下改进： 12345678public static LazySingleton getInstance() &#123; if (instance == null) &#123; synchronized (LazySingleton.class) &#123; instance = new LazySingleton(); &#125; &#125; return instance; &#125; 问题貌似得以解决，事实并非如此。如果使用以上代码来实现单例，还是会存在单例对象不唯一。原因如下： 假如在某一瞬间线程A和线程B都在调用 getInstance() 方法，此时 instance 对象为 null 值，均能通过 instance == null 的判断。由于实现了 synchronized 加锁机制，线程A进入 synchronized 锁定的代码中执行实例创建代码，线程B处于排队等待状态，必须等待线程A执行完毕后才可以进入 synchronized 锁定代码。但当A执行完毕时，线程B并不知道实例已经创建，将继续创建新的实例，导致产生多个单例对象，违背单例模式的设计思想。因此需要进行进一步改进，在 synchronized 中再进行一次 (instance == null) 判断，这种方式称为双重检查锁定(Double-Check Locking)。使用双重检查锁定实现的懒汉式单例类完整代码如下所示： 12345678910111213141516171819class LazySingleton &#123; private volatile static LazySingleton instance = null; private LazySingleton() &#123; &#125; public static LazySingleton getInstance() &#123; //第一重判断 if (instance == null) &#123; //锁定代码块 synchronized (LazySingleton.class) &#123; //第二重判断 if (instance == null) &#123; instance = new LazySingleton(); //创建单例实例 &#125; &#125; &#125; return instance; &#125; &#125; 需要注意的是，如果使用双重检查锁定来实现懒汉式单例类，需要在静态成员变量 instance 之前增加修饰符 volatile ，被 volatile 修饰的成员变量可以确保多个线程都能够正确处理，且该代码只能在 JDK 1.5 及以上版本中才能正确执行。由于 volatile 关键字会屏蔽 JVM 所做的一些代码优化，可能会导致系统运行效率降低，因此即使使用双重检查锁定来实现单例模式也不是一种完美的实现方式。 两种单例实现方式比较饿汉式单例类在类被加载时就将自己实例化，它的优点在于无须考虑多线程访问问题，可以确保实例的唯一性；从调用速度和反应时间角度来讲，由于单例对象一开始就得以创建，因此要优于懒汉式单例。但是无论系统在运行时是否需要使用该单例对象，由于在类加载时该对象就需要创建，因此从资源利用效率角度来讲，饿汉式单例不及懒汉式单例，而且在系统加载时由于需要创建饿汉式单例对象，加载时间可能会比较长。 懒汉式单例类在第一次使用时创建，无须一直占用系统资源，实现了延迟加载，但是必须处理好多个线程同时访问的问题，特别是当单例类作为资源控制器，在实例化时必然涉及资源初始化，而资源初始化很有可能耗费大量时间，这意味着出现多线程同时首次引用此类的机率变得较大，需要通过双重检查锁定等机制进行控制，这将导致系统性能受到一定影响。 一种更好的单例实现方法——IoDH饿汉式单例类不能实现延迟加载，不管将来用不用始终占据内存；懒汉式单例类线程安全控制烦琐，而且性能受影响。Initialization Demand Holder (IoDH) 可以克服这两个缺点。 在 IoDH 中，我们在单例类中增加一个静态内部类，在该内部类中创建单例对象，再将该单例对象通过 getInstance() 方法返回给外部使用，实现代码如下所示： 1234567891011121314151617181920//Initialization on Demand Holder class Singleton &#123; private Singleton() &#123; &#125; private static class HolderClass &#123; private final static Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return HolderClass.instance; &#125; public static void main(String args[]) &#123; Singleton s1, s2; s1 = Singleton.getInstance(); s2 = Singleton.getInstance(); System.out.println(s1==s2); &#125; &#125; 编译并运行上述代码，运行结果为：true，即创建的单例对象 s1 和 s2 为同一对象。由于静态单例对象没有作为 Singleton 的成员变量直接实例化，因此类加载时不会实例化 Singleton ，第一次调用 getInstance() 时将加载内部类 HolderClass ，在该内部类中定义了一个 static 类型的变量 instance ，此时会首先初始化这个成员变量，由 Java 虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于 getInstance() 方法没有任何线程锁定，因此其性能不会造成任何影响。 通过使用 IoDH，我们既可以实现延迟加载，又可以保证线程安全，不影响系统性能，不失为一种最好的 Java 语言单例模式实现方式（其缺点是与编程语言本身的特性相关，很多面向对象语言不支持IoDH）。 单例模式总结单例模式作为一种目标明确、结构简单、理解容易的设计模式，在软件开发中使用频率相当高，在很多应用软件和框架中都得以广泛应用。 单例模式的主要优点如下： 单例模式提供了对唯一实例的受控访问。因为单例类封装了它的唯一实例，所以它可以严格控制客户怎样以及何时访问它。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象单例模式无疑可以提高系统的性能。 允许可变数目的实例。基于单例模式我们可以进行扩展，使用与单例控制相似的方法来获得指定个数的对象实例，既节省系统资源，又解决了单例单例对象共享过多有损性能的问题。 单例模式的主要缺点如下： 由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。 单例类的职责过重，在一定程度上违背了“单一职责原则”。因为单例类既充当了工厂角色，提供了工厂方法，同时又充当了产品角色，包含一些业务方法，将产品的创建和产品的本身的功能融合到一起。 现在很多面向对象语言(如 Java 、C# )的运行环境都提供了自动垃圾回收的技术，因此，如果实例化的共享对象长时间不被利用，系统会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致共享的单例对象状态的丢失。 在以下情况下可以考虑使用单例模式： 系统只需要一个实例对象，如系统要求提供一个唯一的序列号生成器或资源管理器，或者需要考虑资源消耗太大而只允许创建一个对象。 客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式——工厂模式]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[简单工厂模式- [简单工厂模式总结](#简单工厂模式总结) - [相关阅读](#相关阅读) 工厂方法模式- [工厂方法模式总结](#工厂方法模式总结) 抽象工厂模式- [抽象工厂模式总结](#抽象工厂模式总结) - [Ads](#ads) 简单工厂模式简单工厂模式(Simple Factory Pattern)：定义一个工厂类，它可以根据参数的不同返回不同类的实例，被创建的实例通常都具有共同的父类。在简单工厂模式中用于创建实例的方法是静态方法，因此简单工厂模式又被称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。 在简单工厂模式结构图中包含如下几个角色： Factory（工厂角色）：工厂角色即工厂类，它是简单工厂模式的核心，负责实现创建所有产品实例的内部逻辑；工厂类可以被外界直接调用，创建所需的产品对象；在工厂类中提供了静态的工厂方法 factoryMethod()，它的返回类型为抽象产品类型 Product 。 Product（抽象产品角色）：它是工厂类所创建的所有对象的父类，封装了各种产品对象的公有方法，它的引入将提高系统的灵活性，使得在工厂类中只需定义一个通用的工厂方法，因为所有创建的具体产品对象都是其子类对象。 ConcreteProduct（具体产品角色）：它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。每一个具体产品角色都继承了抽象产品角色，需要实现在抽象产品中声明的抽象方法。 简单工厂模式总结简单工厂模式提供了专门的工厂类用于创建对象，将对象的创建和对象的使用分离开。它作为一种最简单的工厂模式在软件开发中得到了较为广泛的应用。 简单工厂模式的主要优点如下： 实现了对象创建和使用的分离，从而让客户端可以免除直接创建产品对象的职责。这样的好处在于： 降低因为产品或工厂类改变所造成的维护工作量 系统更加符合“单一职责原则”，防止了使用对象时的代码冗余，有利于功能复用和系统维护 简化操作。客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数。 通过引入配置文件，可以在不修改客户端代码的情况下使用或更换已有的具体产品类，提高系统灵活性。 简单工厂模式的主要缺点如下： 由于工厂类集中了所有产品的创建逻辑，一旦不能正常工作，整个系统都要受到影响。 使用简单工厂模式会增加系统中类的个数（引入了新的工厂类），增加了系统的复杂度。 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，违反了开闭原则。 简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。 以下情况可以考虑使用简单工厂模式： 工厂类负责创建的对象比较少，不会造成工厂方法中的业务逻辑太过复杂。 客户端只知道传入工厂类的参数，对于如何创建对象并不关心。 相关阅读为何要使用工厂模式 工厂方法模式简单工厂模式存在一个很严重的问题，当系统中需要引入新产品时，由于静态工厂方法通过所传入参数的不同来创建不同的产品，这必定要修改工厂类的源代码，将违背开闭原则。因此在工厂方法模式中，不再提供一个统一的工厂类来创建所有的产品对象，而是针对不同的产品提供不同的工厂，系统提供一个与产品等级结构对应的工厂等级结构。 工厂方法模式(Factory Method Pattern)：定义一个用于创建对象的接口，让子类决定将哪一个类实例化。工厂方法模式让一个类的实例化延迟到其子类。工厂方法模式又简称为工厂模式(Factory Pattern)，是一种类创建型模式。 在工厂方法模式结构图中包含如下几个角色： Product（抽象产品）：它是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的公共父类。 ConcreteProduct（具体产品）：它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。 Factory（抽象工厂）：在抽象工厂类中，声明了工厂方法(Factory Method)，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。 ConcreteFactory（具体工厂）：它是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户端调用，返回一个具体产品类的实例。 工厂方法模式总结工厂方法模式是简单工厂模式的延伸，它继承了简单工厂模式的优点，同时还弥补了简单工厂模式的不足。它是使用频率最高的设计模式之一，是很多开源框架和 API 类库的核心模式。 工厂方法模式的主要优点如下： 在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名。 基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够让工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，就正是因为所有的具体工厂类都具有同一抽象父类。 在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了。这样系统的可扩展性也就变得非常好，完全符合“开闭原则”。 工厂方法模式的主要缺点如下： 在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度；有更多的类需要编译和运行，会给系统带来一些额外的开销。 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度；且在实现时可能需要用到 DOM 、反射等技术，增加了系统的实现难度。 在以下情况下可以考虑使用工厂方法模式： 客户端不知道它所需要的对象的类。在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建，可将具体工厂类的类名存储在配置文件或数据库中。 抽象工厂类通过其子类来指定创建哪个对象。在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。 抽象工厂模式工厂方法模式通过引入工厂等级结构，解决了简单工厂模式中工厂类职责太重的问题，但由于工厂方法模式中的每个工厂只生产一类产品，可能会导致系统中存在大量的工厂类，势必会增加系统的开销。此时，我们可以考虑将一些相关的产品组成一个“产品族”，由同一个工厂来统一生产。 抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。抽象工厂模式又称为Kit模式，它是一种对象创建型模式。 在抽象工厂模式结构图中包含如下几个角色： AbstractFactory（抽象工厂）：它声明了一组用于创建一族产品的方法，每一个方法对应一种产品。 ConcreteFactory（具体工厂）：它实现了在抽象工厂中声明的创建产品的方法，生成一组具体产品，这些产品构成了一个产品族，每一个产品都位于某个产品等级结构中。 AbstractProduct（抽象产品）：它为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法。 ConcreteProduct（具体产品）：它定义具体工厂生产的具体产品对象，实现抽象产品接口中声明的业务方法。 为了更好地理解抽象工厂模式，需要引入两个概念： 产品等级结构：产品等级结构即产品的继承结构，如一个抽象类是电视机，其子类有海尔电视机、海信电视机、TCL电视机，则抽象电视机与具体品牌的电视机之间构成了一个产品等级结构，抽象电视机是父类，而具体品牌的电视机是其子类。 产品族：产品族是指由同一个工厂生产的，位于不同产品等级结构中的一组产品。如海尔电器工厂生产的海尔电视机、海尔电冰箱：海尔电视机位于电视机产品等级结构中，海尔电冰箱位于电冰箱产品等级结构中，海尔电视机、海尔电冰箱构成了一个产品族。 当系统所提供的工厂生产的具体产品并不是一个简单的对象，而是多个位于不同产品等级结构、属于不同类型的具体产品时，就可以使用抽象工厂模式。抽象工厂模式是所有形式的工厂模式中最为抽象和最具一般性的一种形式。抽象工厂模式与工厂方法模式最大的区别在于，工厂方法模式针对的是一个产品等级结构，而抽象工厂模式需要面对多个产品等级结构，一个工厂等级结构可以负责多个不同产品等级结构中的产品对象的创建。当一个工厂等级结构可以创建出分属于不同产品等级结构的一个产品族中的所有对象时，抽象工厂模式比工厂方法模式更为简单、更有效率。 抽象工厂模式总结抽象工厂模式是工厂方法模式的进一步延伸，由于它提供了功能更为强大的工厂类并且具备较好的可扩展性，在软件开发中得以广泛应用，尤其是在一些框架和API类库的设计中，例如在Java语言的AWT（抽象窗口工具包）中就使用了抽象工厂模式，它使用抽象工厂模式来实现在不同的操作系统中应用程序呈现与所在操作系统一致的外观界面。抽象工厂模式也是在软件开发中最常用的设计模式之一。 抽象工厂模式的主要优点如下： 抽象工厂模式隔离了具体类的生成，使得客户并不需要知道什么被创建。由于这种隔离，更换一个具体工厂就变得相对容易，所有的具体工厂都实现了抽象工厂中定义的那些公共接口，因此只需改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。 当一个产品族中的多个对象被设计成一起工作时，它能够保证客户端始终只使用同一个产品族中的对象。 增加新的产品族很方便，无须修改已有系统，符合“开闭原则”。 抽象工厂模式的主要缺点如下： 增加新的产品等级结构麻烦，需要对原有系统进行较大的修改，甚至需要修改抽象层代码，这显然会带来较大的不便，违背了“开闭原则”。 在抽象工厂模式中，增加新的产品族很方便，但是增加新的产品等级结构很麻烦，抽象工厂模式的这种性质称为开闭原则的倾斜性。 在以下情况下可以考虑使用抽象工厂模式： 一个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有类型的工厂模式都是很重要的，用户无须关心对象的创建过程，将对象的创建和使用解耦。 系统中有多于一个的产品族，而每次只使用其中某一产品族。可以通过配置文件等方式来使得用户可以动态改变产品族，也可以很方便地增加新的产品族。 属于同一个产品族的产品将在一起使用，这一约束必须在系统的设计中体现出来。同一个产品族中的产品可以是没有任何关系的对象，但是它们都具有一些共同的约束，如同一操作系统下的按钮和文本框，按钮与文本框之间没有直接关系，但它们都是属于某一操作系统的，此时具有一个共同的约束条件：操作系统的类型。 产品等级结构稳定，设计完成之后，不会向系统中增加新的产品等级结构或者删除已有的产品等级结构。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式——观察者模式]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式 观察者模式总结 Ads 观察者模式观察者模式是使用频率最高的设计模式之一，它用于建立一种对象与对象之间的依赖关系，一个对象发生改变时将自动通知其他对象，其他对象将相应作出反应。在观察者模式中，发生改变的对象称为观察目标，而被通知的对象称为观察者，一个观察目标可以对应多个观察者，而且这些观察者之间可以没有任何相互联系，可以根据需要增加和删除观察者，使得系统更易于扩展。 观察者模式(Observer Pattern)：定义对象之间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。观察者模式的别名包括发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。观察者模式是一种对象行为型模式。 在观察者模式结构图中包含如下几个角色： Subject（目标）：目标是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时它定义了通知方法 notify() 。目标类可以是接口，也可以是抽象类或具体类。 ConcreteSubject（具体目标）：具体目标是目标类的子类，通常它包含有经常发生改变的数据，当它的状态发生改变时，向它的各个观察者发出通知。 Observer（观察者）：观察者将对观察目标的改变做出反应，观察者一般定义为接口，该接口声明了更新数据的方法 update()，因此又称为抽象观察者。 ConcreteObserver（具体观察者）：在具体观察者中维护一个指向具体目标对象的引用。它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致；它实现了在抽象观察者 Observer 中定义的 update() 方法。通常在实现时，可以调用具体目标类的 attach() 方法将自己添加到目标类的集合中或通过 detach() 方法将自己从目标类的集合中删除。 观察者模式在 Java 语言中的地位非常重要。在 JDK 的 java.util 包中，提供了 Observable 类以及 Observer 接口，它们构成了JDK对观察者模式的支持。我们可以直接使用 Observer 接口和 Observable 类来作为观察者模式的抽象层，再自定义具体观察者类和具体观察目标类。 观察者模式总结观察者模式是一种使用频率非常高的设计模式，无论是移动应用、Web 应用或者桌面应用，观察者模式几乎无处不在，它为实现对象之间的联动提供了一套完整的解决方案，凡是涉及到一对一或者一对多的对象交互场景都可以使用观察者模式。观察者模式广泛应用于各种编程语言的 GUI 事件处理的实现，在基于事件的 XML 解析技术（如SAX2）以及 Web 事件处理中也都使用了观察者模式。 观察者模式的主要优点如下： 观察者模式可以实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口，使得可以有各种各样不同的表示层充当具体观察者角色。 观察者模式在观察目标和观察者之间建立一个抽象的耦合。观察目标只需要维持一个抽象观察者的集合，无须了解其具体观察者。由于观察目标和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。 观察者模式支持广播通信，观察目标会向所有已注册的观察者对象发送通知，简化了一对多系统设计的难度。 观察者模式满足“开闭原则”的要求，增加新的具体观察者无须修改原有系统代码，在具体观察者与观察目标之间不存在关联关系的情况下，增加新的观察目标也很方便 观察者模式的主要缺点如下： 如果一个观察目标对象有很多直接和间接观察者，将所有的观察者都通知到会花费很多时间。 如果在观察者和观察目标之间存在循环依赖，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 在以下情况下可以考虑使用观察者模式： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面，将这两个方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致一个或多个其他对象也发生改变，而并不知道具体有多少对象将发生改变，也不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式——面向对象设计原则]]></title>
    <url>%2Fse-notes%2FJava%E5%9F%BA%E7%A1%80%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[面向对象设计原则 单一职责原则 开闭原则 里氏代换原则 依赖倒转原则 接口隔离原则 合成复用原则 迪米特法则 Ads 面向对象设计原则对于面向对象软件系统的设计而言，在支持可维护性的同时，提高系统的可复用性是一个至关重要的问题，如何同时提高一个软件系统的可维护性和可复用性是面向对象设计需要解决的核心问题之一。在面向对象设计中，可维护性的复用是以设计原则为基础的。每一个原则都蕴含一些面向对象设计的思想，可以从不同的角度提升一个软件结构的设计水平。 设计原则名称 定义 单一职责原则 (Single Responsibility Principle, SRP) 一个类只负责一个功能领域中的相应职责 开闭原则 (Open-Closed Principle, OCP) 软件实体应对扩展开放，而对修改关闭 里氏代换原则 (Liskov Substitution Principle, LSP) 所有引用基类对象的地方能够透明地使用其子类的对象 依赖倒转原则 (Dependence Inversion Principle, DIP) 抽象不应该依赖于细节，细节应该依赖于抽象 接口隔离原则 (Interface Segregation Principle, ISP) 使用多个专门的接口，而不使用单一的总接口 合成复用原则 (Composite Reuse Principle, CRP) 尽量使用对象组合，而不是继承来达到复用的目的 迪米特法则 (Law of Demeter, LoD) 一个软件实体应当尽可能少地与其他实体发生相互作用 单一职责原则单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责。即对于一个类而言，应该只有一个引起它变化的原因。 单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离。 开闭原则开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 任何软件都需要面临一个很重要的问题，即它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。 为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能，即可实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。 里氏代换原则里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。即在软件中将一个基类对象替换成它的子类对象，程序将不会产生任何错误和异常。 里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。 在使用里氏代换原则时需要注意如下几个问题： 子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。 我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。 依赖倒转原则依赖倒转原则(Dependency Inversion Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。 依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。 在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。 在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入。构造注入是指通过构造函数来传入具体类的对象，设值注入是指通过Setter方法来传入具体类的对象，而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。 接口隔离原则接口隔离原则(Interface Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。 根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色。 在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。 合成复用原则合成复用原则(Composite Reuse Principle, CRP)：尽量使用对象组合，而不是继承来达到复用的目的。简言之：复用时要尽量使用组合/聚合关系（关联关系），少用继承。 在面向对象设计中，可以通过两种方法在不同的环境中复用已有的设计和实现，即通过组合/聚合关系或通过继承，但首先应该考虑使用组合/聚合，组合/聚合可以使系统更加灵活，降低类与类之间的耦合度，一个类的变化对其他类造成的影响相对较少；其次才考虑继承，在使用继承时，需要严格遵循里氏代换原则，有效使用继承会有助于对问题的理解，降低复杂度，而滥用继承反而会增加系统构建和维护的难度以及系统的复杂度，因此需要慎重使用继承复用。 通过继承来进行复用的主要问题在于继承复用会破坏系统的封装性，因为继承会将基类的实现细节暴露给子类，由于基类的内部细节通常对子类来说是可见的，所以这种复用又称“白箱”复用，如果基类发生改变，那么子类的实现也不得不发生改变；从基类继承而来的实现是静态的，不可能在运行时发生改变，没有足够的灵活性；而且继承只能在有限的环境中使用（如类没有声明为不能被继承）。 迪米特法则迪米特法则(Law of Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。 如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。 在迪米特法则中，对于一个对象，其朋友包括以下几类： 当前对象本身(this)； 以参数形式传入到当前对象方法中的对象； 当前对象的成员对象； 如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友； 当前对象所创建的对象。 任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。在应用迪米特法则时，一个对象只能与直接朋友发生交互，不要与“陌生人”发生直接交互，这样做可以降低系统的耦合度，一个对象的改变不会给太多其他对象带来影响。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>编程语言</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java语法</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算实践-Kubernetes部署-README]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2FKubernetes%E9%83%A8%E7%BD%B2%2FREADME%2F</url>
    <content type="text"><![CDATA[Kubernetes 简介 什么是 Kubernetes 操作对象 Pod Service Replication Controller 关于 Label 功能组件 工作流 创建 pod 创建 service 创建 controller Ads Kubernetes 简介什么是 KubernetesKubernetes 是 Google 开源的容器集群管理系统，它构建在 Docker 技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等功能。利用 Kubernetes 可以方便管理跨机器运行的容器化应用，它的主要功能如下： 使用 Docker 对应用程序包装(package)、实例化(instantiate)、运行(run) 以集群的方式运行、管理跨机器的容器 解决 Docker 跨机器容器之间的通讯问题 Kubernetes 的自我修复机制使得容器集群总是运行在用户期望的状态 当前 Kubernetes 支持 GCE、vShpere、CoreOS、OpenShift、Azure 等平台，除此之外也可以直接运行在物理机上。 操作对象PodPod 是 Kubernetes 最基本的部署调度单元，可以包含 container，逻辑上表示某种应用的一个实例。比如一个 web 站点应用由前端、后端及数据库构建而成，这三个组件将运行在各自的容器中，那么我们可以创建包含三个 container 的 pod。 ServiceService 是 pod 的路由代理抽象，用于解决 pod 之间的服务发现问题。因为 pod 的运行状态可动态变化(比如切换机器了、缩容过程中被终止了等)，所以访问端不能以写死 IP 的方式去访问该 pod 提供的服务。Service 的引入旨在保证 pod 的动态变化对访问端透明，访问端只需要知道 service 的地址，由 service 来提供代理。 Replication ControllerReplication Controller 是 pod 的复制抽象，用于解决 pod 的扩容缩容问题。通常情况下，分布式应用为了性能或高可用性的考虑，需要复制多份资源，并且根据负载情况动态伸缩。通过 Replication Controller，我们可以指定一个应用需要几份复制，Kubernetes 将为每份复制创建一个 pod，并且保证实际运行 pod 数量总是与该复制数量相等（例如，当前某个 pod 宕机时，自动创建新的 pod 来替换）。 关于 LabelLabel 是用于区分 Pod、Service、Replication Controller 的 key/value 键值对，Pod、Service、 Replication Controller 可以有多个 label，但是每个 label 的 key 只能对应一个 value。Label 是 Service 和 Replication Controller 运行的基础，为了将访问 Service 的请求转发给后端提供服务的多个容器，正是通过标识容器的 label 来选择正确的容器。同样，Replication Controller 也使用 label 来管理通过 pod 模板创建的一组容器，这样无论有多少容器， Replication Controller 都可以更加容易、方便地管理它们。 功能组件Kubernetes 的集群架构是一个典型的 master/slave 模型。 master 运行三个组件： apiserver：作为 kubernetes 系统的入口，封装了核心对象的增删改查操作，以 RESTFul 接口方式提供给外部客户和内部组件调用。它维护的 REST 对象将持久化到 etcd（一个分布式强一致性的 key/value 存储）。 scheduler：负责集群的资源调度，为新建的 pod 分配机器。这部分工作分出来变成一个组件，意味着可以很方便地替换成其他的调度器。 controller-manager：负责执行各种控制器，目前有两类： endpoint-controller：定期关联 service 和 pod (关联信息由 endpoint 对象维护)，保证 service 到 pod 的映射总是最新的。 replication-controller：定期关联 replicationController 和 pod，保证 replicationController 定义的复制数量与实际运行 pod 的数量总是一致的。 slave（也称作minion）运行两个组件： kubelet：负责管控 Docker 容器，如启动/停止、监控运行状态等。它会定期从 etcd 获取分配到本机的 pod，并根据 pod 信息启动或停止相应的容器。同时，它也会接收 apiserver 的 HTTP 请求，汇报 pod 的运行状态。 proxy：负责为 pod 提供代理。它会定期从 etcd 获取所有的 service，并根据 service 信息创建代理。当某个客户 pod 要访问其他 pod 时，访问请求会经过本机 proxy 做转发。 工作流上文已经提到了 Kubernetes 中最基本的三个操作对象：pod，replicationController 及 service。下面分别从它们的对象创建出发，通过时序图来描述 Kubernetes 各个组件之间的交互及其工作流。 创建 pod 创建 service 创建 controller 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>kubernetes部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础-README]]></title>
    <url>%2Fse-notes%2FLinux%E5%9F%BA%E7%A1%80%2FREADME%2F</url>
    <content type="text"><![CDATA[简介 操作系统的特征 操作系统目标 操作系统的运行机制 系统调用 标准库函数 中断和异常 用户态、内核态 * 操作系统发展- [手工操作阶段（此阶段无操作系统）](#手工操作阶段此阶段无操作系统) - [批处理阶段](#批处理阶段) - [分时操作系统](#分时操作系统) - [实时操作系统](#实时操作系统) - [分布式计算机系统](#分布式计算机系统) - [Ads](#ads) 简介操作系统（Operating System, OS）是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境的程序集合。计算机操作系统是随着计算机研究和应用的发展逐步形成并发展起来的，它是计算机系统中最基本的系统软件。 操作系统三大功能：资源管理与分配、调度工作流程、封装接口与提供环境 操作系统的特征操作系统是一种系统软件，但与其他的系统软件和应用软件有很大的不同，它有自己的基本特征。操作系统的基本特征包括并发、共享、虚拟和异步。 并发（Concurrence）：并发是指多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行着的程序，因此它具有处理和调度多个程序同时执行的能力。在操作系统中，引入进程的目的是使程序能并发执行。 共享（Sharing）：资源共享是指系统中的资源可供内存中多个并发执行的进程共同使用。共享可分为以下两种资源共享方式： 互斥共享方式：系统中的某些资源，如打印机、磁带机，虽然它们可以提供给多个进程使用，但为使所打印或记录的结果不致造成混淆，应规定在一段时间内只允许一个进程访问该资源。 同时访问方式：系统中还有另一类资源，允许在一段时间内由多个进程同时对它们进行访问。这里所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问即 “分时共享”。典型的可供多个进程“同时”访问的资源是磁盘设备，一些文件也可以被“同时”共享，即若干个用户同时访问该文件。 PS：并发和共享是操作系统两个最基本的特征，这两者之间又是互为存在条件的：资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则自然不存在资源共享问题；若系统不能对资源共享实施有效的管理，也必将影响到程序的并发执行，甚至根本无法并发执行。 虛拟（Virtual）：虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。用于实现虚拟的技术，称为虚拟技术。在操作系统中利用了多种虚拟技术，分别用来实现虚拟处理器、虚拟内存和虚拟外部设备等。 如在虚拟处理器技术中，利用多道程序设计技术（即同时把多个程序放入内存，并允许它们交替在CPU中运行），把一个物理上的 CPU 虚拟为多个逻辑上的 CPU 。 异步（Asynchronism）：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。 操作系统目标为了给多道程序提供良好的运行环境，操作系统作为计算机系统资源的管理者具有以下几方面的功能： 处理机管理（进程线程管理）：在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位，因而对处理机的管理可归结为对进程（或线程）的管理。并发时在计算机内同时运行多个进程，进程何时创建、何时撤销、如何管理、如何避免冲突、合理共享是进程管理的主要任务。 存储器管理：存储器管理是为了给多道程序的运行提供良好的环境，方便用户使用以及提高内存的利用率。 文件管理：计算机中的信息都是以文件的形式存在的，操作系统中负责文件管理的部分称为文件系统。 设备管理：设备管理的主要任务是完成用户的I/O请求，方便用户使用各种设备。 为方便用户使用计算机，操作系统还提供了用户接口。操作系统提供的接口主要分为两类，一类是命令接口，用户利用这些操作命令来组织和控制作业的执行；另一类是程序接口，编程人员可以使用它们来请求操作系统服务。 操作系统的运行机制计算机系统中，通常 CPU 执行两种不同性质的程序：一种是操作系统内核程序；另一种是用户自编程序或系统外层的应用程序。对操作系统而言，这两种程序的作用不同，前者是后者的管理者，因此“管理程序”要执行一些特权指令，而“被管理程序”出于安全考虑不能执行这些指令。所谓特权指令，是指计算机中不允许用户直接使用的指令，如 I/O 指令、 置中断指令，存取用于内存保护的寄存器、送程序状态字到程序状态字寄存器等指令。操作系统在具体实现上划分了用户态和核心态，以严格区分两类程序。 内核是计算机上配置的底层软件，是计算机功能的延伸。不同系统对内核的定义稍有区别，大多数操作系统内核包括以下四个方面： 时钟管理：在计算机的各种部件中，时钟是最关键的设备。操作系统需要通过时钟管理，向用户提供标准的系统时间。另外通过时钟中断的管理，可以实现进程的切换。诸如，在分时操作系统中，釆用时间片轮转调度的实现；在实时系统中，按截止时间控制运行的实现；在批处理系统中，通过时钟管理来衡量一个作业的运行程度等。 中断机制：引入中断技术的初衷是提高多道程序运行环境中 CPU 的利用率，而且主要是针对外部设备的。后来逐步得到发展，形成了多种类型，成为操作系统各项操作的基础。例如，键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等，无不依赖于中断机制。可以说，现代操作系统是靠中断驱动的软件。 原语：按层次结构设计的操作系统，底层是一些可被调用的公用小程序，它们各自完成一个规定的操作。其特点是：它们处于操作系统的最底层，是最接近硬件的部分。这些程序的运行具有原子性，运行时间较短，而且调用频繁。通常把具有这些特点的程序称为原语（Atomic Operation）。定义原语的直接方法是关闭中断，让它的所有动作不可分割地进行完再打开中断。系统中的设备驱动、CPU 切换、进程通信等功能中的部分操作都可以定义为原语，使它们成为内核的组成部分。 系统控制的数据结构及处理：系统中用来登记状态信息的数据结构很多，比如作业控制块、进程控制块(PCB)、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表等。为了实现有效的管理，系统需要一些基本的操作，常见的操作有以下三种： 进程管理：进程状态管理、进程调度和分派、创建与撤销进程控制块等。 存储器管理：存储器的空间分配和回收、内存信息保护程序、代码对换程序等。 设备管理：缓冲区管理、设备分配和回收等。 系统调用所有的操作系统都提供多种服务的入口点，由此程序向内核请求服务。各种版本的 UNIX 实现都提供良好定义、数量有限、直接进入内核的入口点，这些入口点被称为系统调用。简单来说，系统调用就是操作系统提供的用于实现系统各种核心功能的许多子程序，如 read()、write()、open() 等。 这些系统调用按功能大致可分为如下几类： 设备管理。完成设备的请求或释放，以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及始址等功能。 显然，系统调用运行在系统的核心态。通过系统调用的方式来使用系统功能，可以保证系统的稳定性和安全性，防止用户随意更改或访问系统的数据或命令。系统调用命令是由操作系统提供的一个或多个子程序模块实现的。 这样，操作系统的运行环境可以理解为：用户通过操作系统运行上层程序（如系统提供的命令解释程序或用户自编程序），而这个上层程序的运行依赖于操作系统的底层管理程序提供服务支持，当需要管理程序服务时，系统则通过硬件中断机制进入核心态，运行底层管理程序；也可能是程序运行出现异常情况，被动地需要底层管理程序的服务，这时就通过异常处理来进入核心态。当底层管理程序运行结束时，用户程序需要继续运行，则通过相应的保存的程序现场退出中断处理程序或异常处理程序，返回断点处继续执行。 下面列举一些由用户态转向核心态的例子： 用户程序要求操作系统的服务，即系统调用。 发生一次中断。 用户程序中产生了一个错误状态。 用户程序中企图执行一条特权指令。 从核心态转向用户态由一条指令实现，这条指令也是特权命令。一般是中断返回指令。 注意：由用户态进入核心态，不仅仅是状态需要切换。而且，所使用的堆栈也可能需要由用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的。 标准库函数库函数顾名思义是把函数放到库里，是把一些常用到的函数编完放到一个文件里，供别人用。libc 就是一个 C 标准库，里面存放一些基本函数，这些基本函数都是被标准化了的，而且这些函数通常都是用汇编直接实现的，如 printf、scanf 等。 标准库函数构建在系统调用接口之上，应用程序既可以使用标准库函数，也可以使用系统调用。如下图： 系统调用和标准库函数的区别如下： 从程序完成的功能来看，函数库提供的函数通常不需要操作系统的服务。系统调用是要求操作系统为用户提供某种服务，通常是涉及系统的硬件资源和一些敏感的软件资源等。 从程序执行的空间来说，标准库函数是在用户空间内执行的，除非函数涉及到 I/O 操作等，一般是不会切到内核态的。系统调用则运行于内核空间。 从程序的可移植性的角度来看，相对于系统调用，C 语言的标准备函数库具备较高的可移植性。因为在所有的 ANSI C 编译器版本中，标准库函数是相同的；系统调用与系统有关，各个操作系统的系统调用是不同的。 ［系统调用函数］ 中断和异常 中断(Interruption)，也称外中断，指来自 CPU 执行指令以外的事件的发生，如设备发出的 I/O 结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入 / 输出请求，同时让完成输入/输出后的程序继续运行。时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与当前程序运行无关的事件，即它们与当前处理机运行的程序无关。 异常(Exception)，也称内中断、例外或陷入(Trap)，指源自 CPU 执行指令内部的事件，如程序的非法操作码、地址越界、算术溢出、虚存系统的缺页以及专门的陷入指令等引起的事件。对异常的处理一般要依赖于当前程序的运行现场，而且异常不能被屏蔽，一旦出现应立即处理。 用户态、内核态操作系统的很多操作会消耗系统的物理资源，例如创建一个新进程时，要做很多底层的工作，如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录、页表等，这些操作显然不能让任何程序都可以做。 我们知道，Intel 的 X86 架构的 CPU 提供了 0 到 3 四个特权级（在CPU的设计中，用户态指非特权状态。在此状态下，执行的代码被硬件限定，不能进行某些操作，比如写入其他进程的存储空间，以防止给操作系统带来安全隐患）。 在 Linux 操作系统操作系统的设计中主要采用了0和3两个特权级，也就是我们通常所说的内核态和用户态。运行于用户态的进程可以执行的操作和访问的资源都受到极大的限制，而运行于内核态的进程则可以执行任何操作并且在资源的使用上也没有限制。 当一个任务（进程）陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0 级）内核代码中执行。每个进程都有自己的内核栈和用户栈，当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态），此时处理器在特权级最低的（3 级）用户代码中运行。简单来说在内核态下， CPU 可执行任何指令，在用户态下 CPU 只能执行非特权指令。 Linux 进程的 4GB 地址空间，3G-4G 是内核态的地址空间，存放整个内核的代码和所有的内核模块，以及内核所维护的数据。用户运行一个程序，该程序所创建的进程运行在用户态，如果要执行文件操作，网络数据发送等操作，必须通过 write，send 等系统调用，这些系统调用会调用内核中的代码来完成操作。这时必须切换到 Ring 0，然后进入 3GB-4GB 中的内核地址空间去执行这些代码完成操作，完成后切换回Ring 3，回到用户态。当程序处于内核态时可以随意进入用户态。 很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程。用户态切换到内核态的 3 种方式： 系统调用：这是处于用户态的进程主动请求切换到内核态的一种方式。用户态的进程通过系统调用申请使用操作系统提供的系统调用服务例程来处理任务 产生异常：CPU 执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会切换到内核态，如缺页异常 外围设备的中断：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换 * 操作系统发展手工操作阶段（此阶段无操作系统）用户在计算机上算题的所有工作都要人工干预，如程序的装入、运行、结果的输出等。随着计算机硬件的发展，人机矛盾（速度和资源利用）越来越大，必须寻求新的解决办法。 批处理阶段为了解决人机矛盾及CPU和I/O设备之间速度不匹配的矛盾，出现了批处理系统。它按发展历程又分为单道批处理系统、多道批处理系统（多道程序设计技术出现以后）。 单道批处理系统：系统对作业的处理是成批进行的，但内存中始终只保持一道作业。当该程序完成或发生异常情况时，才换入其后继程序进入内存运行。 多道批处理系统：多道程序设计技术允许多个程序同时进入内存并运行。即同时把多个程序放入内存，并允许它们交替在CPU中运行，它们共享系统中的各种硬、软件资源。当一道程序因I/O请求而暂停运行时，CPU便立即转去运行另一道程序。它没有用某些机制提高某一技术方面的瓶颈问题，而是让系统的各个组成部分都尽量去“忙”，花费很少时间去切换任务，达到了系统各部件之间的并行工作，使其整体在单位时间内的效率翻倍。 分时操作系统把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行，把处理器让给其他作业使用，等待下一轮再继续运行。由于计算机速度很快，作业运行轮转得很快，给每个用户的感觉好像是自己独占一台计算机。多道批处理是实现作业自动控制而无需人工干预的系统，而分时系统是实现人机交互的系统。 分时系统具有与批处理系统不同的特征，其主要特征如下： 同时性。同时性也称多路性，指允许多个终端用户同时使用一台计算机。 交互性。用户能够方便地与系统进行人-机对话。 独立性。系统中多个用户可以彼此独立地进行操作，互不干扰。 及时性。用户请求能在很短时间内获得响应。 实时操作系统为了能在某个时间限制内完成某些紧急任务而不需时间片排队，诞生了实时操作系统。这里的时间限制可以分为两种情况：如果某个动作必须绝对地在规定的时刻（或规定的时间范围）发生，则称为硬实时系统。例如，飞行器的飞行自动控制系统，这类系统必须提供绝对保证，让某个特定的动作在规定的时间内完成。如果能够接受偶尔违反时间规定，并且不会引起任何永久性的损害，则称为软实时系统，如飞机订票系统、银行管理系统。 在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并且要在严格的时限内处理完接收的事件。实时橾作系统的主要特点是及时性和可靠性。 分布式计算机系统分布式计算机系统是由多台计算机组成并满足下列条件的系统：系统中任意两台计算机通过通信方式交换信息；系统中的每一台计算机都具有同等的地位，即没有主机也没有从机；每台计算机上的资源为所有用户共享；系统中的任意若千台计算机都可以构成一个子系统，并且还能重构；任何工作都可以分布在几台计算机上，由它们并行工作、协同完成。 用于管理分布式计算机系统的操作系统称为分布式计算机系统。该系统的主要特点是：分布性和并行性。分布式操作系统与网络操作系统本质上的不同之处在于分布式操作系统中，若干台计算机相互协同完成同一任务。 分布式领域 CAP 理论： Consistency(一致性)，数据一致更新，所有数据变动都是同步的 Availability(可用性)，好的响应性能 Partition tolerance(分区容错性)：可靠性 定理：任何分布式系统只可同时满足二点，没法三者兼顾。忠告：架构师不要将精力浪费在如何设计能满足三者的完美分布式系统，而是应该进行取舍。 ［分布式系统三个指标］ 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch0-进程与线程]]></title>
    <url>%2Fse-notes%2FLinux%E5%9F%BA%E7%A1%80%2Fch0-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程 进程创建、终止 进程状态转换 进程实现 *僵尸、孤儿进程 线程 线程实现 用户级线程 内核级线程 混合实现 线程同步 线程安全 进程与线程 调度 并发、并行 死锁 更多阅读- [Ads](#ads) 在多道程序环境下，允许多个程序并发执行。为此引入了进程(Process)的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性。简单来说，进程是对正在运行的程序的一个抽象，一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。 进程用于把资源集中到一起，而线程则是在 CPU 上被调度执行的实体。在同一个进程中并行运行多个线程，是对在同一个计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源，而在后一种情况下，多个进程共享物理内存、磁盘、打印机和资源。 进程从不同的角度，进程可以有不同的定义，比较典型的定义有： 进程是程序的一次执行过程。 进程是一个程序及其数据在处理机上顺序执行时所发生的活动。 进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。 进程创建、终止操作系统需要有一种方式来创建进程，主要有4种事件导致进程的创建： 系统初始化； 执行了进程创建系统调用； 用户请求创建一个新进程； 一个批处理作业的初始化 从技术上来看，所有这些情形中，新进程都是由于一个已经存在的进程执行了一个用于创建进程的系统调用而创建的。UNIX系统中，只有一个系统调用可以用来创建新进程：fork。这个系统调用会创建一个与调用进程相同的副本。调用了 fork 之后，这两个进程拥有相同的存储映像、同样的环境字符串和同样的打开文件。 进程创建之后，子进程和父进程拥有不同的地址空间，如果其中某个进程在其地址空间修改了一个字，这个修改对其他进程是不可见的。 一个进程迟早会结束，通常由下列条件引起： 正常退出（自愿的） 出错退出（自愿的） 严重错误（非自愿） 被其他进程杀死（非自愿） 进程状态转换进程在其生命周期内，由于系统中各进程之间的相互制约关系及系统的运行环境的变化，使得进程的状态也在不断地发生变化（一个进程会经历若干种不同状态）。通常进程有三种状态。 运行状态：进程正在 CPU 上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。 就绪状态：进程已处于准备运行的状态，即进程获得了除 CPU 之外的一切所需资源，一旦得到 CPU 即可运行。 阻塞状态，又称等待状态：进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括 CPU）或等待输入/输出完成。即使 CPU 空闲，该进程也不能运行。 下图说明了进程间状态转换的过程： 其中： 进程因为等待资源或事件而阻塞； 调度程序选择了另一个进程； 调度程序选择这个进程 进程获得资源或事件 进程实现为了实现进程模型，操作系统维护着一张表格（一个结构数组），即进程表，每个进程占用一个进程表项（也叫进程控制块, PCB）。系统利用进程控制块（Process Control Block, PCB）来描述进程的基本情况和运行状态，进而控制和管理进程。PCB是进程存在的唯一标志！典型 PCB 中的一些字段如下： *僵尸、孤儿进程子进程先于父进程结束，而且父进程没有函数调用 wait() 或 waitpid() 等待子进程结束，也没有注册 SIGCHLD 信号处理函数，结果使得子进程的进程列表信息无法回收，这样子进程就变成了僵尸进程（Zombie）。 所以简单来说一个已经终止，但是其父进程尚未对其进行善后处理（终止子进程的有关信息）的进程被称为僵尸进程。 UNIX 提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息，就可以得到。这种机制就是: 在每个进程( init 除外)退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号PID，退出状态，运行时间等)，直到父进程通过 wait/waitpid 来取时才释放。 如果父进程不调用 wait/waitpid 的话，那么保留的那段信息就不会释放，其进程号就会一直被占用（这时用ps命令就能看到子进程的状态是“Z”），但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。此即为僵尸进程的危害，应当避免。 注意如果父进程先于子进程结束，这时的子进程应该称作孤儿进程（Orphan）。每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为 init ，而 init 进程会循环地调用 wait() 。这样，当一个孤儿进程结束其生命周期后，init 进程就会进行善后工作。因此孤儿进程并不会有什么危害。 线程线程最直接的理解就是“轻量级进程”，它是一个基本的 CPU 执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。 进程中使用线程的主要原因有以下几个： 通过将应用程序分解成可以准并行运行的多个顺序线程，可简化程序设计模型。因为有了多线程之后，并行实体可以共享同一个地址空间和所有可用数据，这是多进程模型（它们具有不同的地址空间）所无法表达的。 线程比进程更加轻量级，比进程更容易创建，也更容易撤销。 如果存在着大量的计算和大量的 I/O 处理，拥有多个线程允许这些活动彼此重叠进行，从而加快应用程序执行的速度。 进程用于把资源集中到一起，而线程则是在 CPU 上被调度执行的实体。在同一个进程中并行运行多个线程，是对在同一个计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源，而在后一种情况下，多个进程共享物理内存、磁盘、打印机和资源。 进程中的不同线程不像不同进程之间那样存在很大的独立性，所有的线程都有完全一样的地址空间，它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写甚至清除另一个线程的堆栈。线程之间没有保护，一是没必要，二是不可能。 和传统进程一样，线程可以处于若干个状态中的任何一个：运行、阻塞、就绪、终止，之间的互相转换和进程也是一样的。多线程情况下，进程通常会从当前的单个线程开始，这个线程有能力通过调用一个库函数（如 thread_create）创建新的线程，通常情况，线程之间是平等关系的。一个线程完成工作后，调用一个库过程（如 thread_exit）退出。 线程除了共享进程所拥有的资源之外，每个线程还独有一些内容，如下： 线程 ID 寄存器 线程的堆栈指针 程序计数器 线程间通信方式主要有：事件、临界区、互斥量、信号量。 线程实现有两种方式实现线程，在用户空间中和在内核中，各有利弊。 用户级线程在用户级线程中，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。 应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程起始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。 优点主要有： 可以在不支持线程的操作系统上实现（只需要有线程函数库即可）； 线程切换比陷入内核要快一个数量级（调度程序也是本地程序，比内核调用效率高）； 允许每个进程有自己定制的调度算法。 当然，也有一些问题： 阻塞系统调用问题。对应用程序而言，同一进程中只能同时有一个线程在运行，一个线程的阻塞将导致整个进程中所有线程的阻塞。 页面故障问题。如果有页面引起缺页中断，通常会阻塞整个进程直到磁盘I/O完成，尽管其它的线程是可以运行的。 如果一个线程开始运行，那么在该线程中的其它线程就不能运行，除非第一个线程自动放弃 CPU（thread_yelid）。 内核级线程在内核级线程中，线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成。 内核级线程存在的一些问题： 所有能够阻塞线程的调用都以系统调用的形式实现，代价相当可观（理解为：切换线程需陷入内核，代价大） 多线程进程创建新的进程时，新进程是否需要复制所有的线程 混合实现在一些系统中，使用组合方式的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些（小于或等于用户级线程的数目）内核级线程上。 线程同步线程间通信方式主要有：事件、临界区、互斥量、信号量。生产者消费者问题（Producer-consumer problem），是一个多线程同步问题的经典案例。生产者的主要作用是重复生成一定量的数据放到缓冲区中，与此同时，消费者也在缓冲区消耗这些数据。该问题的关键就是要保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中空时消耗数据。 用信号量进行多线程的同步操作，信号量包括两个操作原语： down：检查信号量是否大于0。若该值大于0，将其值减 1（用掉一个保存的唤醒信号）并继续；若该值为0，则进程将睡眠，而且此时 down 操作并未结束。 up：对信号量的值增1，如果一个或多个进程在该信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中的一个并允许进程完成它的 down 操作。（信号量的值增1和唤醒一个进程同样是不可分隔的） 解决生产者消费者问题需要使用三个信号量：一个称为 full（初始为 0），用来记录充满的缓冲槽数目，一个称为 empty（初始为 N），用来记录空的缓冲槽数目，一个称为 mutex（初始为 1），用来确保生产者和消费者不会同时访问缓冲区。 那么生产者、消费者可以如下进行： #define N 100 semaphore mutex=1; //临界区互斥信号量 semaphore empty=n; //空闲缓冲区 semaphore full=0; //缓冲区初始化为空 producer() { //生产者 int item; while(true){ item = produce_item(); //生产数据 down(&amp;empty); //将空槽数目减1 down(&amp;mutex); //进入临界区 insert(item); //将新数据项加入到缓冲区中 up(&amp;mutex); //离开临界区,释放互斥信号量 up(&amp;full); //将满槽的数目加1 } } consumer() { //消费者 int item; while(true){ down(&amp;full); // 将满槽数目减1 down(&amp;mutex); // 进入临界区 item = remove_item(); // 从缓冲区中取出数据项 up(&amp;mutex); // 离开临界区,释放互斥信号量 up(&amp;empty); // 将空槽数目加1 consum_item(); // 处理数据项 } } 线程安全线程安全就是多线程访问时，采用了加锁机制，当一个线程访问某个数据时，进行保护，其他线程不能进行访问直到该线程访问完毕，其他线程才可使用。不会出现数据不一致或者数据污染。线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。 线程安全问题都是由全局变量或者静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。 POSIX 线程标准要求 C 标准库中的大多数函数具备线程安全性。 ［线程并发执行结果］ 进程与线程下面主要从调度、并发性、系统开销、拥有资源等方面来对线程与进程进行比较。 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。 并发性：在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间也可以并发执行，使得操作系统具有更好的并发性，从而能更加有效地使用系统资源和提高系统的吞吐量。 拥有资源：进程是拥有资源的基本单位，一般地说，线程自己不拥有系统资源（也有一点必不可少的资源），但它可以访问其所隶属进程的资源，即一个进程的代码段、数据段及所拥有的系统资源（如已打开的文件、I/O设备等），可供该进程中的所有线程所共享。 系统开销：在创建或撤销进程时，系统都要为之分配和回收进程控制块、内存空间、I/O 设备等，因此操作系统所付出的开销显著地大于创建或撤销线程时的开销。 上下文切换：在进行进程切换时，涉及到当前进程 CPU 环境的保存及新被调度运行进程 CPU 环境的设置。而线程的切换只需要保存和设置少量寄存器的内容，不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。 数据共享：由于同一个进程中的多个线程具有相同的地址空间，在同步和通信的实现方面线程也比进程容易。在一些操作系统中，线程的切换、同步和通信都无须操作系统内核的干预。 调度在多道程序系统中，进程的数量往往多于 CPU 的个数，进程争用 CPU 的情况就在所难免。调度是对 CPU 进行分配，就是从就绪队列中，按照一定的算法（公平、髙效）选择一个进程并将 CPU 分配给它运行，以实现进程并发地执行。 调度的时机： 创建一个新的进程之后，必须决定运行父进程还是子进程 在一个进程退出时必须做出调度决策 当一个进程阻塞在 I/O 或者信号量上或由于其它原因阻塞时，必须选择另一个进程运行 在一个 I/O 中断发生时，必须做出调度决策 不同的环境需要不同的调度算法，主要分下面三种环境： 批处理：一定时间做好一定的事情 交互式：快速响应用户的请求 实时系统：或多或少必须满足截止时间 什么是好的调度算法？ 批处理系统：通常检查三个指标：吞吐量（每小时最大作业数）、周转时间（从提交到终止间的最小时间）、CPU 利用率（保持 CPU 始终忙碌） 交互式系统：最重要的指标是最小响应时间（满足快速响应请求），均衡性（满足用户的期望） 实时系统：最主要的要求是满足所有（或大多数）的截止时间要求 批处理系统中的调度算法： 先来先服务（FCFS）。易于理解且便于在程序中运行，缺点是I/O密集型操作导致效率低下； 最短作业优先（SPF）。非抢占式的批处理调度算法。 最短剩余时间优先。抢占式的算法，调度程序总是选择剩余运行时间最短的那个进程运行。 交互式系统的调度算法： 轮转调度。每个进程被分配一个时间段（时间片），允许该进程在该时间段运行。时间片太短，过多的进程切换降低效率，过长引起对短的交互请求的响应时间变长。 优先级调度。每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行。 ［作业调度设备利用率］［响应比高者优先调度］ 并发、并行并发和并行的区别就是一个处理器同时处理多个任务和多个处理器或者是多核的处理器同时处理多个不同的任务。前者是逻辑上的同时发生，而后者是物理上的同时发生． 并发(concurrent)：指能处理多个同时性活动的能力，并发事件之间不一定要同一时刻发生。 并行(parallel)：指同时发生的两个并发事件，具有并发的含义，而并发则不一定并行。 死锁死锁的规范定义如下：如果一个进程集合中的每个进程都在等待只能由该进程集合中其他进程才能引发的事件，那么该进程集合就是死锁的。 产生死锁的原因主要是： 因为系统资源不足。 进程运行推进的顺序不合适。 资源分配不当等。 产生死锁的四个必要条件： 互斥条件：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待条件：已经得到了某个资源的进程可以再请求新的资源。 不可抢占条件：已经分配给一个进程的资源不能强制性地被抢占，只能被占有它的进程显式地释放； 环路等待条件：死锁发生时，系统中一定有两个或者两个以上的进程组成的一条环路，该环路中的每个进程都在等待着下一个进程所占有的资源。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 四种处理死锁的策略： 鸵鸟策略（忽略死锁）； 检测死锁并恢复； 仔细对资源进行分配，动态地避免死锁； 通过破坏引起死锁的四个必要条件之一，防止死锁的产生。 避免死锁的主要算法是基于一个安全状态的概念。在任何时刻，如果没有死锁发生，并且即使所有进程忽然请求对资源的最大请求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。从安全状态出发，系统能够保证所有进程都能完成，而从不安全状态出发，就没有这样的保证。 银行家算法：判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求，如果满足请求后系统仍然是安全的，就予以分配。不安全状态不一定引起死锁，因为客户不一定需要其最大贷款额度。 ［死锁产生必要条件］［资源一定，进程最多申请多少资源］ 更多阅读《UNIX网络编程》《现代操作系统》《UNIX 环境高级编程》 进程与线程的一个简单解释Linux的IPC命令操作系统(计算机)进程和线程管理内核线程与用户线程的一点小总结孤儿进程与僵尸进程sem_init on OS X 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch1-主机规划与磁盘分区]]></title>
    <url>%2Fse-notes%2FLinux%E5%9F%BA%E7%A1%80%2Fch1-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[主机规划与磁盘分区 磁盘分区表 MBR 与开机流程 磁盘分区的选择 目录树结构 挂载 Ads 主机规划与磁盘分区一块磁盘可以被划分为多个分区。分区的目的包括： 数据安全性：每个分区的数据是互相隔离的。 系统性能考虑：数据集中在某个分区，当要读取该分区数据时只需查询该分区对应的柱面区段，因此了提高数据读取的速度和性能。 磁盘分区表磁盘的第一个扇区记录了两个重要信息： MBR（主引导分区）：用于引导系统加载程序，有446 bytes。 分区表：记录整个硬盘的分区状态，有64 bytes。 关于磁盘分区表： “分区”即为针对64 bytes 的分区表进行设置。但由于硬盘默认的分区表只有64 bytes ，因此最多仅能写入四组分区信息。 这四组分区称为主（Primary）或扩展（Extended）分区。扩展分区最多仅有一个，主要用于扩展分区数量，可继续划分为逻辑分区。 能够被格式化的是主分区和逻辑分区，扩展分区无法被格式化。 分区的最小单位是柱面。分区表中的每组记录区记录了该区段的起始与结束的柱面号码。 当系统要写入磁盘时，必须参考磁盘分区表，才能针对某个分区进行数据的处理。 MBR 与开机流程开机流程涉及到 BIOS 与 CMOS ，其中 CMOS 是记录各项硬件参数且嵌入在主板上面的存储器，BIOS 则是一个主板上的驱动，是开机时计算机系统主动执行的第一个程序。 整个开机流程如下： BIOS：开机时主动执行的驱动程序，根据用户的设置识别可开机的存储设备。 MBR：可开机的存储设备中第一个扇区内的主引导分区，包含了引导加载程序。 引导加载程序（Boot loader）：一个主要用于读取内核文件来执行的程序。其功能还包括：提供菜单、移交控制权给其他 loader。 内核文件：开始操作系统的功能。 磁盘分区的选择目录树结构 如上图所示，目录树中所有的文件都是由根目录(/)衍生来的，而次目录之下还能够有其他的数据存在。上图中长方形为目录， 波浪形则为文件。 挂载挂载：利用一个目录当进入点，将磁盘分区的数据放置在该目录下，即：进入该目录就可以读取该分区。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch2-Linux的文件权限与目录配置]]></title>
    <url>%2Fse-notes%2FLinux%E5%9F%BA%E7%A1%80%2Fch2-Linux%E7%9A%84%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E4%B8%8E%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Linux的文件权限与目录配置 用户与用户组 Linux文件权限概念 Linux文件属性 改变文件属性与权限 改变文件所属用户组：chgrp 改变文件所有者：chown 改变文件权限：chmod 目录与文件的权限意义 文件的权限 目录的权限 Linux目录配置 Ads Linux的文件权限与目录配置用户与用户组Linux的每个文件中，依据权限分为用户、用户组与其他人三种身份。用户可以有多个用户组的支持。 默认情况下，系统上所有用户账号的相关信息都储存在 /etc/passwd 文件中。 个人密码存储在 /etc/shadow 文件中 所有组名都存储在 /etc/group 文件中 Linux文件权限概念Linux文件属性使用命令# ls -al可查看当前目录下所有文件的详细权限与属性，如：12345678910111213141516[root@www ~]# ls -altotal 156drwxr-x--- 4 root root 4096 Sep 8 14:06 .drwxr-xr-x 23 root root 4096 Sep 8 14:21 ..-rw------- 1 root root 1474 Sep 4 18:27 anaconda-ks.cfg-rw------- 1 root root 199 Sep 8 17:14 .bash_history-rw-r--r-- 1 root root 24 Jan 6 2007 .bash_logout-rw-r--r-- 1 root root 191 Jan 6 2007 .bash_profile-rw-r--r-- 1 root root 176 Jan 6 2007 .bashrc-rw-r--r-- 1 root root 100 Jan 6 2007 .cshrcdrwx------ 3 root root 4096 Sep 5 10:37 .gconf &lt;=范例说明处drwx------ 2 root root 4096 Sep 5 14:09 .gconfd-rw-r--r-- 1 root root 42304 Sep 4 18:26 install.log &lt;=范例说明处-rw-r--r-- 1 root root 5661 Sep 4 18:25 install.log.syslog[ 1 ][ 2 ][ 3 ][ 4 ][ 5 ][ 6 ][ 7 ][ 权限 ][连结][拥有者][群组][文件容量][ 修改日期 ][ 文件名 ] 文件属性示意图如下： 第一列代表该文件的类型与权限，共计有十个字符： 第一个字符代表该文件的类型： [d] 表示目录 [-] 表示文件 [|] 表示链接文件 接下来的字符以3个为一组，且均为 “rwx” 的3个参数的组合。“rwx” 分别代表可读、可写与可执行。三个权限的位置不会改变，若没有权限则会出现[-]。 第一组为“文件所有者”的权限。 第二组为“同用户组”的权限。 第三组为“其他非本用户组的权限”。 第二列表示有多少文件名链接到此节点（i-node）： 每个文件会将它的权限与属性记录到文件系统的 i-node 中，由于目录树是使用文件名来记录，因此每个文件名就会链接到一个 i-node 。 该属性记录有多少不同的文件名链接到同一个 i-node 。 第三列表示该文件（或目录）的所有者用户。 第四列表示该文件的所属用户组。 第五列表示该文件的容量大小，默认单位为 Byte 。 第六列表示该文件的创建文件日期或是最近的修改日期。 第七列表示该文件的文件名，但如果文件名前多一个“ . ”，则表示该文件为“隐藏文件”。 改变文件属性与权限在复制文件给其他用户等情况下，需要改变文件的所有者或者权限。 改变文件所属用户组：chgrp1234567#语法：[root@www ~]# chgrp [-R] 用户组名称 文件或目录名#-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件、目录都更新成为这个群组之意。 #范例：改变文件install.log的用户组为users[root@www ~]# chgrp users install.log 改变文件所有者：chown1234567891011#语法：[root@www ~]# chown [-R] 账号名称 文件或目录[root@www ~]# chown [-R] 账号名称:组名 文件或目录#-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都变更#范例：将install.log的拥有者改为bin这个log用户：[root@www ~]# chown bin install.log#范例：将install.log的拥有者与群组改回为root：[root@www ~]# chown root:root install.log 改变文件权限：chmod有两种权限设置方法：数字类型更改权限与符号类型更改权限。 数字类型更改权限 使用数字来代表“rwx”三个权限，其中 r：4；w：2；x：1。 每种身份（owner，group，others）各自的三个权限数字需要累加。 如当权限为 [-rwxrwx—] 时，分数则是：owner = rwx = 7 ；group = rwx = 7 ；others = — =0 。因此总的权限分数就是 770 。 更改权限的命令语法：# chmod [-R] xyz 文件或目录，xyz 即为总的权限分数。 符号类型改变文件权限 用 u、g、o 分别代表 user、group、others 3种身份，此外 a 代表 all，即全部的身份。读写的权限可以写成 r，w，x 。可使用的操作符号有 +（加入）、- （除去）、= （设置）。 更改权限的命令语法：# chmod [-R] 操作表达式 文件或目录，操作表达式是如u=rwx,go=rx或者a+w,o-x的式子。 目录与文件的权限意义文件的权限 r(read)：读取该文件的内容 w(write)：编辑该文件的内容但不可删除该文件 x(execute)：该文件具有可被系统执行的权限。一个文件能否被执行与文件名没有绝对关系 目录的权限 r(read)：读取该目录结构列表的权限 w(write)：读取该目录结构列表的权限，包括新建、删除、重命名该目录下的文件与目录 x(execute)：用户能否进入该目录成为工作目录的权限 开放目录给人浏览时，至少应给予 r 与 x 的权限，但 w 权限不可随便给予。 Linux目录配置FHS（Filesystem Hierarchy Standard）的主要目的在于规范每个特定目录下放置什么样的数据。所定义的三层主目录为/、/var、/usr 。有五个目录不可与根目录放在不同的分区，分别为/etc, /bin, /lib, /dev, /sbin。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch3-Linux文件与目录管理]]></title>
    <url>%2Fse-notes%2FLinux%E5%9F%BA%E7%A1%80%2Fch3-Linux%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux文件与目录管理 1.目录与路径 2.文件与目录管理 3.文件内容查阅 4.文件与目录的默认权限与隐藏权限 文件默认权限：umask 文件隐藏属性 文件特殊权限：SUID、SGID、SBIT 5.命令与文件的查询 脚本文件名的查询 文件名的查找 Ads Linux文件与目录管理1.目录与路径 常用的目录操作 cd：切换目录 pwd：显示当前目录 mkdir：新建一个目录 rmdir：删除一个空目录 执行文件路径变量：$PATH 当执行一个命令时，系统会按照 PATH 的设置去其定义的目录下查询命令对应的可执行文件。 多个目录下有与命令相同的文件时，按照先被查询的目录下的文件执行。 2.文件与目录管理 查看文件与目录：ls 123456[root@www~]# ls [参数] [目录名称]# 常用参数：# -a：全部文件，包括隐藏文件# -d：仅列出目录本身，而非目录内文件数据# -l：列出长数据串，包含文件属性与权限等数据 复制文件或目录：cp 12345678[root@www~]# cp [参数] 源文件 目标文件# 常用参数：# -a：相当于 -pdr# -i：若目标文件已经存在，覆盖时会先询问操作的进行# -p：连同文件的属性一起复制过去，而非使用默认属性。常用于备份# -d：若源文件为链接文件，则复制链接文件的属性而非实际文件本身# -r：递归持续复制，常用于目录的复制行为 默认条件下，cp 的源文件与目的文件的权限是不同的，目的文件的所有者通常是命令操作者本身。因此，在进行备份时，一些需特别注意的特别权限文件如密码文件等，不能直接用 cp 来复制，而必须要加上 -a 或者是 -p 等可以完整复制文件权限的参数。 删除文件或目录：rm 123456[root@www~]# rm [参数] 文件# 常用参数：# -f：强制模式，忽略不存在的文件，不会出现警告信息# -i：互动模式，删除前询问用户是否操作# -r：递归删除，特别危险的参数（古往今来多少数据死于rm -rf） 移动文件或目录：mv 1234567[root@www~]# mv [参数] 源文件 目标文件[root@www~]# mv [参数] 源文件1 源文件2 ... 目标目录# 常用参数：# -f：强制模式，若目标文件已经存在则不会询问，强行覆盖。# -i：互动模式。# -u：更新模式，若目标文件已经存在，且源文件比目标文件要新，才会更新。 取得路径的文件名与目录名称：basename 与 dirname 3.文件内容查阅直接查阅文件内容： cat：从第一行开始显示文件内容 参数 -b：打印行号，但空白行不标行号 参数 -n：显示结尾断行字符 $ 参数 -T：将 Tab 按键以 ^I 显示出来 tac：从最后一行开始倒序显示文件内容 nl：显示时输出行号 翻页查看： more：向后一页一页翻动 less：既可向后、也可向前一页一页翻动 数据选取： head：取出前面几行，# head [-n number] 文件名，其中 number 为显示行数 tail：取出后面几行，# head [-n number] 文件名，其中 number 为显示行数 查阅非纯文本文件： od：读取数据文件。# od [-t TYPE] 文件 参数 TYPE 为 a：使用默认的字符来输出 参数 TYPE 为 c：使用 ASCII 方式来输出 其他操作： touch：修改文件时间或创建新文件 file：查看文件类型 4.文件与目录的默认权限与隐藏权限文件默认权限：umask即当前用户在新建文件或目录时的权限默认设置值。123456[root@www ~]# umask 0022 #与一般权限有关的是后面三个数字 [root@www ~]# umask -S u=rwx,g=rx,o=rx #以符号形式显示[root@www ~]# umask 002 # 设置 unmask 值为002 在原始默认权限的属性上，目录与文件是不一样的： 若用户创建文件则默认没有 x 权限，默认权限为：-rw-rw-rw- 若用户新建目录，由于 x 权限与是否可以进入此目录有关，因此默认所有权限开放，即：drwxrwxrwx 注意的是，umask 的分数是指 “默认值再需要减去的权限”。因此当 umask 分数是022时，则用户新建文件的权限是 -rw-r–r–；新建目录的权限是 drwxr-xr-x 。 文件隐藏属性文件的隐藏属性主要用于系统安全方面。 chattr：设置文件的隐藏属性 123456789[root@www ~]# chattr [+-=] [参数] 文件或目录名# 参数：# +：增加某个特殊参数，其他已存在参数不动# -：删除某个特殊参数，其他已存在参数不动# =：仅有后面接的参数# a：让该文件只能增加数据，而不能删除与修改数据（主要用于日志文件）。只有root可设置本权限。# i：让该文件不可被删除、改名、设置链接、增写数据（无敌状态）。只有root可设置本权限。 lsattr：显示文件的隐藏属性 123456[root@www ~]# lsattr [参数] 文件或目录名# 参数：# -a：列出隐藏文件# -d：若接的是目录，则仅列出目录本身属性# -R：连同子目录的数据也列出来 文件特殊权限：SUID、SGID、SBIT 文件具有SUID的特殊权限时，代表当使用者运行此 binary 程序时，在运行过程中使用者会暂时具有程序拥有者的权限，权限数字为4 目录具有SGID的特殊权限时，代表使用者在这个目录底下新建的文件之群组都会与该目录的群组名称相同，权限数字为2 目录具有SBIT的特殊权限时，代表在该目录下使用者创建的文件只有自己与root能够删除，权限数字为1 5.命令与文件的查询脚本文件名的查询 which：寻找“执行文件”123[root@www ~]# which [-a] command# 参数# -a：列出所有可以从PATH路径找到的同名执行文件 文件名的查找 whereis（寻找特定文件） 123456[root@www ~]# whereis [-bmsu] 文件或目录# 参数# -b：只找二进制格式的文件# -m：只找在说明文件manual路径下的文件# -s：只找source源文件# -u：查找不在上述三个选项中的其他特殊文件 locate（关键字查找文件）须安装 mlocate 方可使用。 1234[root@www ~]# locate [-ir] keyword# 参数# -i：忽略大小写差异# -r：后面可接正则表达式的显示方式 find（功能最强的查询） 1234567891011121314151617[root@www ~]# find [PATH] [option] [action]# 1.与时间有关的参数：共有 -atime、-ctime 和 -mtime# -mtime n ： n 为数字，表示在 n 天之前的“一天之内”被更改过的文件# -mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过的文件# -mtime -n ：列出在 n 天之内(含 n 天本身)被更动过的文件# -newer file ：file 为一个存在的文件，列出比 file 还要新的文件# 2.与用户或用户组有关的参数：# -user name ：name 为用户名。例如 dmtsai# -group name ：name 为用户组，例如 users # 3.与文件权限及名称有关的参数：# -name filename：查找文件名为 filename 的文件# -size [+-]SIZE：查找比 SIZE 还要大(+)或小(-)的文件，如“-size +50k”# -type TYPE：查找文件类型为 TYPE 的文件，包括：一般文件(f)、目录(d)、链接文件(l)# -perm mode：查找文件权限刚好等于 mode 的文件 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch4-Linux磁盘与文件系统管理]]></title>
    <url>%2Fse-notes%2FLinux%E5%9F%BA%E7%A1%80%2Fch4-Linux%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux磁盘与文件系统管理 1. EXT2文件系统 EXT2文件系统的组成部分 与目录树的关系 2. 文件系统的简单操作 磁盘与目录的容量：df、du 连接文件 硬连接或实际连接（hard link） 符号连接（symbolic link） 3. 磁盘的分区、格式化、检验和挂载 4. 设置开机挂载 5. 内存交换空间（swap）的构建 使用物理分区构建 swap 使用文件构建 swap Ads Linux磁盘与文件系统管理1. EXT2文件系统Linux 操作系统的文件数据包括文件内容和文件属性，其中权限和属性放置到 inode 中，实际数据放置到 data block 中。每个 inode 与 block 都有编号。 EXT2文件系统的组成部分EXT2 文件系统在格式化时被区分为多个块组（Block Group），每个块组有独立的 inode/block/superblock 系统。 date block（数据块） 用于放置文件内容，若文件过大则会占用多个block inode table （inode 表） 记录文件属性以及文件的实际内容所放置的 block 编号 每个 inode 大小固定为128 Bytes，每个文件仅会占用一个 inode 系统读取文件时需先读文件的 inode，若其所记录的权限允许，才可实际读取 block 的内容 superblock（超级块） 记录文件系统的整体信息，包括 inode 与 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等 File system Description（文件系统描述说明） 描述每个 block group 的开始与结束的 block 号码 说明每个区段（包括superblock、bitmap、inodemap、data block）分别介于哪个 block 号码之间 block bitmap（块对照表） 记录每个 block 的使用情况 inode bitmap（inode对照表） 记录每个 inode 的使用情况 与目录树的关系当新建一个文件时，该文件被分配一个 inode 以及适应文件大小的多个 block。 当在 Ext2 文件系统中新建一个目录时，该目录被分配一个 inode 以及至少一个 block。其中 inode 记录该目录的相关权限与属性，并记录分配到的 block 的号码；而 block 记录在该目录下的文件名与该文件名占用的 inode 的编号，如下所示： 当读取目录树时，系统读取挂载点的信息从而得到根目录（广义上的）的 inode 内容，并根据该 inode 读取根目录内的文件数据，逐层向下读直到读取正确的文件名。 关于挂载：挂载是文件系统和目录树的结合；挂载点一定是目录，该目录为进入该文件系统的入口。 2. 文件系统的简单操作磁盘与目录的容量：df、dudf 用于列出文件系统整体磁盘使用量123[root@www ~]# df [-ahikHTm] 目录或文件名# -h：以GB、MB、KB等格式自行显示# -i：不用硬盘容量，而以 inode 的数量来显示 du用于评估文件系统的磁盘使用量123[root@www ~]# du [-ahskm] 目录或文件名# -h：以易读方式显示# -s：只列出总量 连接文件硬连接或实际连接（hard link）由于每个文件只会占用一个 inode，文件内容由 inode 的所指向的 block 来指定，且若要读取文件，必须经过目录记录的文件名来指向正确的 inode 。因此文件名只和目录有关，而文件内容只和 inode 有关。 此种情况下，则可能有多个文件名对应到同一个 inode 。即：hard link 只是在某个目录下新建一条文件名连接到已有的某 inode 的关联记录而已。 上图示意：可通过1或2的目录 inode 指定的 block 找到两个不同的文件名，而不管通过哪个文件名均可以指向 real 这个 inode 来读取最终数据。 hard link 的限制： 不能跨文件系统 不能硬连接到目录（因为硬连接到目录时，连接数据需要连同被连接目录下的所有数据都建立连接，会造成大的复杂度）#这里不太懂 符号连接（symbolic link）符号连接即是创建一个独立（即拥有和源文件不一样的 inode）文件，该文件会让数据的读取指向其连接的那个文件的文件名，类似于“快捷方式”。 上图示意：由1号 inode读取到连接文件的内容仅有文件名，根据文件名连接到正确的目录去取得目标文件的 inode，即可读取到正确数据。 123[root@www ~]# ln [-sf] 源文件 目标文件# -s：如果不加任何参数，则是hard link，至于-s则是symbolic link# -f：目标文件存在时，删除目标文件再创建 3. 磁盘的分区、格式化、检验和挂载磁盘管理是对 Linux 系统管理中的重要一环。当想要在系统中新增一块硬盘时，应该： 对磁盘进行分区，以新建可用的分区 对该分区进行格式化，以创建系统可用的文件系统 对新建文件系统进行检验 在 Linux 系统上创建挂载点（也即目录），并将其挂载 以下是几个常用的命令： 磁盘分区：fdisk、parted 磁盘格式化：mkfs 磁盘检验：fsck、badblocks 磁盘挂载与卸载：mount、umount 略。 4. 设置开机挂载手动处理 mount 很麻烦，需要设置成让系统在开机时自动挂载。 略。 5. 内存交换空间（swap）的构建swap 的功能是在物理内存不足时作为内存扩展（虚拟内存）。 使用物理分区构建 swap 分区：使用 fdisk 在磁盘中分出一个分区给系统作为 swap。 格式化：mkswap 设备文件名即可格式化该分区。 使用：swapon 设备文件名启动该 swap 设备。 查看：通过free查看内存使用情况。 使用文件构建 swap 使用dd新增一个大文件（如128MB）在 /tmp 下 使用mkswap将 /tmp/swap 这个文件格式化为 swap 的文件格式 使用mkswap将 /tmp/swap 启动 使用swapoff将 /tmp/swap 关闭 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Linux</category>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>系统管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算实践-README]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2FREADME%2F</url>
    <content type="text"><![CDATA[配置虚拟云主机(CentOS 7) 安装操作系统 配置IP地址 更改yum源 关闭防火墙与SELinux 更改语言 Ads 配置虚拟云主机(CentOS 7)以下所有操作均在 root 权限下完成。 安装操作系统以 vSphere Client 为例，当一个新的云虚拟机（非模板复制）选择完硬件配置并创建完成后，需要在该虚拟机上安装操作系统： 下载操作系统的 ISO 文件（如 CentOS-7-x86_64-DVD-1511.iso ）到本地。 通过本地的 VMware Workstation ，设置虚拟机的光驱为“启动时连接”与“已连接”，并使用ISO镜像文件为本地已下载的操作系统ISO文件。 重新启动虚拟机，进入操作系统安装界面，等待一段时间后安装完成。 可通过passwd命令来修改root密码；编辑/etc/hostname来修改主机名（重启后生效）。 配置IP地址安装完操作系统后，由于 CentOS7 默认不开启网络，故需要修改一下配置才能使虚拟机自动获得由物理机所分配的IP地址。 使用命令cd /etc/sysconfig/network-scripts/ ，找到以太网卡配置文件 ifcfg-e** 文件，文件名后面的数字一般是随机生成的。把该文件里onboot的值修改为yes。此外，如果遇到网络服务重启失败，可以查看该文件里的 Mac 地址与ipconfig命令所查询到的 Mac 地址是否相同。 若ifconfig命令无法使用，则需使用yum install net-tools.x86_64 命令来安装该网络工具包。安装完成后使用该命令即可查看虚拟机所获得的IP。 若发现无法ping通一些域名，可打开vi /etc/resolv.conf，增加条目 nameserver 8.8.8.8 或者 nameserver 114.114.114.114（其他可用的DNS服务器亦可）。 若无法ping通域名，在 ifcfg-e** 文件中设置 DNS1 = 8.8.8.8 或 114.114.114.114。 若需使同一网络上的各个虚机能互相解析彼此的主机名为IP地址，需要在每个虚机的 /etc/hosts 文件里写入每一台虚机的IP地址与主机名。如172.18.216.211 mon。具体参考 /etc/hosts详解 。 更改yum源Linux的默认官方yum源在国内访问不佳、速度慢，因此把yum源更改为国内比较好的 阿里云开源镜像站 或者 清华大学开源镜像站 能获得极大的下载速度提升。 在修改完/etc/yum.repos.d/下yum源的CentOS-Base.repo后，依次执行yum clean all与yum makecache来删除与更新yum源的缓存。若在执行命令的过程中发现yum源总是切换到速度满的其他yum源进行下载，则可以在目录下修改该劣质yum源的repo文件，把其enabled值设置为 0 即可。 使用yum install epel-release命令可安装 epel 源，该源提供了很多扩展性的功能软件。 关闭防火墙与SELinux使用某些网络应用时可能需要关闭防火墙与SELinux服务。 关闭 SELinux：编辑 /etc/selinux/config ，设置SELINUX = disabled； 执行# setenforce 0可即时生效。可使用# getenforce命令查看SELinux状态。 关闭防火墙服务： 12# systemctl stop firewalld# systemctl disable firewalld 更改语言修改配置文件/etc/locale.conf。若改为英文则写入：LANG=&quot;en_US.UTF-8&quot;，改为中文则写入：LANG=&quot;zh_CN.UTF-8&quot;。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础-README]]></title>
    <url>%2Fse-notes%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2FREADME%2F</url>
    <content type="text"><![CDATA[数据与数据库 数据库系统的目标 数据模型- [Ads](#ads) 数据与数据库数据（Data）是描述事物的符号，是数据库中存储的基本对象。在日常生活中，人们使用自然语言来描述事物，而在计算机中，为了存储和处理事物，必须抽取出事物的某些本质特性，用记录的形式来描述。例如在员工档案中，人们最感兴趣的是员工号、员工姓名、员工性别、出生日期、工资、部门号等信息。 数据库（DataBase，DB）是指按一定的数据模型组织、描述和存储的数据的集合。数据库中的数据具有较小的冗余度和较高的数据独立性，可以实现数据共享，由数据库管理系统统一管理。 数据库管理系统（DBMS）由一个数据库以及一组用于访问数据库的程序组成，其主要目标是提供一种可以方便、高效地存取数据库信息的途径。 数据库系统的目标传统的文件处理系统：把数据存放在操作系统文件之中；为了使用户可以对信息进行操作，系统也有一些对文件进行操作的应用程序。 数据库系统需要解决传统的文件处理系统处理数据的弊端： 数据的冗余和不一致：不同文件可能有不同结构、不同程序用不同语言、可能存储冗余信息 数据访问困难：访问程序可能需要临时编写 数据孤立：数据分散在不同文件中，又可能有不同文件格式 完整性问题：难以增加或修改新的约束条件 原子性问题：文件系统难以保持原子性 并发访问异常：多个读写线程竞争 安全问题：难以实现安全性 数据模型数据库结构的基础是数据模型，它是一个描述数据、数据联系、数据语义以及一致性约束的概念工具的集合。数据模型可划分为四类： 关系模型：用表的集合来表示数据和数据之间的关系 实体-联系模型：基于现实世界——现实世界由一组称为实体的基本对象和这些对象之间的联系组成 基于对象的数据模型：可视为 E-R 模型增加了封装、方法（函数）和对象标识等概念后的扩展 半结构化数据模型：允许相同类型的数据项含有不同的属性集的数据定义 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>数据库</category>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch1-关系模型]]></title>
    <url>%2Fse-notes%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2Fch1-%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[关系数据库 码 关系代数- [基本关系代数运算](#基本关系代数运算) - [附加关系代数运算](#附加关系代数运算) - [Ads](#ads) 关系数据库关系数据库由表的集合构成，每个表有唯一的名字。表中的一行代表了一组值之间的一种联系。 在关系模型的术语中，关系(relation)用来指代表，而元组(tuple)用来指代行，属性(attribute)指表中的列。关系实例(relation instance)表示一个关系的特定实例，也就是所包含的一组特定的行。对于关系的每个属性，都存在一个允许取值的范围，称为该属性的域(domain)。 码一个关系中没有两个元组在所有属性上的值相同，因此一个元组的属性值必须要能够唯一区分元组。 超码：一个或多个属性的集合，这些属性的组合可以在一个关系中唯一地标识一个元组。超码中可以包含无关紧要的属性，如果 k 是一个超码，那么 k 的任意超集也是超码。 候选码：任意真子集都不能成为超码的超码，也即最小超码。有可能有多个不同的属性集都可以做候选码。 主码：被数据库设计者选中的，主要用来在一个关系中区分不同元组的候选码。主码的选择必须慎重，应该选择那些值从来不变或者极少变化的属性。 外码：若一个关系模式（如 r1）可能在它的属性中包括另一个关系模式（如 r2）的主码，则这个属性在 r1 上称作参照 r2 的外码 关系代数关系代数是一种过程化查询语言，包括一个运算的集合。这些运算以一个或者两个关系作为输入，产生一个新的关系作为结果。关系代数的基本运算有：选择、投影、并、集合差、笛卡尔积和更名。在基本运算外，还有一些其它运算，即集合交、自然连接和赋值。 基本关系代数运算 基本关系运算 解释 选择 σ 从关系的水平方向进行运算，选择满足给定条件的元组组成新的关系 投影 π 从关系的垂直方向开始运算，选择关系中的若干列组成新的列 并 R,S 具有相同的关系模式，RUS 为属于R或者S的元组 集合差 R,S 具有相同的关系模式，R-S为属于R但不属于S的元组 笛卡儿积 从两个输入关系中输出所有的元组对（无论它们在共同属性上的取值是否相同） 更名 ρ 将更名运算运用于关系 r，得到一个具有新名字的相同关系 附加关系代数运算通过定义一些附加的运算，虽然不能增强关系代数的表达能力，却可以简化一些常用的查询。 附加关系运算 解释 集合交运算 R,S具有相同的关系模式，R∩S=R-(R-S) 自然连接 ⋈ R⋈S 的结果是在R和S中的在它们的公共属性名字上相等的所有元组的组合。 赋值运算 ← 类似程序语言中的赋值，将 ← 右侧的表达式的结果赋给左侧的关系变量，该关系变量可以在后续的表达式中使用 左外链接 ⟕ R ⟕ S，包含R中所有元组，对每个元组，若在S中有在公共属性名字上相等的元组，则正常连接，若在S中没有在公共属性名字上相等的元组，则依旧保留此元组，并将对应其他列设为NULL 右外链接 ⟖ R ⟖ S，外连接的结果包含S中所有元组，对每个元组，若在R中有在公共属性名字上相等的元组，则正常连接，若在R中没有在公共属性名字上相等的元组，则依旧保留此元组，并将对应其他列设为NULL。 全外链接 ⟗ R ⟗ S，全外连接的结果包含R与S中所有元组，对每个元组，若在另一关系上中有在公共属性名字上相等的元组，则正常连接，若在另一关系上中没有在公共属性名字上相等的元组，则依旧保留此元组，并将对应其他列设为NULL。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>数据库</category>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch2-SQL基础]]></title>
    <url>%2Fse-notes%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%2Fch2-SQL%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[SQL 简介 SQL DDL 属性基本类型 基本模式定义 SQL DML：增删查改 查询 自然连接 插入 更新 删除 附加的基本运算 更名运算 WHERE 子句 ORDER BY 子句 集合运算 聚集函数 基本聚集 分组聚集 HAVING 子句 嵌套子查询 执行顺序- [Ads](#ads) SQL 简介SQL (结构化查询语言)是一门标准计算机语言，用来访问和操作数据库系统。 可以把 SQL 分为两个部分：数据操作语言 (DML) 和 数据定义语言 (DDL)。DML 提供从数据库中查询信息，以及在数据库中插入、删除、修改元组的命令，DDL 提供定义、删除、修改关系模式的命令。 SQL 的数据操作语言（DML）部分包括删除、更新、插入、查询操作： SELECT - 从数据库表中获取数据 UPDATE - 更新数据库表中的数据 DELETE - 从数据库表中删除数据 INSERT INTO - 向数据库表中插入数据 SQL 的数据定义语言（DDL）部分使我们有能力创建或删除表格。我们也可以定义索引（键），规定表之间的链接，以及施加表间的约束： CREATE DATABASE - 创建新数据库 ALTER DATABASE - 修改数据库 DROP DATABASE - 删除数据库 CREATE TABLE - 创建新表 ALTER TABLE - 变更数据库表 DROP TABLE - 删除表 CREATE INDEX - 创建索引 DROP INDEX - 删除索引 此外 SQL 还包括定义完整性约束的命令，定义视图的命令，定义事务的开始和结束的命令，定义对关系和视图的访问权限的命令等。 注意：SQL 语句对大小写不敏感 SQL DDL数据库中的关系集合必须由数据定义语言（DDL）指定给系统。 属性基本类型 char(n)：固定长度的字符串，用户指定长度 n varchar(n)：可变长度的字符串，用户指定最大长度 n int：整数类型 smallint：小整数类型 numeric(p,d)：定点数，精度由用户指定。这个数有 p 位数字，其中 d 位在小数点右边 float(n)：精度至少为 n 位的浮点数 每种类型都可能包含一个被称作空值（null）的特殊值。123select namefrom studentwhere salary is null; // 使用is null和is not null来判断是否是空值，而非用等号 基本模式定义使用 create table 命令定义 SQL 关系，如下：123456create table department (dept_id varchar(5), dept_name varchar(20) not null, //设置为非空属性 building_id varchar(5), primary key(dept_id), //设置dept_id为主键 foreign key(building_id) reference building); //设置building_id为来自表building的外键 使用 drop table 命令可以从数据库中去掉一个关系，其将会从数据库中删除关于被去掉关系的所有信息。 PS：drop table 与 delete from 命令不同，后者虽然会删除所有元组但会保留关系 使用 alter table 命令可以修改关系： 为已有关系增加属性：alter table r add A D;，其中 r 是现有关系名，A 是待添加属性的名字，D 是待添加属性的域 为已有关系去掉属性：alter table r drop A; 为已有关系修改属性：alter table r alter A D; SQL DML：增删查改查询SELECT 语句用于从表中选取数据，结果存储在一个结果表中。SQL 查询的基本结构由三个子句组成：select、from 和 where。SQL 查询的输入是在 from 子句中列出的关系，在这些关系上进行 where 和 select 子句中指定的运算，然后产出一个关系作为结果。语法如下： SELECT column_name,column_name FROM table_name WHERE p 例如，下列 SQL 语句返回所有有定单的客户： SELECT Orders.orderID, Customer.customerID FROM Orders, Customers WHERE Orders.CustomerID = Customers.CustomerID 一个 SQL 查询的执行顺序如下： 为 from 子句中列出的关系产生笛卡儿积 在步骤 1 的结果上应用 where 子句中指定的谓词 对于步骤 2 的结果中的每个元组，输出 select 字句中指定的属性（或表达式的结果） PS：select 子句可带有含 +、-、*、/ 等的算术表达式；where 子句中允许使用逻辑连词 and、or 和 not 。 自然连接自然连接作用于两个关系，并产生一个关系作为结果。不同于两个关系上的笛卡儿积（笛卡儿积把第一个关系的所有元组和第二个关系的所有元组都进行连接），自然连接只考虑那些在两个关系模式的公共属性上取值相同的元组对。SQL 支持使用自然连接运算。123select name, course_idfrom instructor, teacheswhere instructor.ID = teaches.ID; 以上代码可以使用 SQL 的自然连接运算重写为：12select name, course_idfrom instructor natural join teaches; 为了避免不必要的相等属性带来的危险，SQL 提供一种自然连接的构造形式join ... using或join ... on，允许用户来指定需要哪些列相等。如：12345select name, titlefrom teaches join course using (course_id); /*可跟多个列*/select name,titlefrom teaches join course on teaches.course_id = course.course_id; /*可在 on 后接子句*/ 插入INSERT INTO 语句用于向表中插入新记录。要往关系中插入数据，可以指定待插入的元组，或者写一条查询语句来生成待插入的元组集合。必须保证待插入元组的属性值必须在相应属性的域中。 insert 语句中可以指定属性，也可以不指定，不指定属性时，插入值的排序和关系模式中属性排列的顺序一致。 insert into course values(&apos;CS-437&apos;,&apos;Database System&apos;, &apos;Comp. Sci&apos;, 4); insert into course(course_id, title, dept_name, credits) values(&apos;CS-437&apos;,&apos;Database System&apos;, &apos;Comp. Sci&apos;, 4); insert into course(title, course_id, dept_name, credits) values(&apos;Database System&apos;, &apos;CS-437&apos;, &apos;Comp. Sci&apos;, 4); 更新update 语句可以在不改变整个元组的情况下改变其部分属性的值。假如要进行年度工资增长，如下： update instructor set salary=salary*1.5 上面更新语句将在 instructor 关系的每个元组上执行一次。update 语句中嵌套的 select 语句可以引用待更新的关系，对工资低于平均工资的教师涨 5% 的工资，可以写成如下形式： update instructor set salary=salary*1.05 where salary &lt; (select avg(salary) from instructor); SQL 语句提供 case 语句，可以利用它在一条语句中执行多种更新，避免因为更新次序可能引发的问题。 update instructor set salary=case when salary = 7000 then salary * 1.05 when salary &lt; 7000 then salary * 1.15 else salary * 1.03 end 删除DELETE 语句用于删除表中的记录。只能删除整个元组，而不能只删除某些属性上的值。 DELETE FROM r WHERE p; 其中 P 代表一个谓词，r 代表一个关系。delete 语句首先从 r 中找出所有使 P(t) 为真的元组，然后把它们从 r 中删除。如果省略 where 子句，则 r 中所有元组将被删除。 delete 请求可以引用包含嵌套的 select，该 select 引用待删除元组的关系。假如想删除工资低于大学平均工资的教师记录，可以写出如下语句： delete from instructor where salary &lt; (select avg(salary) from instructor); 该 delete 语句首先测试 instructor 关系中的每一个元组，检查其工资是否小于大学教师的平均工资，然后再删除所有符合条件的元组。注意，这里在执行任何删除之前先进行所有元组的测试至关重要。 附加的基本运算更名运算更名运算的两个作用： 把长关系名替换为短的，查询操作更加方便 适用于关系与其自身进行运算 123select T.name, S.course_idfrom instructor as T, teaches as Swhere T.ID = S.ID WHERE 子句WHERE 子句用于提取那些满足指定标准的记录。语法如下： 123SELECT column_name,column_nameFROM table_nameWHERE column_name operator value; 下面的运算符可以在 WHERE 子句中使用： =：等于。 &lt;&gt;：不等于。（在 SQL 的一些版本中，该操作符可被写成 !=） >：大于 &lt;：小于 >=：大于等于 &lt;=：小于等于 BETWEEN：在某个范围内（和连词 and 一起使用） LIKE：搜索某种模式 IN：指定针对某个列的多个可能值 可以在字符串上可以使用like 操作符来实现模式匹配。 百分号 %：匹配任意字符串 下划线 _：匹配任意一个字符 为了使模式中包含特殊模式的字符（％，_），SQL 允许转义字符。在 like 比较运算中使用escape 关键词来定义转义字符。如下例子： like ‘ab\%cd%’ escape ‘\‘: 匹配所有以 ‘ab%cd’ 开头的字符串； like ‘[8,6]_0%’：匹配第一位为8或6，第三位为0的字符串； 所以要查找 student表中所有电话号码(列名：telephone)的第一位为8或6，第三位为0的电话号码，用下面语句即可： SELECT telephone FROM student WHERE telephone LIKE ‘[8,6]_0%’ PS：字符串大小写敏感，且使用单引号标注 ORDER BY 子句ORDER BY 关键字用于对结果集按照一个列或者多个列进行排序，默认按照升序对记录进行排序。如果需要按照降序对记录进行排序，可以使用 DESC 关键字。 123SELECT column_name,column_nameFROM table_nameORDER BY column_name ASC|DESC, column_name ASC|DESC; 如果想从 “Websites” 表中选取所有网站，并按照 “country” 和 “alexa” 列排序： 12SELECT * FROM WebsitesORDER BY country,alexa; [ 查找倒数第三个字符为W ] 集合运算SQL 作用在关系上的 union、intersect、except 运算对应于数学集合论中的∪、∩、- 运算。1234567(select course_idfrom sectionwhere semester = 'Fall' and year = 2009)union /* 或 intersect、except */(select course_idfrom sectionwhere semester = 'Spring' and year = 2010) 集合运算的结果中自动去除重复元组。若想保留重复，则分别使用 union all、intersect all、except all 来代替 union、intersect、except 。 聚集函数基本聚集SQL 拥有很多可用于计数和计算的内建函数。聚集函数计算从列中取得的值，返回一个单一的值，SQL 提供了五个固有的聚集函数： 函数 用处 AVG() 返回数值列的平均值。 COUNT() 返回匹配指定条件的行数。 MAX() 返回指定列的最大值。 MIN() 返回指定列的最小值。 SUM() 返回数值列的总数。 分组聚集Group By 语句从字面意义上理解就是根据(by)一定的规则进行分组(Group)。它的作用是通过一定的规则将一个数据集划分成若干个小的区域，然后针对若干个小区域进行数据处理。 GROUP BY 语句用于结合聚合函数，根据一个或多个列对结果集进行分组。比如统计 access_log 各个 site_id 的访问量： 12SELECT site_id, SUM(access_log.count) AS numsFROM access_log GROUP BY site_id; ［Group By 子句作用］［分组后满足指定条件的查询］ HAVING 子句在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与聚合函数一起使用。HAVING 子句可以让我们筛选已经分组后的各组数据。假设我们想要查找总访问量大于 200 的网站，可以使用下面的 SQL 语句： 123456SELECT Websites.name, Websites.url, SUM(access_log.count) AS nums FROM (access_logINNER JOIN WebsitesON access_log.site_id = Websites.id)GROUP BY Websites.nameHAVING SUM(access_log.count) &gt; 200; 现在假设想要查找总访问量大于 200 的网站，并且 alexa 排名小于 200。我们在 SQL 语句中增加一个普通的 WHERE 子句：123456SELECT Websites.name, SUM(access_log.count) AS nums FROM WebsitesINNER JOIN access_logON Websites.id=access_log.site_idWHERE Websites.alexa &lt; 200 GROUP BY Websites.nameHAVING SUM(access_log.count) &gt; 200; 嵌套子查询嵌套子查询中的一些常用判断谓词： A in B 与 A not in B ：测试元组 A 是否是子查询 B 中的成员 A &gt;some B：元组 A 至少比子查询 B 中某一个元素要大 A &gt;all B：元组 A 比子查询 B 中所有元素都要大 exist B：子查询 B 非空 unique B：子查询 B 没有重复元组 with 子句提供了定义临时关系的方法，可以使逻辑关系更加清晰：1234567/* 找出具有最大预算值的部门 */with max_budget(value) as (select max(budget) from department)select budgetfrom department,max_budgetwhere department.budget = max_budget.value 执行顺序SQL 语句的语法顺序和其执行顺序并不一致，标准的 SQL 的解析顺序为: FROM 子句, 组装来自不同数据源的数据 WHERE 子句, 基于指定的条件对记录进行筛选 GROUP BY 子句, 将数据划分为多个分组 使用聚合函数进行计算 使用 HAVING 子句筛选分组 计算 SELECT 等表达式 使用 ORDER BY 对结果集进行排序 FROM 是 SQL 语句执行的第一步，并非 SELECT。数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。 SELECT 是在大部分语句执行了之后才执行的，严格的说是在 FROM 和 GROUP BY 之后执行的。理解这一点是非常重要的，这就是你不能在 WHERE 中使用在 SELECT 中设定别名的字段作为判断条件的原因。 SELECT A.x + A.y AS z FROM A WHERE z = 10 // z 在此处不可用，因为SELECT是最后执行的语句！ 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>数据库</category>
        <category>数据库基础</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络基础-README]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2FREADME%2F</url>
    <content type="text"><![CDATA[网络层 ICMP 协议 地址解析协议（ARP） 传输层 TCP 协议 网络端口 网络套接字 TCP，UDP区别 应用层 HTTP 协议 其它 更多阅读- [Ads](#ads) 网络本质上就是解决多台计算机之间如何互相通信这个问题，从最初的ARPANET(Advanced Research Projects Agency Network) 到现在的 TCP/IP，这个本质问题并没有变化，只是技术不断改进。 20世纪60年代以来，计算机网络得到了飞速增长。各大厂商为了在数据通信网络领域占据主导地位，纷纷推出了各自的网络架构体系和标准，如IBM公司的SNA，Apple公司的AppleTalk协议，以及广泛流行的TCP/IP协议。同时，各大厂商针对自己的协议生产出了不同的硬件和软件。由于多种协议的并存，使得网络变得越来越复杂；而且，厂商之间的网络设备大部分不能兼容，很难进行通信。 为了解决网络之间的兼容性问题，帮助各个厂商生产出可兼容的网络设备，国际标准化组织ISO于1984年提出了OSI RM（OpenSystem Interconnection Reference Model，开放式系统互联通信参考模型），OSI 参考模型很快成为计算机网络通信的基础模型。该体系结构定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层和应用层），在这一框架下进一步详细规定了每一层的功能，以实现开放系统环境中的互连性、互操作性和应用的可移植性。 由于OSI模型和协议比较复杂，所以并没有得到广泛的应用。而TCP/IP(transfer control protocol/internet protocol,传输控制协议/网际协议)模型因其开放性和易用性在实践中得到了广泛的应用，TCP/IP协议栈也成为互联网的主流协议。 更多内容参考 OSI_TCP_IP 网络层网络层(network layer)是实现互联网的最重要的一层。正是在网络层面上，各个局域网根据IP协议相互连接，最终构成覆盖全球的Internet。更高层的协议，无论是TCP还是UDP，必须通过网络层的IP数据包(datagram)来传递信息。 IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGCP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制–这被认为是上层协议–TCP或UDP要做的事情。 更多内容参考 IP ICMP 协议ICMP 是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。 ICMP基于IP协议，也就是说，一个ICMP包需要封装在IP包中，然后在互联网传送。ICMP是IP套装的必须部分，任何一个支持IP协议的计算机，都要同时实现ICMP。 ICMP传输的控制信息可以分为两大类： 错误(error)信息：这一类信息可用来诊断网络故障。IP协议的工作方式是“Best Effort”，如果IP包没有被传送到目的地，或者IP包发生错误，IP协议本身不会做进一步的努力。但上游发送IP包的主机和接力的路由器并不知道下游发生了错误和故障，它们可能继续发送IP包。通过ICMP包，下游的路由器和主机可以将错误信息汇报给上游，从而让上游的路由器和主机进行调整。 咨询(Informational)信息：比如某台计算机询问路径上的每个路由器都是谁，然后各个路由器同样用ICMP包回答。 ICMP包有Type, Code和Checksum三部分： 类型：指明该数据包属于什么类型（大分类），长度1个字节。 代码：指明数据包属于大类里面的哪个小类，长度1个字节。类型字段与代码字段共同决定ICMP数据包类型，以及后续字段含义。 校验和： 指明该数据包的校验和，长度2个字节。该校验和覆盖整个ICMP数据包。 ICMP数据包通过类型字段与代码字段来共同决定该数据包传达的控制信息。常见的ICMP包类型： 0（Echo Reply）：属于咨询信息，ping命令就是利用了该类型的ICMP包。 3（Destination Unreachable）属于错误信息。如果一个路由器接收到一个IP包，不知道下一步往哪里发送，就会向出发主机发送该类型的ICMP包。 11（Time Exceeded）属于错误信息。IPv4中的Time to Live(TTL)会随着经过的路由器而递减，当这个区域值减为0时，就认为该IP包超时(Time Exceeded)。traceroute就利用了这种类型的ICMP包，它向目的地发送IP包，第一次的时候，将TTL设置为1，引发第一个路由器的Time Exceeded错误。这样，第一个路由器回复ICMP包，从而让出发主机知道途径的第一个路由器的信息。随后TTL被设置为2、3、4，…，直到到达目的主机。这样，沿途的每个路由器都会向出发主机发送ICMP包来汇报错误。traceroute将ICMP包的信息打印在屏幕上，就是接力路径的信息了。 地址解析协议（ARP）首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。 当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP地址。 当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。 源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。广播发送ARP请求，单播发送ARP响应。 RARP协议：反向地址转换协议，允许局域网的物理机器从网关服务器的ARP表或者缓存上请求其IP地址。其因为较限于IP地址的运用以及其他的一些缺点，因此渐为更新的BOOTP或DHCP所取代。 工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系。当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。 传输层TCP 协议TCP(Transmission Control Protocol)为应用程序之间提供面向连接的可靠的字节流服务。TCP为全双工协议，提供流控制机制，即允许接收方控制发送方的发送速度，此外还提供拥塞控制功能。 ［TCP 协议细节］［滑动窗口协议］［nagle算法］［拥塞控制算法］［状态转换流程］ 详细内容参见 TCP 网络端口TCP 服务器由发送端和接收端创建一种称为套接字的端点来获得，每个套接字有一个套接字编号（地址），该编号由主机的 IP 地址以及一个本地的16位数值组成的。这个16位数值称为端口，所以一共有2^16 ＝ 65535个端口可用。 1024以下的（不0包括1024）的端口被保留，只能用作由特权用户（比如UNIX系统的 root）启动的标准服务，这些端口称为知名端口。一些知名的端口如下： 端口 协议 用途 20，21 FTP 文件传输协议，21是控制端口，20是数据端口 22 SSH 远程登录，Telnet的替代 23 Telnet TELNET 终端仿真服务 25 SMTP 简单邮件传输协议 53 DNS 域名解析服务 80 HTTP 万维网, 超文本传输服务 443 HTTPS 安全的 Web 1024～49151 之间的的其它端口可以通过 IANA 注册，由非特权用户使用，但是应用程序可以选择自己的端口号。 网络套接字网络上不同的计算机之间进行 TCP、UDP通信需要使用网络套接字（socket）。socket是在不同计算机之间进行通信的一个抽象。他工作于TCP/IP协议中应用层和传输层之间的一个抽象。 socket起源于UNIX，在Unix一切皆文件哲学的思想下，socket是一种”打开—读/写—关闭”模式的实现，服务器和客户端各自维护一个”文件”，在建立连接打开后，可以向自己文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。 详细内容参见 Socket TCP，UDP区别TCP协议和UDP协议特性区别，主要从连接性、可靠性、有序性、拥塞控制、传输速度、头部大小(Header size)等6个方面来讲。 TCP是面向连接的协议，UDP是无连接协议。TCP用三次握手建立连接，UDP发送数据前不需要建立连接； TCP可靠，UDP不可靠。TCP丢包会重传，并且有确认机制，UDP不会； TCP有序，UDP无序。消息在传输过程中可能会乱序，后发送的消息可能会先到达，TCP会对其进行重排序，UDP不会； TCP 必须对数据进行校验，而UDP的校验是可选的； TCP有流量控制（滑动窗口）和拥塞控制，UDP没有； TCP传输慢，UDP传输快。因为TCP需要建立连接、保证可靠性和有序性，所以比较耗时。 TCP要建立连接、保证可靠性和有序性，就会传输更多的信息，包头比较大（TCP头部至少需要20字节，UDP头部只要8个字节）。 基于TCP的协议有：HTTP/HTTPS，Telnet，FTP，SMTP。基于UDP的协议有：DHCP，DNS，SNMP，TFTP，BOOTP。 应用层HTTP 协议HTTP 是一个客户端终端（用户）和服务器端（网站）请求和应答的标准。通过使用Web浏览器、网络爬虫或者其它的工具，客户端发起一个HTTP请求到服务器上指定端口（默认端口为80），我们称这个客户端为用户代理程序（user agent）。应答的服务器上存储着一些资源，比如HTML文件和图像，我们称这个应答服务器为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如代理服务器、网关或者隧道（tunnel）。 HTTP是一个无状态的协议，也就是说服务器不会去维护与客户交互的相关信息，因此它对于事务处理没有记忆能力。为了解决HTTP无状态的问题，HTTP 引入了 Cookie 和 Session机制，用来保存客户端状态信息。 HTTP协议中，并没有规定它支持的层。事实上，HTTP可以在任何互联网协议上，或其他网络上实现。HTTP假定其下层协议提供可靠的传输，因此，任何能够提供这种保证的协议都可以被其使用，在TCP/IP协议族使用TCP作为其传输层。 HTTP 有两个主要的版本 HTTP 1.0 和 HTTP 1.1，1.1 版本在带宽优化，长连接，缓存，Host头域，错误提示等方面有一些改进。 详细内容参见 HTTP 其它Questions 里面是一些和网络场景有关的具体问题，比如： 访问网页过程 Ping 过程 QQ 传输层 UDP More 里面是一些网络方面的零散概念，比如： 网络延迟 以太网工作模式 路由权 路由器与交换机区别 更多阅读协议森林系列文章《计算机网络》这门课为何如此之难？TCP和UDP的区别 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch1-OSI参考模型]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch1-OSI%E5%8F%82%E8%80%83%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[OSI 参考模型 TCP/IP 协议栈 更多阅读 Ads OSI 参考模型（Open System Interconnection Reference Model，开放式系统互联通信参考模型），是 ISO （国际标准化组织）组织在 1985 年研究的网络互联模型。该体系结构标准定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层和应用层），在这一框架下进一步详细规定了每一层的功能，以实现开放系统环境中的互连性、互操作性和应用的可移植性。 OSI 参考模型ISO 通信功能七个层次的划分原则是： 网路中各节点都有相同的层次； 不同节点的同等层具有相同的功能； 同一节点内相邻层之间通过接口通信； 每一层使用下层提供的服务，并向其上层提供服务； 不同节点的同等层按照协议实现对等层之间的通信。 OSI参考模型具有以下优点： 简化了相关的网络操作； 提供设备间的兼容性和标准接口； 促进标准化工作； 结构上可以分隔，各层可以独立修改或者扩充； 易于实现和维护； 有利于大家学习、理解数据通讯网络。 各层包含的协议大致如下图所示： 各层功能详述如下： 物理层 (Physical Layer)：物理层是 OSI 参考模型的最低层，它利用传输介质为数据链路层提供物理连接。它主要关心的是通过物理链路从一个节点向另一个节点传送比特流，物理链路可能是铜线、卫星、微波或其他的通讯媒介。它关心的问题有：多少伏电压代表 1 ？多少伏电压代表 0 ？时钟速率是多少？采用全双工还是半双工传输？总的来说物理层关心的是链路的机械、电气、功能和规程特性。 数据链路层 (Data Link Layer)：数据链路层是为网络层提供服务的，解决两个相邻结点之间的通信问题，传送的协议数据单元称为数据帧。数据帧中包含物理地址（又称 MAC 地址）、控制码、数据及校验码等信息。该层的主要作用是通过校验、确认和反馈重发等手段，将不可靠的物理链路转换成对网络层来说无差错的数据链路。此外，数据链路层还要协调收发双方的数据传输速率，即进行流量控制，以防止接收方因来不及处理发送方来的高速数据而导致缓冲器溢出及线路阻塞。 网络层 (Network Layer)：网络层是为传输层提供服务的，传送的协议数据单元称为数据包（分组）。该层的主要作用是解决如何使数据包通过各结点传送的问题，即通过路径选择算法（路由）将数据包送到目的地。另外，为避免通信子网中出现过多的数据包而造成网络阻塞，需要对流入的数据包数量进行控制（拥塞控制）。当数据包要跨越多个通信子网才能到达目的地时，还要解决网际互连的问题。 传输层 (Transport Layer)：传输层的作用是为上层协议提供端到端的可靠和透明的数据传输服务，包括处理差错控制和流量控制等问题，传输层传送的协议数据单元称为数据段（报文）。该层向高层屏蔽了下层数据通信的细节，使高层用户看到的只是在两个传输实体间的一条主机到主机的、可由用户控制和设定的、可靠的数据通路。 会话层 (Session Layer)：会话层主要功能是管理和协调不同主机上各种进程之间的通信（对话），即负责建立、管理和终止应用程序之间的会话。会话层得名的原因是它很类似于两个实体间的会话概念。例如，一个交互的用户会话以登录到计算机开始，以注销结束。 表示层 (Presentation Layer)：表示层处理流经结点的数据编码的表示方式问题，以保证一个系统应用层发出的信息可被另一系统的应用层读出。如果必要，该层可提供一种标准表示形式，用于将计算机内部的多种数据表示格式转换成网络通信中采用的标准表示形式。数据压缩和加密也是表示层可提供的转换功能之一。 应用层 (Application Layer)：应用层是 OSI 参考模型的最高层，是用户与网络的接口。该层通过应用程序来完成网络用户的应用需求，如文件传输、收发电子邮件等。 ［网络层含有的协议］［网络层功能］ TCP/IP 协议栈由于OSI模型和协议比较复杂，所以并没有得到广泛的应用。而TCP/IP(transfer control protocol/internet protocol,传输控制协议/网际协议)模型因其开放性和易用性在实践中得到了广泛的应用，TCP/IP协议栈也成为互联网的主流协议。 TCP/IP模型是一系列网络协议的总称，这些协议的目的，就是使计算机之间可以进行信息交换。所谓”协议”可以理解成机器之间交谈的语言，每一种协议都有自己的目的。TCP/IP模型一共包括几百种协议，对互联网上交换信息的各个方面都做了规定。 这些协议可以大致分成四个层次，分别为连接层(Link Layer)、网络层(Internet Layer)、传输层(Transport Layer)、应用层(Application Layer)，上一层的协议都以下一层的协议为基础，数据传输的的过程如下图所示： 协议栈向下传递数据，并添加报头和报尾的过程称为封装，数据被封装并通过网络传输后，接收设备将删除添加的信息，并根据报头中的信息决定如何将数据沿协议栈上传给合适的应用程序，这个过程称为解封装。不同设备的对等层之间依靠封装和解封装来实现相互间的通信。 更多阅读TCP/IP 协议栈及 OSI 参考模型详解TCP/IP协议族 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch2-HTTP]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch2-HTTP%2F</url>
    <content type="text"><![CDATA[HTTP 协议基础 HTTP Request 请求行 消息报头 空行 请求正文 HTTP 响应 状态行 消息报头 响应正文 GET 与 POST HTTP不同版本区别 HTTP 高级内容 Cookie 与 Session Cookie 机制 Session 机制 跨站攻击 CSRF（跨站请求伪造） XSS（跨站脚本攻击） Web 缓存 HTTP 代理 参考- [Ads](#ads) HTTP 是一个应用层 Web 协议，通常由 HTTP 客户端发起一个请求，创建一个到服务器指定端口（默认是80端口）的 TCP 连接。HTTP 服务器则在那个端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态，比如”HTTP/1.1 200 OK”，以及返回的内容，如请求的文件、错误消息、或者其它信息。 HTTP 的主要特点如下： 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有 GET、POST 。每种方法规定了客户与服务器联系的类型不同。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。 灵活： HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。 无连接（限于HTTP/1.0）：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态： HTTP 是一个无状态的协议，即服务器不会去维护与客户交互的相关信息，因此它对于事务处理没有记忆能力。举个例子来讲，你通过服务器认证后成功请求了一个资源，紧接着再次请求这一资源时，服务器仍旧会要求你表明身份。 无状态不代表 HTTP 不能保持 TCP 连接，更不能代表 HTTP 使用的是 UDP 协议（无连接）。HTTP 协议中，并没有规定它所依赖的层。HTTP 假定其下层协议提供可靠的传输，因此任何能够提供这种保证的协议都可以被其使用。HTTP 在 TCP/IP 协议族使用 TCP 作为其传输层，其在 TCP/IP 四层网络模型中的位置如下图所示： HTTP 协议基础HTTP Request客户端发送一个 HTTP 请求到服务器的请求消息包括四个部分：请求行（request line）、消息报头（header）、空行、请求正文。 以下是一个 HTTP GET 请求的实例。1234567GET /562f25980001b1b106000338.jpg HTTP/1.1Host img.mukewang.comUser-Agent Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36Accept image/webp,image/*,*/*;q=0.8Referer http://www.imooc.com/Accept-Encoding gzip, deflate, sdchAccept-Language zh-CN,zh;q=0.8 请求行请求行以一个方法符号开头，后面跟着请求的 URI 和协议版本，彼此由空格分隔。 常用的请求方法如下： 方法名称 含义 GET 获取由 Request-URI 标识的任何信息(以实体的形式)，如果 Request-URI 引用某个数据处理过程，则应该以它产生的数据作为在响应中的实体，而不是该过程的源代码文本，除非该过程碰巧输出该文本。 POST 用来请求原始服务器接受请求中封装的实体作为请求行中的Request-URI标识的副属。POST主要用于向数据处理过程提供数据块，如递交表单或者是通过追加操作来扩展数据库。 PUT 以提供的Request-URI存储封装的实体。 DELETE 请求原始服务器删除Request-URI标识的资源。 HEAD 除了服务器不能在响应中返回消息体，HEAD方法与GET相同。用来获取暗示实体的元信息，而不需要传输实体本身。常用于测试超文本链接的有效性、可用性和最近的修改。 简单例子如下： GET /index.html HTTP/1.1 POST http://192.168.2.217:8080/index.jsp HTTP/1.1 消息报头消息报头是紧接着请求行（即第一行）之后的部分，用来说明服务器要使用的附加信息。 报头域由键值对组成。请求头部包含了普通报头、请求报头、实体报头。 普通报头用于所有的请求和响应消息，但并不用于被传输的实体，只用于传输的消息。比如： Cache-Control：用于指定缓存指令，缓存指令是单向的(响应中出现的缓存指令在请求中未必会出现)，且是独立的(一个消息的缓存指令不会影响另一个消息处理的缓存机制)； Date：表示消息产生的日期和时间； Connection：允许发送指定连接的选项，例如指定连接是连续的，或者指定 “close” 选项，通知服务器在响应完成后关闭连接。 请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息。常用的请求报头如下： Host：指定被请求资源的 Internet 主机和端口号，它通常是从 HTTP URL 中提取出来的； User-Agent：允许客户端将它的操作系统、浏览器和其它属性告诉服务器； Accept：指定客户端接受哪些类型的信息，eg:Accept:image/gif，表明客户端希望接受GIF图象格式的资源； Accept-Charset：指定客户端接受的字符集，缺省是任何字符集都可以接受； Accept-Encoding：指定可接受的内容编码，缺省是各种内容编码都可以接受； Authorization：证明客户端有权查看某个资源，当浏览器访问一个页面，如果收到服务器的响应代码为401(未授权)，可以发送一个包含 Authorization 请求报头域的请求，要求服务器对其进行验证。 实体报头定义了关于实体正文（eg：有无实体正文）和请求所标识的资源的元信息。常用的实体报头如下： Allow：GET，POST Content-Encoding：文档的编码（Encode）方法，eg：gzip； Content-Language：内容的语言类型，eg：zh-cn； Content-Length：表示内容长度，eg：80 空行请求头部后面的空行是必须的。 即使第四部分的请求数据为空，也必须有空行。 请求正文通常是 HTML 代码或者 JSON 格式的文本。 HTTP 响应在接收和解释请求消息后，服务器返回一个 HTTP 响应消息。HTTP 响应也是由四个部分组成，分别是：状态行、消息报头、空行、响应正文。 一个 HTTP Response 实例：12345678910HTTP/1.1 200 OKDate: Fri, 22 May 2009 06:07:21 GMTContent-Type: text/html; charset=UTF-8&lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;body&gt; &lt;!--body goes here--&gt; &lt;/body&gt;&lt;/html&gt; 状态行所有 HTTP 响应的第一行都是状态行，依次是当前 HTTP 版本号，3 位数字组成的状态码，以及描述状态的短语，彼此由空格分隔。 HTTP 状态码由三位数字组成，共分五种类别。状态代码的第一个数字代表当前响应的类型： 1xx：指示信息——请求已被服务器接收，继续处理 2xx：成功——请求已成功被服务器接收、理解、接受 3xx：重定向——需要后续操作才能完成这一请求 4xx：客户端错误——请求含有词法错误或者无法被执行 5xx：服务器错误——服务器在处理某个正确请求时发生错误 常见的状态码有如下： 1234567200 OK //客户端请求成功400 Bad Request //客户端请求有语法错误，不能被服务器所理解401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务404 Not Found //请求资源不存在，eg：输入了错误的URL500 Internal Server Error //服务器发生不可预期的错误503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 消息报头响应消息报头包含了普通报头、响应报头、实体报头，普通报头和实体报头与 HTTP Request 报头中的普通报头、实体报头相同。 响应报头允许服务器传递不能放在状态行中的附加响应信息，以及关于服务器的信息和 对 Request-URI 所标识的资源进行下一步访问的信息。常用的响应报头如下： Location：用于重定向接受者到一个新的位置，Location 响应报头域常用在更换域名的时候； Server：包含了服务器用来处理请求的软件信息，与 User-Agent 请求报头域是相对应的； WWW-Authenticate：必须被包含在 401(未授权的)响应消息中。 响应正文消息正文类似 HTTP 请求的消息正文。 GET 与 POSTHTTP 协议定义了很多与服务器交互的方法，最基本的有 4 种，分别是 GET, POST, PUT, DELETE 。一个 URL 用于描述一个网络上的资源，而 HTTP 中的 GET, POST, PUT, DELETE 就对应着对这个资源的查，改，增，删 4 个操作。 GET 一般用于获取/查询资源信息，而POST一般用于更新资源信息，主要区别如下： GET 通过地址栏来传值（但由于敏感信息附在 URL 上，可能有安全问题）；POST 方法通过提交表单来传值，提交的数据放在 HTTP 包的 Body 中。 GET 提交的数据大小有限制（因为浏览器对URL的长度有限制，实际上 HTTP 协议规范没有对 URL 长度进行限制），而 POST 方法提交的数据没有限制。 对于 GET 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；而对于 POST，浏览器先发送 header ，服务器响应 100 continue，浏览器再发送 data ，服务器响应 200 ok（返回数据）。 GET 在浏览器回退时是无害的，而 POST 会再次提交请求。GET 请求参数会被完整保留在浏览器历史记录里，而 POST 中的参数不会被保留。 对参数的数据类型，GET 只接受 ASCII 字符，而 POST 没有限制。 HTTP不同版本区别HTTP/1.0 与 HTTP/1.1 主要区别如下： 带宽优化 HTTP/1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了。HTTP/1.1 中在请求消息中引入了 range 头域，它允许只请求资源的某个部分。 另外一种情况是请求消息中如果包含比较大的实体内容，但不确定服务器是否能够接收该请求（如是否有权限），此时若贸然发出带实体的请求，如果被拒绝也会浪费带宽。HTTP/1.1 加入了一个新的状态码100（Continue），客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码 401（Unauthorized）；如果服务器接收此请求就回送响应码 100，客户端就可以继续发送带实体的完整请求了。 长连接 HTTP 1.0 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。由于大多数网页的流量都比较小，一次 TCP 连接很少能通过 slow-start 区，不利于提高带宽利用率。 HTTP 1.1 支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟。 HTTP 1.1 还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。 缓存 在HTTP/1.0 中，使用Expire头域来判断资源的 fresh 或 stale ，并使用条件请求来判断资源是否仍有效。例如，cache 通过 If-Modified-Since 头域向服务器验证资源的 Last-Modefied 头域是否有更新，源服务器可能返回 304（Not Modified），则表明该对象仍有效；也可能返回 200（OK）替换请求的 Cache 对象。 HTTP/1.1 在 1.0 的基础上加入了一些 cache 的新特性，当缓存对象的 Age 超过 Expire 时变为 stale 对象， cache 不需要直接抛弃 stale 对象，而是与源服务器进行重新激活（revalidation）。 Host 头域 在 HTTP1.0 中认为每台服务器都绑定一个唯一的IP地址，因此请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都支持 Host 头域，请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）。 错误提示 HTTP/1.0 中只定义了16个状态响应码，对错误或警告的提示不够具体。HTTP/1.1 引入了一个 Warning 头域，增加对错误或警告信息的描述。 此外，在HTTP/1.1中新增了24个状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 HTTP 高级内容Cookie 与 SessionCookie 和 Session 都为了用来保存状态信息，都是保存客户端状态的机制，它们都是为了解决 HTTP 无状态的问题。 Cookie 机制简单地说，cookie 就是浏览器储存在用户电脑上的一小段文本文件。cookie 是纯文本格式，不包含任何可执行的代码。一个 Web 页面或服务器告知浏览器按照一定规范来储存这些信息，并在随后的请求中将这些信息发送至服务器，Web 服务器就可以使用这些信息来识别不同的用户。大多数需要登录的网站在用户验证成功之后都会设置一个 cookie，只要这个 cookie 存在并可以，用户就可以自由浏览这个网站的任意页面。 cookie 会被浏览器自动删除，通常存在以下几种原因： 会话 cookie (Session cookie) 在会话结束时（浏览器关闭）会被删除 持久化 cookie（Persistent cookie）在到达失效日期时会被删除 如果浏览器中的 cookie 数量达到限制，那么 cookie 会被删除以为新建的 cookie 创建空间。 大多数浏览器支持最大为 4096 字节的 Cookie。由于这限制了 Cookie 的大小，最好用 Cookie 来存储少量数据，或者存储用户 ID 之类的标识符。用户 ID 随后便可用于标识用户，以及从数据库或其他数据源中读取用户信息。 浏览器还限制站点可以在用户计算机上存储的 Cookie 的数量。大多数浏览器只允许每个站点存储 20 个 Cookie；如果试图存储更多 Cookie，则最旧的 Cookie 便会被丢弃。有些浏览器还会对它们将接受的来自所有站点的 Cookie 总数作出绝对限制，通常为 300 个。 使用 Cookie 的缺点： 不良站点用 Cookie 收集用户隐私信息 Cookie 窃取：黑客以可以通过窃取用户的 Cookie 来模拟用户的请求行为。（跨站请求伪造 CSRF） Session 机制Session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。当程序需要为某个客户端的请求创建一个 session 的时候，服务器首先检查这个客户端的请求里是否已包含了一个 session 标识（session id）： 如果已包含一个session id 则说明以前已经为此客户端创建过 session，服务器就按照 session id 把这个 session 检索出来使用（如果检索不到，可能会新建一个）。 如果客户端请求不包含 session id，则为此客户端创建一个 session 并且生成一个与此session相关联的 session id ， session id 的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个 session id 将被在本次响应中返回给客户端保存。 具体实现方式： Cookie方式：服务器给每个Session分配一个唯一的JSESSIONID，并通过Cookie发送给客户端。当客户端发起新的请求的时候，将在Cookie头中携带这个JSESSIONID，这样服务器能够找到这个客户端对应的Session。 URL回写：服务器在发送给浏览器页面的所有链接中都携带JSESSIONID的参数，这样客户端点击任何一个链接都会把JSESSIONID带回服务器。如果直接在浏览器输入服务端资源的url来请求该资源，那么Session是匹配不到的。 跨站攻击CSRF（跨站请求伪造）CSRF 是通过伪造请求从而冒充用户在站内的正常操作。 从上图可以看出，要完成一次 CSRF 攻击，受害者必须依次完成两个步骤 ： 登录受信任网站 A，并在本地生成 Cookie 。 在不退出 A 的情况下，访问危险网站 B。 防范 CSRF 攻击的三种策略： 验证码 CSRF 攻击的过程，往往是在用户不知情的情况下构造网络请求。所以如果使用验证码，那么每次操作都需要用户进行互动，从而简单有效的防御了 CSRF 攻击。但会严重影响用户体验。 验证 HTTP Referer 字段 HTTP 报文头中的字段 Referer 记录了该 HTTP 请求的来源地址。服务端通过验证 Referer 字段来验证请求是来自同一个站点的请求后才提供服务。但由于该字段可以人为篡改，因此也并不安全。 在请求地址中添加 token 并验证 在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token。token 可以在用户登陆后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对。如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。 在 HTTP 头中自定义属性并验证 这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。（然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。） XSS（跨站脚本攻击）XSS 全称“跨站脚本”，是注入攻击的一种。其特点是不对服务器端造成任何伤害，而是通过一些正常的站内交互途径，例如发布评论，提交含有 JavaScript 的内容文本。这时服务器端如果没有过滤或转义掉这些脚本，作为内容发布到了页面上，其他用户访问这个页面的时候就会运行这些脚本。 理论上，所有可输入的地方没有对输入数据进行处理的话，都会存在XSS漏洞，漏洞的危害取决于攻击代码的威力，攻击代码也不局限于script。防御 XSS 攻击最简单直接的方法，就是过滤用户的输入。 如果不需要用户输入 HTML，可以直接对用户的输入进行 HTML escape 。一小段脚本：&lt;script&gt;window.location.href=”http://www.baidu.com”;&lt;/script&gt;，经过 escape 之后就成了： &amp;lt;script&amp;gt;window.location.href=&amp;quot;http://www.baidu.com&amp;quot;&amp;lt;/script&amp;gt;。它现在会像普通文本一样显示出来，变得无毒无害，不能执行了。 Web 缓存WEB缓存(cache)位于Web服务器和客户端之间，缓存机制会根据请求保存输出内容的副本，例如 html 页面、图片、文件。当下一个请求来到的时候：如果是相同的 URL，缓存直接使用副本响应访问请求，而不是向源服务器再次发送请求。 有缓存的 Get 请求过程如下： 主要分三种情况: 未找到缓存(黑色线)：当没有找到缓存时，说明本地并没有这些数据，这种情况一般发生在我们首次访问网站，或者以前访问过，但是清除过缓存后。浏览器就会先访问服务器，然后把服务器上的内容取回来，内容取回来以后，就要根据情况来决定是否要保留到缓存中了。 缓存未过期(蓝色线)：缓存未过期，指的是本地缓存没有过期，不需要访问服务器了，直接就可以拿本地的缓存作为响应在本地使用了。这样节省了不少网络成本，提高了用户体验过。 缓存已过期(红色线)：当满足过期的条件时，会向服务器发送请求，发送的请求一般都会进行一个验证，目的是虽然缓存文档过期了，但是文档内容不一定会有什么改变，所以服务器返回的也许是一个新的文档，这时候的HTTP状态码是200，或者返回的只是一个最新的时间戳和304状态码。 缓存过期后，有两种方法来判定服务端的文件有没有更新。第一种在上一次服务端告诉客户端约定的有效期的同时，告诉客户端该文件最后修改的时间，当再次试图从服务端下载该文件的时候，check 下该文件有没有更新（对比最后修改时间），如果没有，则读取缓存；第二种方式是在上一次服务端告诉客户端约定有效期的同时，同时告诉客户端该文件的版本号，当服务端文件更新的时候，改变版本号，再次发送请求的时候check一下版本号是否一致就行了，如一致，则可直接读取缓存。 浏览器是依靠请求和响应中的的头信息来控制缓存的，如下： Expires与Cache-Control：服务端用来约定和客户端的有效时间的。Expires规定了缓存失效时间（Date为当前时间），而Cache-Control的max-age规定了缓存有效时间（2552s）。Expires是HTTP1.0的东西，而Cache-Control是HTTP1.1的，规定如果max-age和Expires同时存在，前者优先级高于后者。 Last-Modified/If-Modified-Since：缓存过期后，check服务端文件是否更新的第一种方式。 ETag/If-None-Match：缓存过期时check服务端文件是否更新的第二种方式。实际上ETag并不是文件的版本号，而是一串可以代表该文件唯一的字符串，当客户端发现和服务器约定的直接读取缓存的时间过了，就在请求中发送If-None-Match选项，值即为上次请求后响应头的ETag值，该值在服务端和服务端代表该文件唯一的字符串对比（如果服务端该文件改变了，该值就会变），如果相同，则相应HTTP304，客户端直接读取缓存，如果不相同，HTTP200，下载正确的数据，更新ETag值。 当然并不是所有请求都能被缓存。无法被浏览器缓存的请求： HTTP信息头中包含Cache-Control:no-cache，pragma:no-cache（HTTP1.0），或Cache-Control:max-age=0等告诉浏览器不用缓存的请求 需要根据Cookie，认证信息等决定输入内容的动态请求是不能被缓存的 POST请求无法被缓存 浏览器缓存过程还和用户行为有关。譬如先打开一个主页有个 jquery 的请求（假设访问后会缓存下来）。接着如果直接在地址栏输入 jquery 地址，然后回车，响应HTTP200（from cache），因为有效期还没过直接读取的缓存；如果ctrl+r进行刷新，则会相应HTTP304（Not Modified），虽然还是读取的本地缓存，但是多了一次服务端的请求；而如果是ctrl+shift+r强刷，则会直接从服务器下载新的文件，响应HTTP200。 HTTP 代理Web代理（proxy）服务器是网络的中间实体。代理位于Web客户端和Web服务器之间，扮演“中间人”的角色。HTTP的代理服务器即是Web服务器又是Web客户端。（Fiddler 是以代理web服务器的形式工作的,它使用代理地址:127.0.0.1, 端口:8888. 当Fiddler退出的时候它会自动注销代理，这样就不会影响别的程序。） 代理服务器有许多用处： 跨过网络障碍。翻墙技术：局域网不能上网，只能通过局域网内的一台代理服务器上网。 匿名访问。HTTP代理服务器通过删除HTTP报文中的身份特性（比如客户端的IP地址，或cookie,或URI的会话ID），从而对远端服务器隐藏原始用户的IP地址以及其他细节。同时HTTP代理服务器上也不会记录原始用户访问记录的log。 通过代理缓存，加快上网速度。大部分代理服务器都具有缓存的功能，不断将新取得数据存储到它本地的存储器上，如果浏览器所请求的数据在它本机的存储器上已经存在而且是最新的，那么直接将存储器上的数据传给用户，这样就能显著提高浏览速度。 过滤指定内容。比如儿童过滤器，很多教育机构，会利用代理来阻止学生访问成人内容。 代理服务器和抓包工具（比如Fiddler）都能看到http request中的数据。如果我们发送的request中有敏感数据，比如用户名，密码，信用卡号码，就会被代理服务器看到。所以我们一般都是用HTTPS来加密Http request。 参考深入理解HTTP协议（二）——协议详解篇深入理解HTTP协议（三）——深入了解篇RFC2616 is DeadHTTP协议 (四) 缓存HTTP cookies 详解细说 CookieHTTP/1.1与HTTP/1.0的区别浏览器缓存机制浅析HTTP缓存机制Http状态码查询，各种返回码的详解HTTP协议详解(五) http协议代理Http(二)-消息报头CSRF 攻击的应对之道99%的人都理解错了HTTP中GET与POST的区别 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch3-TCP]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch3-TCP%2F</url>
    <content type="text"><![CDATA[TCP 协议 TCP 报文结构 三次握手建立连接 四次握手断开连接 TCP 状态转换图 TCP 重传机制 TCP 滑动窗口 TCP 拥塞控制 慢启动(Slow Start) 拥塞避免算法(Congestion Avoidance) 拥塞发生算法 更多阅读 Ads TCP 协议因特网的网络层只提供无连接、不可靠的尽力服务。它可以将分组从一个主机通过因特网传送到另一台主机，可能出现比特错、丢失、重复和错序到达的情形。 传输层建立在网络层之上，为进程之间的数据传输提供服务。传输层可以通过不可靠的因特网在两个进程之间建立一条可靠的逻辑链路，提供字节流传输服务。 因特网的传输层有两个协议UDP和TCP： UDP(User Datagram Protocol)只提供无连接的不可靠的服务，应用进程通过&lt;远端IP地址，远端端口号&gt;向远端进程发送数据，应用进程并不要求远端进程进行确认。 TCP(Transmission Control Protocol)为应用程序之间提供面向连接的可靠的字节流服务。TCP为全双工协议，提供流控制机制，即允许接收方控制发送方的发送速度，此外还提供拥塞控制功能。 下图即为两个端点之间TCP通信的简单示意图： 源主机的TCP进程从上层收集应用进程的数据，并在满足一定条件时发送出去，TCP发送的数据称为分段(Segment)。 TCP 报文结构TCP头部数据格式如下： 各个字段的信息说明如下： Source Port(Destination Port)：分别占用16位，表示源端口号和目的端口号；用于区别主机中的不同进程，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接； Sequence Number：用来标识从TCP发送端向TCP接收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节在数据流中的序号，主要用来解决网络报乱序的问题； Acknowledgment Number：发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志为1时该确认序列号的字段才有效，该字段主要用来解决丢包的问题。此外，TCP采用累计确认，即只有当确认字节之前的所有数据都到达之后才能发送确认，这样就可以用一个数字概括接收到的所有数据。 Data offset：用来标识TCP头部的长度，该数字为头部中字(32 bit)的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit，因此TCP最多有60字节的头部。然而，没有任选字段，正常的长度是20字节； Reserved：3个保留位，留作以后使用，全部设置为0； 标志位：TCP头部中共有9个标志位，用于操控TCP的状态，主要有URG，ACK，PSH，RST，SYN，FIN，标志位的意思如下： URG：此标志表示TCP包的紧急指针域有效，用来保证TCP连接不被中断，并且督促中间层设备要尽快处理这些数据； ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中； PSH：表示Push操作，数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队； RST：表示连接复位请求，用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包； SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1； FIN：表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了。 Window Size：窗口大小，也就是有名的滑动窗口，用来进行流量控制。指定从被确认的字节算起可以发送多少个字节，窗口大小字段为0是合法的，说明已经接收到了 确认号－1 个字节，但是接收端没有来得及取走数据。 三次握手建立连接TCP协议提供可靠的连接服务，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，连接是通过三次握手进行初始化的，三次握手的过程如下： 前两次握手，客户端进入连接状态，后两次握手，服务器进入连接状态。所以，三次握手之后，一个全双工的连接就建立起来了，之后，客户端和服务器端就可以开始传送数据。 第一次握手：客户端发送连接请求报文段，将SYN位设为1，SeqNum为随机数A； 第二次握手：服务器返回ACK，确认收到客户端发来的SYN，然后设置AckNum为A+1；此外，服务器发送自己的连接请求报文段，即发送SYN和随机数B作为SeqNum； 第三次握手：客户端返回ACK，确认收到服务器发来的SYN，然后设置AckNum=B+1。 为什么需要三次握手建立连接？ 简单来说，为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 考虑下面一种情况：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。server收到此失效的连接请求报文段后，误认为是client发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。 假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。 采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 四次握手断开连接客户端和服务器数据传送完毕后，需要断开TCP连接，断开连接的时候需要进行四次握手。 四次握手的过程如下： 第一次握手：发起端发送FIN和SeqNum=A，进入FIN_WAIT_1状态，用来关闭发起端到接收端的数据传送，也就是告诉接收端：不会再给你发新数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，发起端依然会重发这些数据)，但此时发起段还可以接受数据； 第二次握手：接收端收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（AckNum=A+1），此时接收端仍然可以给发起段发送数据（同意关闭连接请求，但是我还有数据需要传送，稍等…）； 第三次握手：接收端向发起端发送FIN，用来关闭到发起端的数据传送，也就是告诉发起端：我的数据也发送完了，不会再给你发数据了。此时接收端进入CLOSE_WAIT状态； 第四次握手：发起端发送ACK报文段，然后进入TIME_WAIT状态，接收端收到ACK报文段以后，就关闭连接。发起端等待2MSL后依然没有收到回复，则证明Server端已正常关闭，此时也可以关闭连接了。 如果要正确的理解四次分手的原理，还需要了解四次分手过程中的状态变化。 FIN_WAIT_1: FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态。（主动方） FIN_WAIT_2：FIN_WAIT_2状态下的SOCKET，表示半连接，也即主动方要求断开连接，得到了被动方的确认，但被动方还有数据要发送，因此主动方还得继续接收。（主动方） TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方） CLOSE_WAIT：在CLOSE_WAIT状态下，被动方还有数据需要传送。（被动方） LAST_ACK: 被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方） CLOSED: 表示连接中断。 为什么要四次握手断开连接？ TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会中断这次TCP连接。 TIME_WAIT 状态存在的理由： 可靠地实现TCP全双工连接的终止。 在进行关闭连接四次握手协议时，最后的ACK是由主动关闭端发出的，如果这个最终的ACK丢失，被动关闭方将重发最终的FIN，主动关闭端只有在该连接未关闭的情况下才可以重新发送最终的那个ACK。否则主动关闭端将会响应一个RST，被动端会将此响应标记为错误，从而不能进行正常的关闭。 允许老的重复分节在网络中消逝。 假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：(local_ip, local_port, remote_ip,remote_port)，因某些原因，先关闭，接着很快以相同的四元组建立一条新连接。TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间先释放再建立的过程对其来说是“感知”不到的。这样就可能发生这样的情况：前一条TCP连接由local peer发送的数据到达remote peer后，会被该remot peer的TCP传输层当做当前TCP连接的正常数据接收并向上传递至应用层（而事实上，在我们假设的场景下，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。 local peer主动调用close后，此时的TCP连接进入TIME_WAIT状态，处于该状态下的TCP连接不能立即以同样的四元组建立新连接，即发起active close的那方占用的local port在TIME_WAIT期间不能再被重新分配。由于TIME_WAIT状态持续时间为2MSL，这样保证了旧TCP连接双工链路中的旧数据包均因过期（超过MSL）而消失，此后，就可以用相同的四元组建立一条新连接而不会发生前后两次连接数据错乱的情况。 参考 再叙TIME_WAIT TCP 状态转换图 TCP 重传机制TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。 注意，接收端给发送端的Ack确认只会确认最后一个连续的包，比如，发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？我们要知道，SeqNum和Ack是以字节数为单位，所以ack的时候，不能跳着确认，只能确认最大的连续收到的包，不然，发送端就以为之前的都收到了。 超时重传机制 每次发送数据包时，发送的数据报都有seq号，接收端收到数据后，会回复ack进行确认，表示某一seq号数据已经收到。发送方在发送了某个seq包后，等待一段时间，如果没有收到对应的ack回复，就会认为报文丢失，会重传这个数据包。 针对上面的情况，接收端不回ack，死等3，当发送方发现收不到3的ack超时后，会重传3。一旦接收方收到3后，会ack 回 4——意味着3和4都收到了。但是，这种方式会有比较严重的问题，那就是因为要死等3，所以会导致4和5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到Ack，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4和5的重传。 快速重传机制 接收数据一方发现有数据包丢掉了。就会发送ack报文告诉发送端重传丢失的报文。如果发送端连续收到标号相同的ack包，则会触发客户端的快速重传。比较超时重传和快速重传，可以发现超时重传是发送端在傻等超时，然后触发重传；而快速重传则是接收端主动告诉发送端数据没收到，然后触发发送端重传。 比如：如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。 TCP 滑动窗口TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。滑动窗可以是提高TCP传输效率的一种机制。要注意滑动窗口只关注发送端和接收端自身的状况，而没有考虑整个网络的通信情况。 为了说明滑动窗口，我们需要先看一下TCP缓冲区的一些数据结构： 上图中，我们可以看到： 接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区。 发送端的LastByteAcked指向了被接收端Ack过的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有收到成功确认的Ack，LastByteWritten指向的是上层应用正在写的地方。 于是： 接收端在给发送端回ACK中会汇报自己的AdvertisedWindow = MaxRcvBuffer – LastByteRcvd – 1; 而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。 下面我们来看一下发送方的滑动窗口示意图： 上图中分成了四个部分，分别是：（其中那个黑模型就是滑动窗口） 已收到ack确认的数据。 发还没收到ack的。 在窗口中还没有发出的（接收方还有空间）。 窗口以外的数据（接收方没空间） 下面是个滑动后的示意图（收到36的ack，并发出了46-51的字节）： 下面我们来看一个接收端控制发送端的图示： 上图可以看到一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。如果Window变成0了，发送端就不发数据了，可以想像成“Window Closed”。（有两种意外情形，第一紧急数据仍可以发送，比如用户杀掉远程机器上运行的某一个进程。第二，发送段可以发送一个用来进行窗口探测的段，下面详细介绍） Window size 变为0之后，为了防止服务器发来的窗口更新数据包丢失后发生死锁。TCP使用了窗口探测（Zero Window Probe）技术，缩写为ZWP，也就是说发送端在窗口变成0后会发送一个1字节的段给接收方，以便强制接收端重新宣告下一个期望的字节和窗口大小。一般会尝试发送3次，如果3次过后还是0的话，有的TCP实现就会发送RST把连接断开。 此外，发送端不一定接到应用程序传递来的数据就马上把数据传送出去，同样，接收端也不一定必须尽可能快的发送确认段。特别是遇到下面这两种极端情况： 发送端每次向 TCP 连接传递一个字节； 接收端每次从 TCP 流中读取一个字节； 考虑下面的场景： 远程终端连接（SSH）：使用 Nagle 算法避免发送端发送多个小数据包，减轻发送端给网络的负载。（Nagle 算法：数据每次以很少量方式进入到发送端时，发送端只发送第一次到达的数据字节，然后将后面到达的缓存起来，直到发送出去的那个数据包被确认，然后将所有缓冲的字节放在一个 TCP 段中发送出去。并且继续开始缓冲，直到下一个端被确认。）不适用的场景：互动游戏，需要快速的短数据包流。 低能窗口综合症：接收端的交互式应用每次仅能读取一个字节数据。使用延迟确认的优化方法可以避免接收端发送只有一个字节的窗口更新端。Clark解决方案：禁止接收端发送只有1个字节的窗口更新端，强制必须等一段时间，直到有了一定数量的可用空间之后再通知给对方。 TCP 拥塞控制TCP通过滑动窗口来做流量控制，但是这还不够，因为滑动窗口仅依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流量控制并不够，因为流量控制只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。 考虑一下这样的场景：某一时刻网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。 所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。 拥塞控制主要是四个算法（相应的论文）：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复。 这四个算法不是一天都搞出来的，它们的发展经历了很多时间，到今天都还在优化中。 1988年，TCP-Tahoe 提出了1）慢启动，2）拥塞避免，3）拥塞发生时的快速重传； 1990年，TCP Reno 在Tahoe的基础上增加了 4）快速恢复 慢启动(Slow Start)慢启动的意思是，刚刚加入网络的连接，一点一点地提速。慢启动的算法如下(cwnd全称Congestion Window)： 连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。 每当收到一个ACK，cwnd++; 这样每当过了一个RTT，cwnd = cwnd*2。 还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法” 所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT（Round Trip Time，也就是一个数据包从发出去到回来的时间）也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。 拥塞避免算法(Congestion Avoidance)ssthresh（slow start threshold）是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下： 收到一个ACK时，cwnd = cwnd + 1/cwnd，这样当每过一个RTT时，cwnd = cwnd + 1 这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。 拥塞发生算法前面我们说过，当丢包的时候，会有两种情况： 1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。 ssthresh = cwnd /2 cwnd 重置为 1 进入慢启动过程 2）快速重传，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。 TCP Tahoe的实现和RTO超时一样。 TCP Reno(RFC5681, RFC682)的实现是： cwnd = cwnd /2 ssthresh = cwnd 按照拥塞避免算法继续线性增长 更多阅读图解TCP-IP协议简析TCP的三次握手与四次分手TCP 的那些事儿（上）TCP 的那些事儿（下） TCP keepalive overviewDetection of Half-Open (Dropped) Connections 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch4-IP]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch4-IP%2F</url>
    <content type="text"><![CDATA[IP 地址 IP 报文 路由协议 Ads 整个的因特网就是一个单一的、抽象的网络。IP地址就是给因特网上的每一个主机（或路由器）的每一个接口分配一个在全世界范围内唯一的32位的标识符。 IP 地址每个 32 位的 IP 地址由高位的可变长网络和低位的主机两部分组成。同一网络的所有主机，其地址的网络值是相同的。这意味着一个网络对应一块连续的 IP 地址空间，这块地址空间就称为地址的前缀。如果前缀包含 2^8 个主机地址，那么就留下了 24 位用于网络部分，可以写成 *.*.*.*/24。子网掩码用来与一个 IP 地址进行 AND 操作，提取出该 IP 地址的网络部分。 子网划分：在内部将一个网络块分成几个部分供多个内部网络使用，但对外部世界仍像单个网络一样。路由聚合：把多个小前缀的地址块合并成一个大前缀的地址块。（解决路由表过大的问题）。 1953年，IP 地址被分为 5 个类别： 注意全零（0.0.0.0）地址对应于当前主机。全1的IP地址（255.255.255.255）是当前子网的广播地址。 还有三个范围的 IP地址被声明为私有化，任何网络可以在内部随意地使用这些地址，但是不允许包含这些地址的数据包出现在 Internet 上。 1 个A类地址：10.0.0.0~10.255.255.255/8 (2^24 个地址) 16 个B类地址：172.16.0.0~172.31.255.255/16 (16 * 2^16 个地址) 256个C类地址：192.168.0.0~192.168.255.255/24 (256*2^8 个地址) 保留IP地址不会在internet网上出现，用于企业网络，A企业可以用,B企业也可以使用！ IP 报文 报头各字段： 版本号（Version）：标识目前采用的IP协议的版本号。一般的值为0100（IPv4），IPv6的值（0110） 头部长度（Header Length）：这个字段的作用是为了描述IP包头的长度，因为在IP包中有变长的可选部分。 服务类型（Type of Service）：这个子段可以拆分成两个部分：Precedence和TOS。TOS目前不太使用。而Precedence则用于QOS应用。（TOS字段的详细描述RFC 1340 1349） 总长（Total Length）：长度16比特。IP包最大长度65535字节。 标识符（Identifier）：该字段和Flags和Fragment Offest字段联合使用，对大的上层数据包进行分段（fragment）操作。 标记（Flags）：该字段第一位不使用。第二位是DF位，DF位设为1时表明路由器不能对该上层数据包分段。如果一个上层数据包无法在不分段的情况下进行转发，则路由器会丢弃该上层数据包并返回一个错误信息。第三位是MF位，当路由器对一个上层数据包分段，则路由器会在除了最后一个分段的IP包的包头中将MF位设为1。 分段序号（Fragment Offset）：该字段对包含分段的上层数据包的IP包赋予序号。由于IP包在网络上传送的时候不一定能按顺序到达，这个字段保证了目标路由器在接受到IP包之后能够还原分段的上层数据包。到某个包含分段的上层数据包的IP包在传送是丢失，则整个一系列包含分段的上层数据包的IP包都会被要求重传。 生存时间（TTL）：TTL长度8 bit，最大值是255，TTL的一个推荐值是64。虽然从字面上翻译，TTL是IP数据包在计算机网络中的存在的最长时间。但实际上TTL是IP数据包在网络中可以转发的最大跳数。TTL字段由IP数据包的发送者设置，在IP数据包从源到目的的整个转发路径上，每经过一个路由器，把该TTL的值减1，然后再将IP包转发出去。如果在IP包到达目的IP之前，TTL减少为0，路由器将会丢弃收到的TTL=0的IP包并向发送者发送 ICMP time exceeded消息。TTL的主要作用是避免IP包在网络中的无限循环和收发，节省了网络带宽，并能使IP包的发送者能收到告警消息。这个字段可以防止由于故障而导致IP包在网络中不停被转发。 起源和目标地址（Source and Destination Addresses）：这两个地段都是32比特。标识了这个IP包的起源和目标地址。 路由协议在互联网中，网络结构是相当复杂的（存在复杂的局域网或广域网），若想要将数据包从一个主机成功发送到目的主机，则需要合理的路由将数据转发最终发送到目的主机。而要使路由能够正确的工作，需要路由控制模块和相关的路由协议来支持路由的工作。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch5-Web]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch5-Web%2F</url>
    <content type="text"><![CDATA[为什么需要高并发？ 慢客户端 Web 服务器并发处理 nginx 高并发解决方案 HTML静态化 图片服务器分离 数据库集群、库表散列 缓存 镜像 负载均衡 CDN加速技术 更多阅读- [Ads](#ads) 简单来说，一台服务器在单位时间里能处理的请求越多，服务器的能力越高，也就是服务器并发处理能力越强。 为什么需要高并发？相比十年前，互联网已得到了广泛的普及与应用。现在我们甚至难以想象离开互联网的世界。 从最初基于 NCSA 进化到基于Apache web 提供的可进行简单文本操作的html，再到目前的全世界20亿用户永久在线媒介。互联网一直在高速进化，即时信息与娱乐服务变得更加轻盈精巧，在线业务的安全可靠性也发生了显著变化。因此，当下的网站服务比之前变得更复杂，web引擎需要在工程上更具健壮性和可扩展性。 并发一直是web体系结构最大的挑战之一。自web services应用以来，并发能力持续增长。流行站点服务10w甚至100w的访问量非常常见。 十年前，影响并发的主要因素是客户端缓慢－－用户使用ADSL或者拨号连接网络。现在，并发增长主要是由移动端和新的应用架构引起，这些应用采用长链接以便能让用户及时更新消息，微博和朋友圈等等。浏览器行为的变化是另一个导致并发增长的原因，现代浏览器访问网站时一般会打开4～6个并发以提高页面加载速度。 慢客户端设想一个基于Apache的简单网站服务器，该服务器生成相对简短的100K的返回体–由文本或图片组成的简单页面。服务器耗费了不到一秒的时间生成一个页面，但是在80kbps(10KB/s)的网络环境下却耗费了10秒传输到客户端。网站服务器相对较快地推送10KB的内容，却需要在释放连接前耗费10秒钟将内容发送到客户端。 现在设想有1000个客户端同时连接上，请求类似的内容。假设仅分配1M内存给每个客户端，那么就是说，1000个客户端，100KB的请求内容，服务端却要消耗1G的内存。 事实上，一个典型的基于Apache的网站服务器需要为每个client分配超过1M的内存，而移动端的有效速度往往也在几十kbps。针对发送内容到客户端低效这个问题，虽然提高操作系统内核的socket缓冲区的大小，能一定程度上解决缓解问题，但是并不是一个通用的解决方案，并且有无法预期的副作用。 Web 服务器并发处理单进程：此种架构方式中，web服务器一次处理一个请求，结束后读取并处理下一个请求。在某请求处理过程中，其它所有的请求将被忽略，因此，在并发请求较多的场景中将会出现严重的性能问题。 多进程/多线程：此种架构方式中，web服务器生成多个进程或线程并行处理多个用户请求，进程或线程可以按需或事先生成。有的web服务器应用程序为每个用户请求生成一个单独的进程或线程来进行响应，不过，一旦并发请求数量达到成千上万时，多个同时运行的进程或线程将会消耗大量的系统资源。 I/O多路复用：为了能够支持更多的并发用户请求，越来越多的web服务器正在采用多种复用的架构：即同步监控所有的连接请求的活动状态，当一个连接的状态发生改变时(如数据准备完毕或发生某错误)，将为其执行一系列特定操作；在操作完成后，此连接将重新变回暂时的稳定态并返回至打开的连接列表中，直到下一次的状态改变。由于其多路复用的特性，进程或线程不会被空闲的连接所占用，因而可以提供高效的工作模式。 基于事件的模型：一个进程处理多个请求，并且通过epoll机制来通知用户请求完成。 nginxnginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在nginx中，连接请求由为数不多的几个仅包含一个线程的进程worker以高效的回环(run-loop)机制进行处理，而每个worker可以并行处理数千个的并发连接及请求。 Nginx会按需同时运行多个进程：一个主进程(master)和几个工作进程(worker)，配置了缓存时还会有缓存加载器进程(cache loader)和缓存管理器进程(cache manager)等。所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。主进程以root用户身份运行，而worker、cache loader和cache manager均应以非特权用户身份运行。 主进程主要完成如下工作： 读取并验正配置信息； 创建、绑定及关闭套接字； 启动、终止及维护worker进程的个数； 无须中止服务而重新配置工作特性； 控制非中断式程序升级，启用新的二进制程序并在需要时回滚至老版本； 重新打开日志文件； 编译嵌入式perl脚本； worker进程主要完成的任务包括： 接收、传入并处理来自客户端的连接； 提供反向代理及过滤功能； nginx任何能完成的其它任务； 如果负载以CPU密集型应用为主，如SSL或压缩应用，则worker数应与CPU数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍 高并发解决方案随着互联网业务的不断丰富，网站相关的技术经过这些年的发展，已经细分到很细的方方面面，尤其对于大型网站来说，所采用的技术更是涉及面非常广，从硬件到软件、编程语言、数据库、WebServer、防火墙等各个领域都有了很高的要求，已经不是原来简单的html静态网站所能比拟的。 大型网站，比如门户网站，在面对大量用户访问、高并发请求方面，基本的解决方案集中在这样几个环节：使用高性能的服务器、高性能的数据库、高效率的编程语言、还有高性能的Web容器。 HTML静态化效率最高、消耗最小的就是纯静态化的html页面，所以我们尽可能使我们的网站上的页面采用静态页面来实现，这个最简单的方法其实也是最有效的方法。但是对于大量内容并且频繁更新的网站，我们无法全部手动去挨个实现，于是出现了我们常见的信息发布系统CMS，像我们常访问的各个门户站点的新闻频道，甚至他们的其他频道，都是通过信息发布系统来管理和实现的，信息发布系统可以实现最简单的信息录入自动生成静态页面，还能具备频道管理、权限管理、自动抓取等功能，对于一个大型网站来说，拥有一套高效、可管理的CMS是必不可少的。 除了门户和信息发布类型的网站，对于交互性要求很高的社区类型网站来说，尽可能的静态化也是提高性能的必要手段，将社区内的帖子、文章进行实时的静态化、有更新的时候再重新静态化也是大量使用的策略，像Mop的大杂烩就是使用了这样的策略，网易社区等也是如此。 同时，html静态化也是某些缓存策略使用的手段，对于系统中频繁使用数据库查询但是内容更新很小的应用，可以考虑使用html静态化来实现。比如论坛中论坛的公用设置信息，这些信息目前的主流论坛都可以进行后台管理并且存储在数据库中，这些信息其实大量被前台程序调用，但是更新频率很小，可以考虑将这部分内容进行后台更新的时候进行静态化，这样避免了大量的数据库访问请求。 图片服务器分离对于Web服务器来说，不管是Apache、IIS还是其他容器，图片是最消耗资源的，于是我们有必要将图片与页面进行分离，这是基本上大型网站都会采用的策略，他们都有独立的、甚至很多台的图片服务器。这样的架构可以降低提供页面访问请求的服务器系统压力，并且可以保证系统不会因为图片问题而崩溃。 在应用服务器和图片服务器上，可以进行不同的配置优化，比如apache在配置ContentType的时候可以尽量少支持、尽可能少的LoadModule，保证更高的系统消耗和执行效率。 数据库集群、库表散列大型网站都有复杂的应用，这些应用必须使用数据库，那么在面对大量访问的时候，数据库的瓶颈很快就能显现出来，这时一台数据库将很快无法满足应用，于是我们需要使用数据库集群或者库表散列。 在数据库集群方面，很多数据库都有自己的解决方案，Oracle、Sybase等都有很好的方案，常用的MySQL提供的Master/Slave也是类似的方案，您使用了什么样的DB，就参考相应的解决方案来实施即可。 上面提到的数据库集群由于在架构、成本、扩张性方面都会受到所采用DB类型的限制，于是我们需要从应用程序的角度来考虑改善系统架构，库表散列是常用并且最有效的解决方案。 我们在应用程序中安装业务和应用或者功能模块将数据库进行分离，不同的模块对应不同的数据库或者表，再按照一定的策略对某个页面或者功能进行更小的数据库散列，比如用户表，按照用户ID进行表散列，这样就能够低成本的提升系统的性能并且有很好的扩展性。 sohu的论坛就是采用了这样的架构，将论坛的用户、设置、帖子等信息进行数据库分离，然后对帖子、用户按照板块和ID进行散列数据库和表，最终可以在配置文件中进行简单的配置便能让系统随时增加一台低成本的数据库进来补充系统性能。 缓存缓存一词搞技术的都接触过，很多地方用到缓存。网站架构和网站开发中的缓存也是非常重要。 架构方面的缓存，对Apache比较熟悉的人都能知道Apache提供了自己的缓存模块，也可以使用外加的Squid模块进行缓存，这两种方式均可以有效的提高Apache的访问响应能力。 网站程序开发方面的缓存，Linux上提供的Memory Cache是常用的缓存接口，可以在web开发中使用，比如用java开发的时候就可以调用MemoryCache对一些数据进行缓存和通讯共享，一些大型社区使用了这样的架构。另外，在使用web语言开发的时候，各种语言基本都有自己的缓存模块和方法，PHP有Pear的Cache模块，Java就更多了，.net不是很熟悉，相信也肯定有。 镜像镜像是大型网站常采用的提高性能和数据安全性的方式，镜像的技术可以解决不同网络接入商和地域带来的用户访问速度差异，比如ChinaNet和EduNet之间的差异就促使了很多网站在教育网内搭建镜像站点，数据进行定时更新或者实时更新。在镜像的细节技术方面，这里不阐述太深，有很多专业的现成的解决架构和产品可选。也有廉价的通过软件实现的思路，比如Linux上的rsync等工具。 负载均衡负载均衡将是大型网站解决高负荷访问和大量并发请求采用的高端解决办法。负载均衡技术发展了多年，有很多专业的服务提供商和产品可以选择，我个人接触过一些解决方法，其中有两个架构可以给大家做参考。 硬件四层交换：第四层交换使用第三层和第四层信息包的报头信息，根据应用区间识别业务流，将整个区间段的业务流分配到合适的应用服务器进行处理。 第四层交换功能就像是虚IP，指向物理服务器。它传输的业务服从的协议多种多样，有HTTP、FTP、NFS、Telnet或其他协议。这些业务在物理服务器基础上，需要复杂的载量平衡算法。在IP世界，业务类型由终端TCP或UDP端口地址来决定，在第四层交换中的应用区间则由源端和终端IP地址、TCP和UDP端口共同决定。 在硬件四层交换产品领域，有一些知名的产品可以选择，比如Alteon、F5等，这些产品很昂贵，但是物有所值，能够提供非常优秀的性能和很灵活的管理能力。“Yahoo中国”当初接近2000台服务器，只使用了三、四台Alteon就搞定了。 软件四层交换：大家知道了硬件四层交换机的原理后，基于OSI模型来实现的软件四层交换也就应运而生，这样的解决方案实现的原理一致，不过性能稍差。但是满足一定量的压力还是游刃有余的，有人说软件实现方式其实更灵活，处理能力完全看你配置的熟悉能力。 软件四层交换我们可以使用Linux上常用的LVS来解决，LVS就是Linux Virtual Server，他提供了基于心跳线heartbeat的实时灾难应对解决方案，提高系统的强壮性，同时可供了灵活的虚拟VIP配置和管理功能，可以同时满足多种应用需求，这对于分布式的系统来说必不可少。 一个典型的使用负载均衡的策略就是，在软件或者硬件四层交换的基础上搭建squid集群，这种思路在很多大型网站包括搜索引擎上被采用，这样的架构低成本、高性能还有很强的扩张性，随时往架构里面增减节点都非常容易。 对于大型网站来说，前面提到的每个方法可能都会被同时使用到，这里介绍得比较浅显，具体实现过程中很多细节还需要大家慢慢熟悉和体会。有时一个很小的squid参数或者apache参数设置，对于系统性能的影响就会很大。 CDN加速技术CDN的全称是内容分发网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。 CDN有别于镜像，因为它比镜像更智能，或者可以做这样一个比喻：CDN=更智能的镜像+缓存+流量导流。因而，CDN可以明显提高Internet网络中信息流动的效率。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等问题，提高用户访问网站的响应速度。 CDN的实现分为三类：镜像、高速缓存、专线。 镜像站点（Mirror Site），是最常见的，它让内容直接发布，适用于静态和准动态的数据同步。但是购买和维护新服务器的费用较高，还必须在各个地区设置镜像服务器，配备专业技术人员进行管理与维护。对于大型网站来说，更新所用的带宽成本也大大提高了。 高速缓存，成本较低，适用于静态内容。Internet的统计表明，超过80%的用户经常访问的是20%的网站的内容，在这个规律下，缓存服务器可以处理大部分客户的静态请求，而原始的服务器只需处理约20%左右的非缓存请求和动态请求，于是大大加快了客户请求的响应时间，并降低了原始服务器的负载。CDN服务一般会在全国范围内的关键节点上放置缓存服务器。 专线，让用户直接访问数据源，可以实现数据的动态同步。 CDN的实例：举个例子来说，当某用户访问网站时，网站会利用全球负载均衡技术，将用户的访问指向到距离用户最近的正常工作的缓存服务器上，直接响应用户的请求。 当用户访问已经使用了CDN服务的网站时，其解析过程与传统解析方式的最大区别就在于网站的授权域名服务器不是以传统的轮询方式来响应本地DNS的解析请求，而是充分考虑用户发起请求的地点和当时网络的情况，来决定把用户的请求定向到离用户最近同时负载相对较轻的节点缓存服务器上。 通过用户定位算法和服务器健康检测算法综合后的数据，可以将用户的请求就近定向到分布在网络“边缘”的缓存服务器上，保证用户的访问能得到更及时可靠的响应。 由于大量的用户访问都由分布在网络边缘的CDN节点缓存服务器直接响应了，这就不仅提高了用户的访问质量，同时有效地降低了源服务器的负载压力。 更多阅读如何提高服务器并发处理能力Nginx介绍(为什么高并发很重要)Nginx介绍(Nginx架构综述)Web服务器处理并发连接请求的工作模型Web网站高并发量的解决方案 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch6-Socket]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch6-Socket%2F</url>
    <content type="text"><![CDATA[Socket 属性 Socket 接口函数 服务器端函数 客户端函数 通用函数 TCP 通信 UDP Socket函数 更多阅读- [Ads](#ads) Socket 起源于 Unix，而Unix基本哲学之一就是一切皆文件，都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”模式来操作。Socket就是该模式的一个实现，网络的Socket数据传输是一种特殊的I/O，Socket也是一种文件描述符。 Socket也具有一个类似于打开文件的函数调用：Socket()，该函数返回一个整型的Socket描述符，随后的连接建立、数据传输等操作都是通过该Socket实现的。使用TCP/IP协议的应用程序通常采用应用编程接口：UNIX BSD的套接字（socket）和UNIX System V的TLI（已经被淘汰），来实现网络进程之间的通信。 Socket 属性套接字的特性由3个属性确定，它们分别是：域、类型和协议。 套接字的域：它指定套接字通信中使用的网络介质，最常见的套接字域是AF_INET，它指的是Internet网络。当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。另一个域AF_UNIX表示UNIX文件系统，它就是文件输入/输出，而它的地址就是文件名。 套接字类型：因特网提供了两种通信机制：流（stream）和数据报（datagram），因而套接字的类型也就分为流套接字和数据报套接字。这里主要讲流套接字。 流套接字由类型SOCK_STREAM指定，它们是在AF_INET域中通过TCP/IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。 与流套接字相对的是由类型SOCK_DGRAM指定的数据报套接字，它不需要建立连接和维持一个连接，它们在AF_INET中通常是通过UDP/IP协议实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输,它可能会丢失、复制或错乱到达，UDP不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。 套接字协议：只要底层的传输机制允许不止一个协议来提供要求的套接字类型，我们就可以为套接字选择一个特定的协议。通常只需要使用默认值。 Socket 接口函数既然socket是“open—write/read—close”模式的一种实现，那么socket就提供了这些操作对应的函数接口。下面以TCP为例，介绍几个基本的socket接口函数。 socket函数：使用给定的协议族、套接字类型、协议编号（默认为0）来创建套接字。 socket函数对应于普通文件的打开操作。普通文件的打开操作返回一个文件描述字，而socket()用于创建一个socket描述符（socket descriptor），它唯一标识一个socket。这个socket描述字跟文件描述字一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。 int socket(int domain, int type, int protocol); socket函数的三个参数分别为： domain：协议域。常用的协议族有AF_INET、AF_INET6等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合。 type：socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等。 protocol：指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP等，它们分别对应TCP传输协议、UDP传输协议。 注意：type和protocol不可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。 我们调用socket创建一个socket后，返回的socket描述符存在于协议族空间中，但没有一个具体的地址。如果想要给它赋值一个地址，就必须调用bind()函数，否则就当调用connect()、listen()时系统会自动随机分配一个端口。 服务器端函数bind函数：将套接字绑定到地址。 int bind(int sockfd, struct sockaddr * my_addr, int addrlen); 三个参数分别为： sockfd : 即socket描述字，通过socket()函数创建，唯一标识一个socket。 my_addr : 结构体指针变量，指向要绑定给sockfd的协议地址。这个地址结构根据地址创建socket时的地址协议族的不同而不同。 addrlen : 对应的是地址的长度。 通常服务器在启动的时候都会绑定一个地址（如ip地址+端口号），用于提供服务，客户就可以通过它来接连服务器；而客户端就不用指定，系统自动分配一个端口号和自身的ip地址组合。这就是为什么通常服务器端在listen之前会调用bind()，而客户端就不会调用，而是在connect()时由系统随机生成一个。 listen函数：使服务器的这个端口和IP处于监听状态，等待网络中某一客户机的连接请求。如果客户端有连接请求，端口就会接受这个连接。 int listen(int sockfd, int backlog); 两个参数分别为： sockfd: socket描述字。 backlog: 指定同时能处理的最大连接要求，通常为10或者5。最大值可设至128。 accept函数：接受远程计算机的连接请求，建立起与客户机之间的通信连接。服务器处于监听状态时，如果某时刻获得客户机的连接请求，此时并不是立即处理这个请求，而是将这个请求放在等待队列中，当系统空闲时再处理客户机的连接请求。 int accept(int sockfd, struct sockaddr * addr,int * addrlen); 三个参数分别为： sockfd : socket描述字。 addr: 为结构体指针变量，和bind的结构体是同种类型的，系统会把远程主机的信息（远程主机的地址和端口号信息）保存到这个指针所指的结构体中。 addrlen : 表示结构体的长度 accept的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为监听socket描述字；而accept函数返回的是已连接的socket描述字。一个服务器通常通常仅仅只创建一个监听socket描述字，它在该服务器的生命周期内一直存在。内核为每个由服务器进程接受的客户连接创建了一个已连接socket描述字，当服务器完成了对某个客户的服务，相应的已连接socket描述字就被关闭。 客户端函数connect函数用来请求连接远程服务器. int connect (int sockfd,struct sockaddr * serv_addr,int addrlen); 三个参数分别为： sockfd : socket描述字，前面socket的返回值； serv_addr : 存储着远程服务器的IP与端口号信息； addrlen : 表示结构体变量的长度。 通用函数recv函数：负责从缓冲区中读取内容。当读成功时，read返回实际所读的字节数，如果返回的值是0表示已经读到文件的结束了，小于0表示出现了错误。 int recv(int sockfd,void *buf,int len,unsigned int flags); 四个参数分别为： sockfd : 为前面accept的返回值.也就是新的套接字。 buf : 表示缓冲区 len : 表示缓冲区的长度 flags : 通常为0 send函数：将buf中的n bytes字节内容写入socket描述字。成功时返回写的字节数。失败时返回-1，并设置errno变量。 int send(int sockfd,const void * msg,int len,unsigned int flags); sockfd : 为前面socket的返回值. msg : 一般为常量字符串 len : 表示长度 flags : 通常为0 close函数：关闭套接字。若顺利关闭则返回0，发生错误时返回-1。 int close(int sockfd); TCP 通信TCP中 Socket 通信的基本步骤如下： 一个简单的 C/S 程序如下（客户端发出的数据, 服务器会回显到客户端的终端上。只是一个简单的模型, 没考虑错误处理等问题。） 服务器端如下： import socket # socket模块 BUF_SIZE = 1024 # 设置缓冲区大小 server_addr = (&apos;127.0.0.1&apos;, 8888) # IP和端口构成表示地址 server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 生成一个新的socket对象 server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # 设置地址复用 server.bind(server_addr) # 绑定地址 server.listen(5) # 监听, 最大监听数为5 while True: client, client_addr = server.accept() # 接收TCP连接, 并返回新的套接字和地址 print &apos;Connected by&apos;, client_addr while True: data = client.recv(BUF_SIZE) # 从客户端接收数据 print data client.sendall(data) # 发送数据到客户端 server.close() 客户端如下： import socket BUF_SIZE = 1024 server_addr = (&apos;127.0.0.1&apos;, 8888) client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect(server_addr) while True: data = raw_input(&quot;Please input some string &gt; &quot;) client.sendall(data) data = client.recv(BUF_SIZE) print data client.close() 不过真实的网络编程环境中，一定要使用大量的错误处理，可以尽量的发现错误，也能够使代码显得更加严谨。 三次握手SYN_SENT connect() 阻塞 — accept() 阻塞 SYS_RCVESTABLISHED connect() 返回 — accept() 返回 ESTABLISHED 四次挥手FIN_WAIT1 close() 阻塞 — read() 读 0 字节 LAST_ACKFIN_WAIT2 close() UDP Socket函数sendto()函数：发送UDP数据，将数据发送到套接字。返回实际发送的数据字节长度或在出现发送错误时返回-1。 int sendto(int sockfd, const void *msg,int len,unsigned int flags,const struct sockaddr *to, int tolen); recvfrom()函数：接受UDP套接字的数据, 与recv()类似。返回接收到的字节数或当出现错误时返回-1，并置相应的errno。 int recvfrom(int sockfd,void *buf,int len,unsigned int flags,struct sockaddr *from,int *fromlen); UDP通信流程图如下： 简单的客户端服务器UDP连接，服务器端： #!/usr/bin/env python # -*- coding:utf-8 -*- import socket BUF_SIZE = 1024 # 设置缓冲区大小 server_addr = (&apos;127.0.0.1&apos;, 8888) # IP和端口构成表示地址 # 生成新的套接字对象 server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) server.bind(server_addr) # 套接字绑定IP和端口 while True: print &quot;waitting for data&quot; # 从客户端接收数据 data, client_addr = server.recvfrom(BUF_SIZE) print &apos;Connected by&apos;, client_addr, &apos; Receive Data : &apos;, data # 发送数据给客户端 server.sendto(data, client_addr) server.close() 客户端如下： import socket BUF_SIZE = 1024 # 设置缓冲区 server_addr = (&apos;127.0.0.1&apos;, 8888) # IP和端口构成表示地址 client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) while True: data = raw_input(&apos;Please Input data &gt; &apos;) client.sendto(data, server_addr) # 向服务器发送数据 data, addr = client.recvfrom(BUF_SIZE) # 从服务器接收数据 print &quot;Data : &quot;, data client.close() 更多阅读Socket通信原理简介简单理解SocketPython爬虫(三)-Socket网络编程Linux Socket编程（不限Linux） 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch7-More]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch7-More%2F</url>
    <content type="text"><![CDATA[网络延迟 以太网工作模式 路由权 路由器与交换机区别 Ads 网络延迟在传输介质中传输所用的时间，即从报文开始进入网络到它开始离开网络之间的时间。(网络延迟PING值越低速度越快) 1~30ms:极快，几乎察觉不出有延迟，玩任何游戏速度都特别顺畅 31~50ms:良好，可以正常游戏，没有明显的延迟情况 51~100ms:普通，对抗类游戏能感觉出明显延迟，稍有停顿 100ms:差，无法正常游戏，有卡顿，丢包并掉线现象 以太网工作模式常用的以太网卡支持以下工作模式：广播模式、多播模式、直接模式和混杂模式。 广播模式（Broad Cast Model）：物理地址（MAC）地址是 0Xffffff 的帧为广播帧，工作在广播模式的网卡接收广播帧。它将会接收所有目的地址为广播地址的数据包，一般所有的网卡都会设置为这个模式。 多播模式（MultiCast Model）：多播传送地址作为目的物理地址的帧可以被组内的其它主机同时接收，而组外主机却接收不到。但是，如果将网卡设置为多播传送模式，它可以接收所有的多播传送帧，而不论它是不是组内成员。 直接模式（Direct Model）：工作在直接模式下的网卡只接收目地址是自己Mac地址的帧。只有当数据包的目的地址为网卡自己的地址时，网卡才接收它。 混杂模式（Promiscuous Model）：工作在混杂模式下的网卡接收所有的流过网卡的帧，信包捕获程序就是在这种模式下运行的。网卡的缺省工作模式包含广播模式和直接模式，即它只接收广播帧和发给自己的帧。如果采用混杂模式，一个站点的网卡将接受同一网络内所有站点所发送的数据包这样就可以到达对于网络信息监视捕获的目的。它将接收所有经过的数据包，这个特性是编写网络监听程序的关键。 路由权路由权是衡量路由好坏的标准。路由算法修改路由表的基本目的是将最好路由信息添加到路由表中，路由的好坏是由路由算法根据自己获得的路由信息计算出来的。 对于每一条路由，路由算法产生一种权值来表示路由的好坏。通常情况下，这种权值越小，该路径越好。路由权的计算可能基于路径某单一特性计算，也可能基于路径多种属性进行计算。有几种路径特性经常被用于权值计算，如下： 带宽 – 链路的数据容量。例如，通常情况下10M 以太网链路比 64K 出租线路要更好。 时延 – 报文到达目标网络所需要的时间。 负载 – 处于活跃状态的网络资源数量。 可靠性 – 每条数据链路的出错率。 跳数 – 报文到目的地需要经过的网络数。 开销 – 一种人为设定的值，通常由网络管理员根据带宽、线路价格或其他一些因素综合得出。 路由器与交换机区别工作层次不同：最初的的交换机是工作在数据链路层，而路由器一开始就设计工作在网络层。由于交换机工作在数据链路层，所以它的工作原理比较简单，而路由器工作在网络层，可以得到更多的协议信息，路由器可以做出更加智能的转发决策。 数据转发所依据的对象不同：交换机是利用物理地址或者说MAC地址来确定转发数据的目的地址。而路由器则是利用IP地址来确定数据转发的地址。IP地址是在软件中实现的，描述的是设备所在的网络。MAC地址通常是硬件自带的，由网卡生产商来分配的，而且已经固化到了网卡中去，一般来说是不可更改的。而IP地址则通常由网络管理员或系统自动分配。 传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域。由交换机连接的网段仍属于同一个广播域，广播数据包会在交换机连接的所有网段上传播，在某些情况下会导致通信拥挤和安全漏洞。连接到路由器上的网段会被分配成不同的广播域，广播数据不会穿过路由器。虽然第三层以上交换机具有VLAN功能，也可以分割广播域，但是各子广播域之间是不能通信交流的，它们之间的交流仍然需要路由器。 路由器提供了防火墙的服务：路由器仅仅转发特定地址的数据包，不传送不支持路由协议的数据包传送和未知目标网络数据包的传送，从而可以防止广播风暴。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch8-Questions]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch8-Questions%2F</url>
    <content type="text"><![CDATA[访问网页过程 Ping 过程 QQ 传输层UDP 更多阅读- [Ads](#ads) 访问网页过程从网络模型的角度来分析，主要涉及 应用层：DNS、HTTP； 传输层：TCP 网络层：IP，路由选择协议RIP，OSPF(内部网关协议),BGP(外部网关协议） 数据链路层：ARP 应用层：客户端浏览器发起一个HTTP会话到服务器。客户端浏览器通过 DNS 解析到 www.baidu.com 的IP地址，通过这个IP地址找到客户端到服务器的路径。 传输层：在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口（服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000），和服务器建立 TCP 连接后进行通信。 网络层：客户端的网络层不关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器。其中可能用到的路由选择协议有 RIP协议、OSPF协议、EGP协议。 链路层：包从路由器到达服务器的局域网后，通过 ARP 协议查找服务器IP地址对应的MAC地址，然后将数据帧传到服务器。 Ping 过程ping 程序用来探测主机到主机之间是否可通信，如果不能ping到某台主机，表明不能和这台主机建立连接。ping 使用的是ICMP协议，它发送icmp回送请求消息给目的主机。ICMP协议规定：目的主机必须返回ICMP回送应答消息给源主机。如果源主机在一定时间内收到应答，则认为主机可达。 假定主机A的IP地址是192.168.1.1，主机B的IP地址是192.168.1.2，都在同一子网内，则当你在主机A上运行“Ping 192.168.1.2”后，都发生了些什么呢? 首先，Ping命令会构建一个固定格式的ICMP请求数据包，然后由ICMP协议将这个数据包连同地址“192.168.1.2”一起交给IP层协议（和ICMP一样，实际上是一组后台运行的进程），IP层协议将以地址“192.168.1.2”作为目的地址，本机IP地址作为源地址，加上一些其他的控制信息，构建一个IP数据包，并在通过 ARP 协议查找出IP地址192.168.1.2所对应的物理地址，一并交给数据链路层。后者构建一个数据帧，目的地址是IP层传过来的物理地址，源地址则是本机的物理地址，还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。 主机B收到这个数据帧后，先检查它的目的地址，并和本机的物理地址对比，如符合，则接收；否则丢弃。接收后检查该数据帧，将IP数据包从帧中提取出来，交给本机的IP层协议。同样，IP层检查后，将有用的信息提取后交给ICMP协议，后者处理后，马上构建一个ICMP应答包，发送给主机A，其过程和主机A发送ICMP请求包到主机B一模一样。 QQ 传输层UDPQQ 为什么采用 UDP 协议？ 最本质上UDP的优势还是带宽的利用。这一切要回归到99~03年的网络状况，当时网络的特点就是接入带宽很窄而且抖动特别厉害。所谓抖动可能是多方面的，例如延时突发性地暴增、也有可能是由于路由层面的变化突然导致路由黑洞，还各种等等等等的问题。TCP因为拥塞控制、保证有序等原因，在这种网络状态上对带宽的利用是非常低的。而且因为网络抖动的原因，应用层心跳超时（一般不依靠keepalive）应用层主动断掉socket之后TCP需要三次握手才能重新建立链接，一旦出现频繁的小抖动就会使得带宽利用更低。而等待四次挥手的时间，也会占用服务器上宝贵的资源。总结来说，当网络差到一定程度了，TCP的优势反而会成为劣势。 使用UDP对抗网络抖动，说到底就是在应用层比TCP更快地探测和重传，一旦超过一定的时间没有收到回复，客户端可以选择马上重试，在服务器端则可以果断地断掉socket。而可以应用UDP的时候，往往是你的应用层协议本身已经具备了一定的面向连接的特性。如果你应用层的协议已经达到了一定程度的消息幂等，客户端可以几乎无脑地进行重传，这样就可以尽可能地降低网络抖动的影响，同时也可以尽可能地利用整个带宽。而刚好QQ的协议，就具备类似的特点。 简单来说就是我们可以使用UDP实现一个面向连接协议，这个协议可以很好地适应当时的网络状况和QQ本身的业务。但凡事都有成本，成本就是你的应用层协议本身需要去实现抵抗网络异常带来的问题。例如乱序、重传，业务数据的分片和重组、网络状态探测等。 （当然，也可能是因为当时没有epoll这种可以支持成千上万tcp并发连接的技术，所以他们使用了udp，然后在udp上面封装了模拟tcp，解决大并发的问题。） 更多阅读在浏览器中输入URL后执行的全部过程的个人总结QQ 为什么采用 UDP 协议，而不采用 TCP 协议实现 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ch9-SS_Surge]]></title>
    <url>%2Fse-notes%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2Fch9-SS_Surge%2F</url>
    <content type="text"><![CDATA[ShadowSocks的原理 扩展 surge 是什么 更多阅读 Ads ShadowSocks的原理Shadowsocks 基于 Socks5协议，将代理服务器拆开成Server端和client端，然后通过以下方式进行通信： PC客户端（即你的电脑）发出请求基于Socks5协议跟SS-Local端进行通讯; SS-Local和SS-Server两端通过多种可选的加密方法进行通讯; SS-Server将收到的加密数据进行解密，还原初始请求，再发送到用户需要访问的服务网站，获取响应原路再返回到客户端。 扩展为什么不应该用 SSL 翻墙？ SSL 设计目标: 防内容篡改 防冒充服务器身份 加密通信内容 而翻墙的目标: 不被检测出客户端在访问什么网站 不被检测出服务器在提供翻墙服务 SSL 和这个目标还是有一些出入。其中最大的问题是防冒充服务器身份这个功能多余了。他会导致墙嗅探出证书信息，继而墙会知道服务器身份。如果墙知道一个服务器身份是用来翻墙的，它要做的仅仅是封掉使用这个证书的所有 IP。 surge 是什么 如果你还没听过 Surge，你就有点落后了，如果你还没用过 Surge，很抱歉你错过了好多。 Surge 是一款开发者调试和代理工具，一经推出便备受大家瞩目，赢的一片赞誉。最开始时，它只是一款 iOS 9 上的网络调试工具，较适用于开发人员。现在，还有了 Mac 版。目前功能可以说是强大至极，包括广告过滤（再也看不到各种讨厌的广告），科学上网等，绝对值得所有人拥有。 更多阅读翻墙路由器的原理与实现翻墙软件的选择与安全系数关于翻墙和匿名与网络安全类科普文大集合Surge 新手使用指南Surge for Mac 简明指南 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>network</tag>
        <tag>tcp/ip</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-CE安装]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2FKubernetes%E9%83%A8%E7%BD%B2%2FDocker-CE%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Docker CE 安装 参考资料 Ads Docker CE 安装首先安装 Docker 的依赖包如下：1$ yum install yum-utils device-mapper-persistent-data lvm2 添加 Docker 的软件源（这里使用的是国内源，也可以挂代理来使用官方的源）：123$ sudo yum-config-manager \ --add-repo \ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo 更新 yum 软件源缓存，并安装 docker-ce ：12$ sudo yum makecache fast$ sudo yum install docker-ce 启动 Docker CE：12$ sudo systemctl enable docker$ sudo systemctl start docker PS：默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好的做法是将需要使用 docker 的用户加入 docker 用户组。 国内从 Docker Hub 拉取镜像有时会遇到困难，此时可以配置镜像加速器。对于使用 CentOS 系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）12345&#123; &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ]&#125; 之后重新启动服务：12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 测试 Docker 是否安装正确：1$ docker run hello-world 若输出如下则说明安装成功：1234567891011121314151617181920Hello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ 若出现以下报错：1docker: Error response from daemon: OCI runtime create failed: unable to retrieve OCI runtime error (open /run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/225edd3d808116d3cc5992849e60bf5369ace67c291a066ebae4ca5784bcce7a/log.json: no such file or directory): docker-runc did not terminate sucessfully: unknown. 则是因为 libseccomp 没有更新到最新版本，安装最新版本即可：1yum install http://mirror.centos.org/centos/7/os/x86_64/Packages/libseccomp-2.3.1-3.el7.x86_64.rpm 默认配置下，如果在 CentOS 使用 Docker CE 看到下面的这些警告信息：12WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled 请添加内核配置参数以启用这些功能：1234$ sudo tee -a /etc/sysctl.conf &lt;&lt;-EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 然后重新加载 sysctl.conf 即可：1$ sudo sysctl -p 参考资料 CentOS 安装 Docker CE Docker 官方 CentOS 安装文档 docker-runc did not terminate sucessfully: unknown 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>kubernetes部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker配置网络代理]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2FKubernetes%E9%83%A8%E7%BD%B2%2FDocker%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[为 Docker 配置网络代理 背景 步骤 参考资料 Ads 为 Docker 配置网络代理背景在一些实验环境中服务器没有直接连接外网的权限，需要通过网络代理。我们通常会将网络代理直接配置在/etc/environment、/etc/profile之类的配置文件中，这对于大部分操作都是可行的。然而，docker 命令却使用不了这些代理。比如 docker pull 时需要从外网下载镜像，就会出现错误。 步骤首先为 docker 服务创建一个内嵌的 systemd 目录：1$ mkdir -p /etc/systemd/system/docker.service.d 创建/etc/systemd/system/docker.service.d/http-proxy.conf文件，并添加 HTTP_PROXY 环境变量（其中[proxy-addr]和[proxy-port]分别改成实际情况的代理地址和端口）：12[Service]Environment=&quot;HTTP_PROXY=http://[proxy-addr]:[proxy-port]/&quot; &quot;HTTPS_PROXY=https://[proxy-addr]:[proxy-port]/&quot; 如果还有内部的不需要使用代理来访问的 Docker registries，那么还需要制定 NO_PROXY 环境变量：12[Service]Environment=&quot;HTTP_PROXY=http://[proxy-addr]:[proxy-port]/&quot; &quot;HTTPS_PROXY=https://[proxy-addr]:[proxy-port]/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com&quot; 更新配置与重启 Docker 服务：12$ systemctl daemon-reload$ systemctl restart docker 验证配置是否已经加载：12$ systemctl show --property=Environment dockerEnvironment=HTTP_PROXY=http://proxy.example.com:80/ 参考资料Docker 网络代理设置 Docker 官网教程 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>kubernetes部署</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群高可用方案-README]]></title>
    <url>%2Fse-notes%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E5%AE%9E%E8%B7%B5%2F%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%2FREADME%2F</url>
    <content type="text"><![CDATA[集群高可用方案概念介绍 双机热备 LVS Keepalived Heartbeat Keepalived VS Heartbeat DRBD Ads 集群高可用方案概念介绍双机热备双机热备特指高可用服务器集群中两台服务器的高可用，目标是实现如下场景： 两台 Web 服务器为主从备份，并同时开启，但只有主服务器对外提供服务。（或者通过负载均衡同时对外提供服务） 当主服务器宕机时，从服务器接管服务，且 IP 地址保持不变。 主服务器与从服务器的数据库与静态文件资源保持实时一致。 LVSLVS（Linux Virtual Server）即 Linux 虚拟服务器，采用 IP 负载均衡技术和基于内容请求分发技术，是一个高可伸缩、高可用网络服务的虚拟服务器集群系统，主要用于服务器集群的负载均衡。 使用 LVS 架设的服务器集群系统有三个部分组成： 负载调度器（Load Balancer）：整个集群对外服务的前端机，负责将用户请求发送到一组服务器上执行，而用户认为服务只来自一个IP地址（即 Virtual IP）。 服务器集群（Server Array），是一组真正执行客户请求的服务器（Real Server），执行的服务包括但不限于 WEB、MAIL、FTP 和 DNS 等。 共享存储（Shared Storage）：为服务器池所提供的一个共享存储区，这样可使得服务器集群拥有相同的内容，提供相同的服务。 LVS 集群中的负载调度器具有很好的吞吐率，可将请求均衡地转移到不同的服务器上执行，且负载调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。整个服务器集群的结构对客户是黑箱状态，而且无需修改客户端和服务器端的程序。 LVS 的实现方式主要分为 NAT（网络地址转换）与 DR（直接路由）两种。 NAT：目标 IP 为 VIP（Virtual IP）的用户请求经过 DS （Director Server）时进行了 IP 地址转换，把 VIP 换成了 RS（Real Server） 的实际 IP。RS 处理完请求后需要把 response 再发回给 DS，再由 DS 转换为 VIP 后返回给请求的用户。（优点是服务器可以运行任何支持 TCP/IP 的操作系统；缺点是 response 都要经过 DS，伸缩能力有限，难以支持大集群） DR：目标 IP 为 VIP 的用户请求经过 DS 时进行了 MAC 地址转换，把 MAC 地址修改为了 RS 的实际 MAC 地址。RS 处理完请求后把 response 直接返回给用户。（优点是伸缩性强，但需要 DS 与 RS 在同一个物理子网） 注意：LVS 集群中的负载调度器不可与真实服务器是同一台机器。因为 LVS 是四层负载均衡（基于传输层，请求的转发通过修改 IP 地址或目标 MAC 地址来实现），所以无法保证一个请求是交付给本机的负载均衡器进行调度还是交付给本机的应用程序处理，因此可能会陷入自己不断把请求发给自己的死循环。 LVS 官方中文文档LVS + Keepalived 中 Vip 不能访问 KeepalivedKeepalived 是一款高可用软件，它的功能主要包括两方面： 基于 VRRP 协议，通过 IP 漂移实现服务的高可用：服务器集群共享一个虚拟 IP，同一时间只有一个服务器占有虚拟 IP 并对外提供服务。若该服务器不可用，则虚拟 IP 漂移至另一台服务器并对外提供服务； 对 LVS 应用服务层的应用服务器集群进行状态监控：若应用服务器不可用，则 Keepalived 将其从集群中摘除，若应用服务器恢复，则 Keepalived 将其重新加入集群中。 Keepalived 可以单独使用，即通过 IP 漂移实现服务的高可用，也可以结合 LVS 使用（即一方面通过IP漂移实现 LVS 负载均衡层的高可用，另一方面实现 LVS 应用服务层的状态监控）。 HeartbeatHeartbeat 是 Linux-HA 工程的一个组件，是集群管理中保证集群高可用的服务软件，它可以瞬间接管一台机器上的所有资源（包括访问资源、提供服务的资源和IP地址等等）。 Heartbeat 最核心的两个部分是心跳监测和资源接管。心跳监测使设备之间相互发送报文来告诉对方自己当前的状态，如果在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运行在对方主机上的资源或者服务。 Keepalived VS Heartbeat Keepalived 使用更简单：从安装、配置、使用、维护等角度上对比，Keepalived 都比 Heartbeat 要简单得多，尤其是 Heartbeat 2.1.4 后拆分成3个子项目，安装、配置、使用都比较复杂；而 Keepalived 只有1个安装文件和1个配置文件。 Heartbeat 功能更强大：Heartbeat 虽然复杂，但功能更强大，配套工具更全，适合做大型集群管理；而 Keepalived 主要用于集群倒换，基本没有管理功能。 协议不同：Keepalived 使用 VRRP 协议进行通信和选举，Heartbeat 使用心跳进行通信和选举；Heartbeat 除了网络外还可以通过串口通信，更加可靠。 使用方式类似：如果要基于两者设计高可用方案，最终都要根据业务需要写自定义的脚本。Keepalived 的脚本没有约束；Heartbeat 的脚本有约束，即需要支持 service start/stop/restart 这种方式。 接管方式不同：Keepalived 仅能用于接管IP地址，而 Heartbeat 可以接管IP、服务、存储等多种资源。且 Keepalived 集群中所有节点保证服务都开启，而 Heartbeat 集群只需要保证主节点服务开启即可（主节点宕机再由从节点开启服务）。 建议：优先使用 Keepalived，当 Keepalived 功能不够用的时候才选择 Heartbeat What is the difference between keepalive and heartbeat? DRBDDRBD （Distributed Replicated Block Device）是一种基于软件的，无共享，复制的存储解决方案，在服务器之间对块设备（硬盘，分区，逻辑卷等）进行镜像。DRBD 负责接收数据，把数据写到本地磁盘，然后通过网络将同样的数据发送给另一个主机，另一个主机再将数据存到自己的磁盘中。 工作原理：每个设备都有一个状态，可能是主状态或从状态。在主节点上，应用程序应能运行和访问 DRBD 设备（/dev/drbd*），且每次写入都会发往本地磁盘设备和从节点设备中。从节点只能简单地把数据写入它的磁盘设备上。 读取数据通常在本地进行。 如果主节点发生故障，心跳（heartbeat 或 corosync）将会把从节点转换到主状态，并启动其上的应用程序。如果发生故障的节点恢复工作，它就会成为新的从节点，而且必须使自己的内容与主节点的内容保持同步。 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>云计算实践</category>
        <category>集群高可用方案</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[informationisbeautiful]]></title>
    <url>%2Finformationisbeautiful%2F</url>
    <content type="text"><![CDATA[informationisbeautiful About Home graffiti/doodle Ads informationisbeautifulAboutData, information, knowledge: we distil it into beautiful, useful graphics &amp; diagrams. Founded by David McCandless, author of two bestselling infographics books, Information is Beautiful is dedicated to helping you make clearer, more informed decisions about the world. All our visualizations are based on facts &amp; data: constantly updated, revised &amp; revisioned. Homehttps://informationisbeautiful.net/ graffiti/doodle informationisbeautiful1printf("informationisbeautiful!");informationisbeautiful informationisbeautiful1. informationisbeautiful1. informationisbeautiful1. informationisbeautiful- [ ] informationisbeautiful&gt; informationisbeautifulinformationisbeautiful———————-Name | Adress——- | ——-informationisbeautiful | https://informationisbeautiful.net/— 我觉得帮助到我了, 支持你一下.* If you think the article is helpful to you, you can reward me through paypal.### Ads这是小广告! 如果有需要, 不妨支持一下吧~&gt; 这些好书您看了吗?&gt; 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>Graphics</category>
      </categories>
      <tags>
        <tag>informationisbeautiful</tag>
        <tag>graphics</tag>
        <tag>diagrams</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-qq]]></title>
    <url>%2Fdocker-qq%2F</url>
    <content type="text"><![CDATA[Docker QQ repo home run command Ads Docker QQ ## repo homehttps://github.com/bestwu/docker-qq## run command12345678910111213141516171819$ docker run -d --name qq \ --init \ -m 384m --cpuset-cpus=2,3 \ --device /dev/snd \ -v /tmp/.X11-unix:/tmp/.X11-unix \ -v $&#123;XDG_RUNTIME_DIR&#125;/pulse/native:$&#123;XDG_RUNTIME_DIR&#125;/pulse/native \ -v $HOME/.qq:/TencentFiles \ -e DISPLAY=unix$DISPLAY \ -e XMODIFIERS=@im=fcitx \ -e QT_IM_MODULE=fcitx \ -e GTK_IM_MODULE=fcitx \ -e QT_X11_NO_MITSHM=1 \ -e PULSE_SERVER=unix:$&#123;XDG_RUNTIME_DIR&#125;/pulse/native \ -e XDG_RUNTIME_DIR=$&#123;XDG_RUNTIME_DIR&#125; \ -e AUDIO_GID=`getent group audio | cut -d: -f3` \ -e VIDEO_GID=`getent group video | cut -d: -f3` \ -e GID=`id -g` \ -e UID=`id -u` \ bestwu/qq:office — 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal.### Ads这是小广告! 如果有需要, 不妨支持一下吧~&gt; 这些好书您看了吗?&gt; 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>通用技术</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker-qq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将PEM证书转换为PFX,P12格式]]></title>
    <url>%2F%E5%B0%86PEM%E8%AF%81%E4%B9%A6%E8%BD%AC%E6%8D%A2%E4%B8%BAPFX%2CP12%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[场景PEM 证书不受支持，它们必须转换为 PKCS#12 (PFX/P12) 格式。 证书转换 转至 https://www.openssl.org/community/binaries.html 下载并安装openssl, 已经安装的则可直接使用openssl. 从 OpenSSL 安装 bin 文件夹运行以下命令格式。1# openssl pkcs12 -export -out Cert.p12 -in cert.pem -inkey key.pem -passin pass:root -passout pass:root [Reference]将 PEM 证书转换为 PFX/P12 格式https://www.ibm.com/support/knowledgecenter/zh/SSPH29_9.0.3/com.ibm.help.common.infocenter.aps/t_ConvertthepfxCertificatetopemFormat068.html 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>协议证书</category>
        <category>openssl</category>
      </categories>
      <tags>
        <tag>PEM证书</tag>
        <tag>openssl</tag>
        <tag>pfx</tag>
        <tag>p12</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openwrt定时任务设置]]></title>
    <url>%2Fopenwrt%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[定时任务设置示例使用 crontab -e 编辑 Openwrt 的定时任务，添加如下12345# Reboot at 4:30am every day# Note: To avoid infinite reboot loop, wait 70 seconds# and touch a file in /etc so clock will be set# properly to 4:31 on reboot before cron starts.30 4 * * * sleep 70 &amp;&amp; touch /etc/banner &amp;&amp; reboot 这个 task 将在每天 4:30am 的时候重启路由器。 需要注意的是，一定要延迟重启，否则可能无限重启，官方给出的配置1中，在 sleep 70 秒之后，使用 touch 写文件，应为路由器如果没有及时联网从NTP服务器上获取到实践，那么路由器的系统时间和重启的系统时间便一样，如果修改过文件，Openwrt 开机后会把最后修改或者访问的文件时间作为默认系统时间。因此延迟1min重启，可以避免这个问题。 [Reference]Cron and crontabhttps://openwrt.org/docs/guide-user/base-system/cron 使用 Cron 定时重启 Openwrt 路由器http://einverne.github.io/post/2017/03/auto-reboot-openwrt.html LEDE/OpenWRT — Scheduling Taskshttps://medium.com/openwrt-iot/openwrt-scheduling-tasks-6e19d507ae45 System configurationhttps://oldwiki.archive.openwrt.org/doc/uci/system#time_zones 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>路由器</category>
        <category>openwrt</category>
      </categories>
      <tags>
        <tag>openwrt</tag>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-rebase]]></title>
    <url>%2Fgit-rebase%2F</url>
    <content type="text"><![CDATA[简要介绍字面意思 re base, 变基.将所有要合并进来的commit在新的基础上重新提交一次.我们知道,还有个熟悉的命令: git merge, 每个commit都可以看到.git rebase相比git merge更”清爽”. git分支合并方法 git merge git rebase git cherry-pick git cherry-pick堪称”神器”,原因是灵活.想要合并某个commit, 直接cherry-pick过来即可. 需要注意, cherry-pick合入的不是分支,而是提交节点. git rebaserebase会将合入分支上超前的节点在待合入分支上重新提交一遍,换言之,git rebase 会计算当前分支和目标分支的最近共同祖先，然后将最近共同祖先与当前分支之间的所有commit都变基到目标分支上，使得提交历史变成一条直线。 merge与rebase后跟的分支名是不一样的。合并是合并进来，变基是变基过去.123C0 -- C1 -- C2 -- C3(master) \ C4 -- C5 -- C6(HEAD -&gt; dev)执行git rebase master123C0 -- C1 -- C2 -- C3(master) -- C4&apos; -- C5&apos; -- C6&apos;(HEAD -&gt; dev) \ C4 -- C5 -- C6最近共同祖先与当前分支之间的所有commit都被复制到master分支之后，并且将HEAD指针与当前分支指针切换过去。原来的commit还在吗？还在，如果你记得它的commit校验和，仍然可以切换过去，git会提示你当前处于detached HEAD状态下。只不过没有任何分支指针指向它们，它们已经被抛弃了，剩余的时光就是等待git垃圾回收命令清理它们。git rebase完并没有结束，因为我变基的目标分支是master，而当前分支是dev。我需要切换到master分支上，然后再合并一次。123$ git rebase master (当前分支是dev分支)$ git checkout master$ git merge dev注意: 这种合并是fast forward的，并不会生成一个新的合并commit。关于fast forward后面在对git merge进行说明时, 会讲到merge的三种方式.如果我要变基的本体分支不是当前分支行不行？也是可以的。在任何一个分支上，将dev分支变基到master分支上，变基完成当前分支会变成dev分支。1$ git rebase master dev## git merge### fast-forwar如果待合并的分支在当前分支的下游，也就是说没有分叉时，会发生快速合并，从test分支切换到master分支，然后合并test分支12$ git checkout master$ git merge test这种方法相当于直接把master分支移动到test分支所在的地方，并移动HEAD指针. ### no-ff如果我们不想要快速合并，那么我们可以强制指定为非快速合并，只需加上–no-ff参数12$ git checkout master$ git merge –no-ff test这种合并方法会在master分支上新建一个提交节点，从而完成合并 ### squashsvn的在合并分支时采用的就是这种方式，squash会在当前分支新建一个提交节点squash和no-ff非常类似，区别只有一点不会保留对合入分支的引用12$ git checkout master$ git merge –squash test — 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal.### Ads这是小广告! 如果有需要, 不妨支持一下吧~&gt; 这些好书您看了吗?&gt; 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>版本控制</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp-检测机器大端或者小端]]></title>
    <url>%2Fcpp-%E6%A3%80%E6%B5%8B%E6%9C%BA%E5%99%A8%E5%A4%A7%E7%AB%AF%E6%88%96%E8%80%85%E5%B0%8F%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[今天在csdn上看到的 自己改进了一下发出来小端输出1 大端输出01234567union&#123; int i; char c[4];&#125; test;test.i = 1;cout &lt;&lt; int(test.c[0]) &lt;&lt; endl; [More Reference]大小端字节序存在的意义，为什么不用一个标准呢？https://www.zhihu.com/question/25311159 “字节序”是个什么鬼？https://zhuanlan.zhihu.com/p/21388517 大小端存储模式精解https://jocent.me/2017/07/25/big-little-endian.html 详解大端模式和小端模式https://blog.csdn.net/ce123_zhouwei/article/details/6971544 主机字节序与网络字节序https://blog.csdn.net/hou09tian/article/details/82759758 Linux程序设计学习笔记—-网络编程之网络数据包拆封包与字节顺序大小端https://blog.csdn.net/suool/article/details/38636993?utm_source=tuicool 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>网络通讯</category>
        <category>大小端</category>
      </categories>
      <tags>
        <tag>大小端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简约不简单]]></title>
    <url>%2F%E7%AE%80%E7%BA%A6%E4%B8%8D%E7%AE%80%E5%8D%95%2F</url>
    <content type="text"><![CDATA[简约不简单Brief, but not simple. 我觉得帮助到我了, 支持你一下. If you think the article is helpful to you, you can reward me through paypal. Ads这是小广告! 如果有需要, 不妨支持一下吧~ 这些好书您看了吗? 体育&amp;户外用品推荐]]></content>
      <categories>
        <category>默认</category>
      </categories>
      <tags>
        <tag>默认</tag>
      </tags>
  </entry>
</search>
